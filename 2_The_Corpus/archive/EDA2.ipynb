{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive approach\n",
    "https://towardsdatascience.com/naive-bayes-document-classification-in-python-e33ff50f937e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "809\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80380</td>\n",
       "      <td>Home | Databases | WorldLII | Search | Feedbac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78839</td>\n",
       "      <td>Home | Databases | WorldLII | Search | Feedbac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>248796</td>\n",
       "      <td>State v Lagivere - Sentence [2017] FJHC 386...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>257586</td>\n",
       "      <td>State v Goundar - Sentence [2018] FJHC 438;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80121</td>\n",
       "      <td>Home | Databases | WorldLII | Search | Feedbac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>79035</td>\n",
       "      <td>Home | Databases | WorldLII | Search | Feedbac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>249470</td>\n",
       "      <td>Kumar v State [2018] FJHC 583; HAA05.2018 (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>268266</td>\n",
       "      <td>Rashid v State [2015] FJCA 49; AAU03.2014 (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>79400</td>\n",
       "      <td>Home | Databases | WorldLII | Search | Feedbac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>83056</td>\n",
       "      <td>Home | Databases | WorldLII | Search | Feedbac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>804 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      docid                                           contents\n",
       "0     80380  Home | Databases | WorldLII | Search | Feedbac...\n",
       "1     78839  Home | Databases | WorldLII | Search | Feedbac...\n",
       "2    248796     State v Lagivere - Sentence [2017] FJHC 386...\n",
       "3    257586     State v Goundar - Sentence [2018] FJHC 438;...\n",
       "4     80121  Home | Databases | WorldLII | Search | Feedbac...\n",
       "..      ...                                                ...\n",
       "799   79035  Home | Databases | WorldLII | Search | Feedbac...\n",
       "800  249470     Kumar v State [2018] FJHC 583; HAA05.2018 (...\n",
       "801  268266     Rashid v State [2015] FJCA 49; AAU03.2014 (...\n",
       "802   79400  Home | Databases | WorldLII | Search | Feedbac...\n",
       "803   83056  Home | Databases | WorldLII | Search | Feedbac...\n",
       "\n",
       "[804 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the matching document contents\n",
    "df_text = pd.read_csv(\"data/trackGBV_xls_match.csv\")\n",
    "print(len(df_text))\n",
    "df_text.head(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "809\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DocID</th>\n",
       "      <th>Customary_Practices</th>\n",
       "      <th>Gender_Stereotypes</th>\n",
       "      <th>Other_Factors</th>\n",
       "      <th>Num_Factors</th>\n",
       "      <th>Discrimination_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69815</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69881</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70042</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70139</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70164</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>285793</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>285800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>285849</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>286739</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>286744</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>804 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      DocID  Customary_Practices  Gender_Stereotypes  Other_Factors  \\\n",
       "0     69815                    0                   0              1   \n",
       "1     69881                    1                   0              1   \n",
       "2     70042                    0                   0              0   \n",
       "3     70139                    1                   0              1   \n",
       "4     70164                    0                   1              0   \n",
       "..      ...                  ...                 ...            ...   \n",
       "799  285793                    0                   1              0   \n",
       "800  285800                    0                   0              0   \n",
       "801  285849                    0                   1              1   \n",
       "802  286739                    0                   0              0   \n",
       "803  286744                    0                   0              0   \n",
       "\n",
       "     Num_Factors  Discrimination_Label  \n",
       "0              1                     1  \n",
       "1              2                     1  \n",
       "2              0                     0  \n",
       "3              2                     1  \n",
       "4              1                     1  \n",
       "..           ...                   ...  \n",
       "799            1                     1  \n",
       "800            0                     0  \n",
       "801            2                     1  \n",
       "802            0                     0  \n",
       "803            0                     0  \n",
       "\n",
       "[804 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels = pd.read_csv(\"data/trackGBV_labels.csv\")\n",
    "print(len(df_text))\n",
    "df_labels.head(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>contents</th>\n",
       "      <th>DocID</th>\n",
       "      <th>Customary_Practices</th>\n",
       "      <th>Gender_Stereotypes</th>\n",
       "      <th>Other_Factors</th>\n",
       "      <th>Num_Factors</th>\n",
       "      <th>Discrimination_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80380</td>\n",
       "      <td>Home | Databases | WorldLII | Search | Feedbac...</td>\n",
       "      <td>80380</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78839</td>\n",
       "      <td>Home | Databases | WorldLII | Search | Feedbac...</td>\n",
       "      <td>78839</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>248796</td>\n",
       "      <td>State v Lagivere - Sentence [2017] FJHC 386...</td>\n",
       "      <td>248796</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>257586</td>\n",
       "      <td>State v Goundar - Sentence [2018] FJHC 438;...</td>\n",
       "      <td>257586</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80121</td>\n",
       "      <td>Home | Databases | WorldLII | Search | Feedbac...</td>\n",
       "      <td>80121</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>75927</td>\n",
       "      <td>Home | Databases | WorldLII | Search | Feedbac...</td>\n",
       "      <td>75927</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>247181</td>\n",
       "      <td>State v Khelawan [2016] FJMC 41; Criminal C...</td>\n",
       "      <td>247181</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>271413</td>\n",
       "      <td>Bulivou v State [2014] FJCA 215; AAU78.2010...</td>\n",
       "      <td>271413</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>252935</td>\n",
       "      <td>State v Lal [2015] FJMC 58; Criminal Case 1...</td>\n",
       "      <td>252935</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>274241</td>\n",
       "      <td>Ram v State [2015] FJSC 26; CAV12.2015 (23 ...</td>\n",
       "      <td>274241</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>809 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      docid                                           contents   DocID  \\\n",
       "0     80380  Home | Databases | WorldLII | Search | Feedbac...   80380   \n",
       "1     78839  Home | Databases | WorldLII | Search | Feedbac...   78839   \n",
       "2    248796     State v Lagivere - Sentence [2017] FJHC 386...  248796   \n",
       "3    257586     State v Goundar - Sentence [2018] FJHC 438;...  257586   \n",
       "4     80121  Home | Databases | WorldLII | Search | Feedbac...   80121   \n",
       "..      ...                                                ...     ...   \n",
       "804   75927  Home | Databases | WorldLII | Search | Feedbac...   75927   \n",
       "805  247181     State v Khelawan [2016] FJMC 41; Criminal C...  247181   \n",
       "806  271413     Bulivou v State [2014] FJCA 215; AAU78.2010...  271413   \n",
       "807  252935     State v Lal [2015] FJMC 58; Criminal Case 1...  252935   \n",
       "808  274241     Ram v State [2015] FJSC 26; CAV12.2015 (23 ...  274241   \n",
       "\n",
       "     Customary_Practices  Gender_Stereotypes  Other_Factors  Num_Factors  \\\n",
       "0                      0                   0              1            1   \n",
       "1                      0                   0              1            1   \n",
       "2                      0                   0              0            0   \n",
       "3                      1                   1              0            2   \n",
       "4                      0                   1              0            1   \n",
       "..                   ...                 ...            ...          ...   \n",
       "804                    0                   0              0            0   \n",
       "805                    0                   1              0            1   \n",
       "806                    0                   0              0            0   \n",
       "807                    0                   0              0            0   \n",
       "808                    0                   0              1            1   \n",
       "\n",
       "     Discrimination_Label  \n",
       "0                       1  \n",
       "1                       1  \n",
       "2                       0  \n",
       "3                       1  \n",
       "4                       1  \n",
       "..                    ...  \n",
       "804                     0  \n",
       "805                     1  \n",
       "806                     0  \n",
       "807                     0  \n",
       "808                     1  \n",
       "\n",
       "[809 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge the two together\n",
    "df = df_text.merge(df_labels, left_on='docid', right_on='DocID')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['contents'], df['Discrimination_Label'], \n",
    "                                                    random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Counting\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(strip_accents='ascii', \n",
    "                     token_pattern=u'(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b', \n",
    "                     lowercase=True, \n",
    "                     stop_words='english')\n",
    "X_train_cv = cv.fit_transform(X_train)\n",
    "X_test_cv = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check training data\n",
    "word_freq_df = pd.DataFrame(X_train_cv.toarray(), columns=cv.get_feature_names())\n",
    "top_words_df = pd.DataFrame(word_freq_df.sum()).sort_values(0, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0\n",
      "court     8837\n",
      "years     7929\n",
      "sentence  7533\n",
      "accused   4998\n",
      "state     4764\n",
      "...        ...\n",
      "lautiki      1\n",
      "laulaba      1\n",
      "latent       1\n",
      "lateness     1\n",
      "zubair       1\n",
      "\n",
      "[15361 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(top_words_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and predict\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(X_train_cv, y_train)\n",
    "predictions = naive_bayes.predict(X_test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.7093596059113301\n",
      "Precision score:  0.7018633540372671\n",
      "Recall score:  0.9112903225806451\n"
     ]
    }
   ],
   "source": [
    "# check scores\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "print('Accuracy score: ', accuracy_score(y_test, predictions))\n",
    "print('Precision score: ', precision_score(y_test, predictions))\n",
    "print('Recall score: ', recall_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(91.68, 0.5, 'predicted label')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "sns.heatmap(cm, square=True, annot=True, cmap='RdBu', cbar=False,\n",
    "xticklabels=['1', '0'], yticklabels=['1', '0'])\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_predictions = []\n",
    "for i in range(len(X_test)):\n",
    "    if predictions[i] == 1:\n",
    "        testing_predictions.append('1')\n",
    "    else:\n",
    "        testing_predictions.append('0')\n",
    "check_df = pd.DataFrame({'actual_label': list(y_test), 'prediction': testing_predictions, 'contents':list(X_test)})\n",
    "check_df.replace(to_replace=0, value='1', inplace=True)\n",
    "check_df.replace(to_replace=1, value='0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual_label</th>\n",
       "      <th>prediction</th>\n",
       "      <th>contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Home | Databases | WorldLII | Search | Feedbac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Home | Databases | WorldLII | Search | Feedbac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>State v Tatoro - Sentence [2016] FJHC 347; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>State v Waqa - Sentence [2016] FJHC 531; HA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>State v Zubair - Sentence [2017] FJHC 895; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Home | Databases | WorldLII | Search | Feedbac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Home | Databases | WorldLII | Search | Feedbac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>State v Balak [2015] FJHC 709; HAC260.2014 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>State v Chand [2015] FJMC 77; Criminal Case...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Sigavinaka v State [2017] FJHC 140; HAA81.2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>203 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    actual_label prediction                                           contents\n",
       "0              0          1  Home | Databases | WorldLII | Search | Feedbac...\n",
       "1              0          1  Home | Databases | WorldLII | Search | Feedbac...\n",
       "2              1          1     State v Tatoro - Sentence [2016] FJHC 347; ...\n",
       "3              0          1     State v Waqa - Sentence [2016] FJHC 531; HA...\n",
       "4              1          1     State v Zubair - Sentence [2017] FJHC 895; ...\n",
       "..           ...        ...                                                ...\n",
       "198            0          1  Home | Databases | WorldLII | Search | Feedbac...\n",
       "199            0          1  Home | Databases | WorldLII | Search | Feedbac...\n",
       "200            1          1     State v Balak [2015] FJHC 709; HAC260.2014 ...\n",
       "201            0          1     State v Chand [2015] FJMC 77; Criminal Case...\n",
       "202            0          1     Sigavinaka v State [2017] FJHC 140; HAA81.2...\n",
       "\n",
       "[203 rows x 3 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Home | Databases | WorldLII | Search | Feedback\\nHigh Court of Fiji\\nYou are here:\\xa0 PacLII >> Databases >> High Court of Fiji >> 2011 >> [2011] FJHC 641\\n\\nDatabase Search | Name Search | Recent Decisions | Noteup | LawCite | Download | Help\\n\\nState v Ram - Sentence [2011] FJHC 641; HAC033.2010L (12 October 2011) \\nIN THE HIGH COURT OF FIJI\\nAT LAUTOKA\\nCRIMINAL JURISDICTION\\n\\nCRIMINAL CASE NO.: HAC 033 OF 2010L\\n\\nBETWEEN:\\n\\nSTATE\\n\\nAND :\\n\\nFELIX RAM\\n\\nMr F. Lacanivalu for the State\\nMs. V. Tamanisau [LAC] for the Accused\\n\\nDate of Hearing : 11th October, 2011.\\nDate of Sentence : 12th October, 2011.\\n\\nSENTENCE\\n[Child Rape]\\n\\n[1] On the 11th October 2011 the accused entered a plea of guilty to one charge of rape contrary to Section 207(1) & (2) (b) of the Crimes Decree 2009, the particulars being that on the 14th March 2010 at Uciwai settlement, Korolevu he raped a child with his finger. He agreed to facts put to him, whereupon he was found guilty and convicted.\\n\\n[2] The facts admitted by the accused were that in March 2010 he was staying with the victims\\' family, he being related to the victims\\' father. On the 14th March 2010, the mother had left home to visit the father in hospital. She left the victim, who at the time was 9 years old and her elder brother in the care of the accused.\\n\\n[3] After dinner the two children went to sleep on a mattress. The boy asked the accused to sleep on the mattress with them as his mother has not yet returned. The accused blew out the candle and joined them on the mattress. The boy told the victim to lie in the middle between him and the accused. While lying down the accused pulled down the girls\\' panties and used his fingers to indecently invade her. The victim felt pain and tried to push his hand away, however the accused persisted. The next morning the young girl told her mother what had happened. The accused was chased from the house and the Police informed.\\n\\n[4] The maximum penalty for rape is life imprisonment and the Courts have recently been handing down very heavy sentences on offenders against children. Sexual offending against children in this country has become far too prevalent and it is the hope that harsh sentences will send out a clear message to would be perpetrators that our children are to be protected from such unrestrained immorality.\\n\\n[5] In Tamanitoakula HAC 28 of 2010 (Lbs), Thurairaja J passed a sentence of 16 years against an accused convicted of rape of a thirteen year old, as a deterrent punishment.\\n\\n[6] A very similar case to this was in Labasa where a 50 years old raped a nine year old and attracted a sentence of twelve years by Goundar J in Joji Mara HAC 38 of 2010(Lbs).\\n\\n[7] The Court of Appeal has set the starting point for rape of a child to be ten years imprisonment in Drotini AAU0001.2005S.\\n\\n[8] In mitigation, Counsel for the accused tells me that the accused is 57 years old, and while previously a saw miller, he now works as a security guard. He regrets what has happened and when he came to his senses he got up and left the room. He was previously a member of the Catholic Church but now belongs to the Harvest Evangelical Church whose Senior Pastor gave a sworn testimonial in his favour.\\n\\n[9] He produces a letter from the Parish Priest of the Lautoka Catholic Church attesting to his good character.\\n\\n[10] He is asthmatic and intensely remorseful. He would have sought forgiveness from the victim but was unable to because of the strict bail conditions imposed on him.\\n\\n[11] Two of the biggest mitigatory features in his favour are his \"eve of trial\" plea of guilty, and in doing so relieving the victim of having to relive her ordeal.\\n\\n[12] It is an aggravating feature of the case that the accused was in a position of trust, that trust given him by the mother to care for the children in her absence. That trust he abused.\\n\\n[13] I take as a starting point a term of fourteen years imprisonment and for the aggravation of breach of trust I increase that to a term of sixteen years. For the demonstrable remorse and religious mitigation I deduct 2 years. This also includes credit for his clear record. The plea of guilty was entered on the day of trial and will not receive the full credit it could; but I am nevertheless aware of the saving of the young girl giving evidence. He will receive credit for that of three years, meaning that the accused will serve a total term of imprisonment of 11 years.\\n\\n[14] He will serve a minimum term of nine years before being eligible for parole.\\n\\nPaul K. Madigan\\nJUDGE\\nAt Lautoka\\n12th October 2011.\\n\\n\\nPacLII: Copyright Policy | Disclaimers | Privacy Policy | Feedback\\nURL: http://www.paclii.org/fj/cases/FJHC/2011/641.html\\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Home | Databases | WorldLII | Search | Feedback\\nHigh Court of Fiji\\nYou are here:\\xa0 PacLII >> Databases >> High Court of Fiji >> 2011 >> [2011] FJHC 641\\n\\nDatabase Search | Name Search | Recent Decisions | Noteup | LawCite | Download | Help\\n\\nState v Ram - Sentence [2011] FJHC 641; HAC033.2010L (12 October 2011) \\nIN THE HIGH COURT OF FIJI\\nAT LAUTOKA\\nCRIMINAL JURISDICTION\\n\\nCRIMINAL CASE NO.: HAC 033 OF 2010L\\n\\nBETWEEN:\\n\\nSTATE\\n\\nAND :\\n\\nFELIX RAM\\n\\nMr F. Lacanivalu for the State\\nMs. V. Tamanisau [LAC] for the Accused\\n\\nDate of Hearing : 11th October, 2011.\\nDate of Sentence : 12th October, 2011.\\n\\nSENTENCE\\n[Child Rape]\\n\\n[1] On the 11th October 2011 the accused entered a plea of guilty to one charge of rape contrary to Section 207(1) & (2) (b) of the Crimes Decree 2009, the particulars being that on the 14th March 2010 at Uciwai settlement, Korolevu he raped a child with his finger. He agreed to facts put to him, whereupon he was found guilty and convicted.\\n\\n[2] The facts admitted by the accused were that in March 2010 he was staying with the victims\\' family, he being related to the victims\\' father. On the 14th March 2010, the mother had left home to visit the father in hospital. She left the victim, who at the time was 9 years old and her elder brother in the care of the accused.\\n\\n[3] After dinner the two children went to sleep on a mattress. The boy asked the accused to sleep on the mattress with them as his mother has not yet returned. The accused blew out the candle and joined them on the mattress. The boy told the victim to lie in the middle between him and the accused. While lying down the accused pulled down the girls\\' panties and used his fingers to indecently invade her. The victim felt pain and tried to push his hand away, however the accused persisted. The next morning the young girl told her mother what had happened. The accused was chased from the house and the Police informed.\\n\\n[4] The maximum penalty for rape is life imprisonment and the Courts have recently been handing down very heavy sentences on offenders against children. Sexual offending against children in this country has become far too prevalent and it is the hope that harsh sentences will send out a clear message to would be perpetrators that our children are to be protected from such unrestrained immorality.\\n\\n[5] In Tamanitoakula HAC 28 of 2010 (Lbs), Thurairaja J passed a sentence of 16 years against an accused convicted of rape of a thirteen year old, as a deterrent punishment.\\n\\n[6] A very similar case to this was in Labasa where a 50 years old raped a nine year old and attracted a sentence of twelve years by Goundar J in Joji Mara HAC 38 of 2010(Lbs).\\n\\n[7] The Court of Appeal has set the starting point for rape of a child to be ten years imprisonment in Drotini AAU0001.2005S.\\n\\n[8] In mitigation, Counsel for the accused tells me that the accused is 57 years old, and while previously a saw miller, he now works as a security guard. He regrets what has happened and when he came to his senses he got up and left the room. He was previously a member of the Catholic Church but now belongs to the Harvest Evangelical Church whose Senior Pastor gave a sworn testimonial in his favour.\\n\\n[9] He produces a letter from the Parish Priest of the Lautoka Catholic Church attesting to his good character.\\n\\n[10] He is asthmatic and intensely remorseful. He would have sought forgiveness from the victim but was unable to because of the strict bail conditions imposed on him.\\n\\n[11] Two of the biggest mitigatory features in his favour are his \"eve of trial\" plea of guilty, and in doing so relieving the victim of having to relive her ordeal.\\n\\n[12] It is an aggravating feature of the case that the accused was in a position of trust, that trust given him by the mother to care for the children in her absence. That trust he abused.\\n\\n[13] I take as a starting point a term of fourteen years imprisonment and for the aggravation of breach of trust I increase that to a term of sixteen years. For the demonstrable remorse and religious mitigation I deduct 2 years. This also includes credit for his clear record. The plea of guilty was entered on the day of trial and will not receive the full credit it could; but I am nevertheless aware of the saving of the young girl giving evidence. He will receive credit for that of three years, meaning that the accused will serve a total term of imprisonment of 11 years.\\n\\n[14] He will serve a minimum term of nine years before being eligible for parole.\\n\\nPaul K. Madigan\\nJUDGE\\nAt Lautoka\\n12th October 2011.\\n\\n\\nPacLII: Copyright Policy | Disclaimers | Privacy Policy | Feedback\\nURL: http://www.paclii.org/fj/cases/FJHC/2011/641.html\\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['contents'][20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>contents</th>\n",
       "      <th>DocID</th>\n",
       "      <th>Customary_Practices</th>\n",
       "      <th>Gender_Stereotypes</th>\n",
       "      <th>Other_Factors</th>\n",
       "      <th>Num_Factors</th>\n",
       "      <th>Discrimination_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80380</td>\n",
       "      <td>Home | Databases | WorldLII | Search | Feedbac...</td>\n",
       "      <td>80380</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78839</td>\n",
       "      <td>Home | Databases | WorldLII | Search | Feedbac...</td>\n",
       "      <td>78839</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>248796</td>\n",
       "      <td>State v Lagivere - Sentence [2017] FJHC 386...</td>\n",
       "      <td>248796</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>257586</td>\n",
       "      <td>State v Goundar - Sentence [2018] FJHC 438;...</td>\n",
       "      <td>257586</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80121</td>\n",
       "      <td>Home | Databases | WorldLII | Search | Feedbac...</td>\n",
       "      <td>80121</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>75927</td>\n",
       "      <td>Home | Databases | WorldLII | Search | Feedbac...</td>\n",
       "      <td>75927</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>247181</td>\n",
       "      <td>State v Khelawan [2016] FJMC 41; Criminal C...</td>\n",
       "      <td>247181</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>271413</td>\n",
       "      <td>Bulivou v State [2014] FJCA 215; AAU78.2010...</td>\n",
       "      <td>271413</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>252935</td>\n",
       "      <td>State v Lal [2015] FJMC 58; Criminal Case 1...</td>\n",
       "      <td>252935</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>274241</td>\n",
       "      <td>Ram v State [2015] FJSC 26; CAV12.2015 (23 ...</td>\n",
       "      <td>274241</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>809 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      docid                                           contents   DocID  \\\n",
       "0     80380  Home | Databases | WorldLII | Search | Feedbac...   80380   \n",
       "1     78839  Home | Databases | WorldLII | Search | Feedbac...   78839   \n",
       "2    248796     State v Lagivere - Sentence [2017] FJHC 386...  248796   \n",
       "3    257586     State v Goundar - Sentence [2018] FJHC 438;...  257586   \n",
       "4     80121  Home | Databases | WorldLII | Search | Feedbac...   80121   \n",
       "..      ...                                                ...     ...   \n",
       "804   75927  Home | Databases | WorldLII | Search | Feedbac...   75927   \n",
       "805  247181     State v Khelawan [2016] FJMC 41; Criminal C...  247181   \n",
       "806  271413     Bulivou v State [2014] FJCA 215; AAU78.2010...  271413   \n",
       "807  252935     State v Lal [2015] FJMC 58; Criminal Case 1...  252935   \n",
       "808  274241     Ram v State [2015] FJSC 26; CAV12.2015 (23 ...  274241   \n",
       "\n",
       "     Customary_Practices  Gender_Stereotypes  Other_Factors  Num_Factors  \\\n",
       "0                      0                   0              1            1   \n",
       "1                      0                   0              1            1   \n",
       "2                      0                   0              0            0   \n",
       "3                      1                   1              0            2   \n",
       "4                      0                   1              0            1   \n",
       "..                   ...                 ...            ...          ...   \n",
       "804                    0                   0              0            0   \n",
       "805                    0                   1              0            1   \n",
       "806                    0                   0              0            0   \n",
       "807                    0                   0              0            0   \n",
       "808                    0                   0              1            1   \n",
       "\n",
       "     Discrimination_Label  \n",
       "0                       1  \n",
       "1                       1  \n",
       "2                       0  \n",
       "3                       1  \n",
       "4                       1  \n",
       "..                    ...  \n",
       "804                     0  \n",
       "805                     1  \n",
       "806                     0  \n",
       "807                     0  \n",
       "808                     1  \n",
       "\n",
       "[809 rows x 8 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another approach\n",
    "https://github.com/saadarshad102/Sentiment-Analysis-CNN/blob/master/Notebook.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "from gensim import models\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Dense, Dropout, Reshape, Flatten, concatenate, Input, Conv1D, GlobalMaxPooling1D, Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import collections\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text_Final</th>\n",
       "      <th>tokens</th>\n",
       "      <th>Discrimination_Label</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>home databases worldlii search feedback high c...</td>\n",
       "      <td>[home, databases, worldlii, search, feedback, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>home databases worldlii search feedback high c...</td>\n",
       "      <td>[home, databases, worldlii, search, feedback, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>state v lagivere sentence 2017 fjhc 386 hac132...</td>\n",
       "      <td>[state, v, lagivere, sentence, 2017, fjhc, 386...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>state v goundar sentence 2018 fjhc 438 hac1762...</td>\n",
       "      <td>[state, v, goundar, sentence, 2018, fjhc, 438,...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>home databases worldlii search feedback high c...</td>\n",
       "      <td>[home, databases, worldlii, search, feedback, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Text_Final  \\\n",
       "0  home databases worldlii search feedback high c...   \n",
       "1  home databases worldlii search feedback high c...   \n",
       "2  state v lagivere sentence 2017 fjhc 386 hac132...   \n",
       "3  state v goundar sentence 2018 fjhc 438 hac1762...   \n",
       "4  home databases worldlii search feedback high c...   \n",
       "\n",
       "                                              tokens  Discrimination_Label  \\\n",
       "0  [home, databases, worldlii, search, feedback, ...                     1   \n",
       "1  [home, databases, worldlii, search, feedback, ...                     1   \n",
       "2  [state, v, lagivere, sentence, 2017, fjhc, 386...                     0   \n",
       "3  [state, v, goundar, sentence, 2018, fjhc, 438,...                     1   \n",
       "4  [home, databases, worldlii, search, feedback, ...                     1   \n",
       "\n",
       "   Pos  Neg  \n",
       "0    1    0  \n",
       "1    1    0  \n",
       "2    0    1  \n",
       "3    1    0  \n",
       "4    1    0  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = []\n",
    "neg = []\n",
    "for l in df.Discrimination_Label:\n",
    "    if l == 0:\n",
    "        pos.append(0)\n",
    "        neg.append(1)\n",
    "    elif l == 1:\n",
    "        pos.append(1)\n",
    "        neg.append(0)\n",
    "df['Pos']= pos\n",
    "df['Neg']= neg\n",
    "\n",
    "data = df[['Text_Final', 'tokens', 'Discrimination_Label', 'Pos', 'Neg']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean dataimport re\n",
    "punc = '!\"#$%&''()*+,-./:;<=>?@[\\]^_`{|}~'\n",
    "import re\n",
    "\n",
    "def remove_punct(text):\n",
    "    text_nopunct = ''\n",
    "    text_nopunct = re.sub('['+punc+']', '', text)\n",
    "    return text_nopunct\n",
    "df['Text_Clean'] = df['contents'].apply(lambda x: remove_punct(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/chris/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "nltk.download('punkt')\n",
    "tokens = [word_tokenize(sen) for sen in df.Text_Clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_token(tokens): \n",
    "    return [w.lower() for w in tokens]    \n",
    "    \n",
    "lower_tokens = [lower_token(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct(text):\n",
    "    text_nopunct = ''\n",
    "    text_nopunct = re.sub('['+string.punctuation+']', '', text)\n",
    "    return text_nopunct\n",
    "\n",
    "df['Text_Clean'] = df['contents'].apply(lambda x: remove_punct(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, WordNetLemmatizer\n",
    "tokens = [word_tokenize(sen) for sen in df.Text_Clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_token(tokens): \n",
    "    return [w.lower() for w in tokens]    \n",
    "    \n",
    "lower_tokens = [lower_token(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stoplist = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(tokens): \n",
    "    return [word for word in tokens if word not in stoplist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_words = [remove_stop_words(sen) for sen in lower_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [' '.join(sen) for sen in filtered_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text_Final'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'] = filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[['Text_Final', 'tokens', 'Discrimination_Label', 'Pos', 'Neg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text_Final</th>\n",
       "      <th>tokens</th>\n",
       "      <th>Discrimination_Label</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>home databases worldlii search feedback high c...</td>\n",
       "      <td>[home, databases, worldlii, search, feedback, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>home databases worldlii search feedback high c...</td>\n",
       "      <td>[home, databases, worldlii, search, feedback, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>state v lagivere sentence 2017 fjhc 386 hac132...</td>\n",
       "      <td>[state, v, lagivere, sentence, 2017, fjhc, 386...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>state v goundar sentence 2018 fjhc 438 hac1762...</td>\n",
       "      <td>[state, v, goundar, sentence, 2018, fjhc, 438,...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Text_Final  \\\n",
       "0  home databases worldlii search feedback high c...   \n",
       "1  home databases worldlii search feedback high c...   \n",
       "2  state v lagivere sentence 2017 fjhc 386 hac132...   \n",
       "3  state v goundar sentence 2018 fjhc 438 hac1762...   \n",
       "\n",
       "                                              tokens  Discrimination_Label  \\\n",
       "0  [home, databases, worldlii, search, feedback, ...                     1   \n",
       "1  [home, databases, worldlii, search, feedback, ...                     1   \n",
       "2  [state, v, lagivere, sentence, 2017, fjhc, 386...                     0   \n",
       "3  [state, v, goundar, sentence, 2018, fjhc, 438,...                     1   \n",
       "\n",
       "   Pos  Neg  \n",
       "0    1    0  \n",
       "1    1    0  \n",
       "2    0    1  \n",
       "3    1    0  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into test and train¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = train_test_split(data, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "649906 words total, with a vocabulary size of 20902\n",
      "Max sentence length is 15937\n"
     ]
    }
   ],
   "source": [
    "#build training vocabulary and get maximum training document length and total number of words training data\n",
    "all_training_words = [word for tokens in data_train[\"tokens\"] for word in tokens]\n",
    "training_sentence_lengths = [len(tokens) for tokens in data_train[\"tokens\"]]\n",
    "TRAINING_VOCAB = sorted(list(set(all_training_words)))\n",
    "print(\"%s words total, with a vocabulary size of %s\" % (len(all_training_words), len(TRAINING_VOCAB)))\n",
    "print(\"Max sentence length is %s\" % max(training_sentence_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72804 words total, with a vocabulary size of 7036\n",
      "Max sentence length is 4062\n"
     ]
    }
   ],
   "source": [
    "#build testing vocabulary and get maximum testing document length and total number of words in testing data\n",
    "all_test_words = [word for tokens in data_test[\"tokens\"] for word in tokens]\n",
    "test_sentence_lengths = [len(tokens) for tokens in data_test[\"tokens\"]]\n",
    "TEST_VOCAB = sorted(list(set(all_test_words)))\n",
    "print(\"%s words total, with a vocabulary size of %s\" % (len(all_test_words), len(TEST_VOCAB)))\n",
    "print(\"Max sentence length is %s\" % max(test_sentence_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Google News Word2Vec model\n",
    "word2vec_path = 'GoogleNews-vectors-negative300.bin.gz'\n",
    "word2vec = models.KeyedVectors.load_word2vec_format(word2vec_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_word2vec(tokens_list, vector, generate_missing=False, k=300):\n",
    "    if len(tokens_list)<1:\n",
    "        return np.zeros(k)\n",
    "    if generate_missing:\n",
    "        vectorized = [vector[word] if word in vector else np.random.rand(k) for word in tokens_list]\n",
    "    else:\n",
    "        vectorized = [vector[word] if word in vector else np.zeros(k) for word in tokens_list]\n",
    "    length = len(vectorized)\n",
    "    summed = np.sum(vectorized, axis=0)\n",
    "    averaged = np.divide(summed, length)\n",
    "    return averaged\n",
    "\n",
    "def get_word2vec_embeddings(vectors, clean_comments, generate_missing=False):\n",
    "    embeddings = clean_comments['tokens'].apply(lambda x: get_average_word2vec(x, vectors, \n",
    "                                                                                generate_missing=generate_missing))\n",
    "    return list(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_embeddings = get_word2vec_embeddings(word2vec, data_train, generate_missing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 50\n",
    "EMBEDDING_DIM = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize and Pad sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20903 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=len(TRAINING_VOCAB), lower=True, char_level=False)\n",
    "tokenizer.fit_on_texts(data_train[\"Text_Final\"].tolist())\n",
    "training_sequences = tokenizer.texts_to_sequences(data_train[\"Text_Final\"].tolist())\n",
    "\n",
    "train_word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(train_word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cnn_data = pad_sequences(training_sequences, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20904, 300)\n"
     ]
    }
   ],
   "source": [
    "train_embedding_weights = np.zeros((len(train_word_index)+1, EMBEDDING_DIM))\n",
    "for word,index in train_word_index.items():\n",
    "    train_embedding_weights[index,:] = word2vec[word] if word in word2vec else np.random.rand(EMBEDDING_DIM)\n",
    "print(train_embedding_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = tokenizer.texts_to_sequences(data_test[\"Text_Final\"].tolist())\n",
    "test_cnn_data = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvNet(embeddings, max_sequence_length, num_words, embedding_dim, labels_index):\n",
    "    \n",
    "    embedding_layer = Embedding(num_words,\n",
    "                            embedding_dim,\n",
    "                            weights=[embeddings],\n",
    "                            input_length=max_sequence_length,\n",
    "                            trainable=False)\n",
    "    \n",
    "    sequence_input = Input(shape=(max_sequence_length,), dtype='int32')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "    convs = []\n",
    "    filter_sizes = [2,3,4,5,6]\n",
    "\n",
    "    for filter_size in filter_sizes:\n",
    "        l_conv = Conv1D(filters=200, kernel_size=filter_size, activation='relu')(embedded_sequences)\n",
    "        l_pool = GlobalMaxPooling1D()(l_conv)\n",
    "        convs.append(l_pool)\n",
    "\n",
    "\n",
    "    l_merge = concatenate(convs, axis=1)\n",
    "\n",
    "    x = Dropout(0.1)(l_merge)  \n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    preds = Dense(labels_index, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(sequence_input, preds)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['acc'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = ['Pos', 'Neg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = data_train[label_names].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_cnn_data\n",
    "y_tr = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 50, 300)      6271200     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 49, 200)      120200      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 48, 200)      180200      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 47, 200)      240200      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 46, 200)      300200      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 45, 200)      360200      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 200)          0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 200)          0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 200)          0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_4 (GlobalM (None, 200)          0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_5 (GlobalM (None, 200)          0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1000)         0           global_max_pooling1d_1[0][0]     \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "                                                                 global_max_pooling1d_3[0][0]     \n",
      "                                                                 global_max_pooling1d_4[0][0]     \n",
      "                                                                 global_max_pooling1d_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1000)         0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          128128      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            258         dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 7,600,586\n",
      "Trainable params: 1,329,386\n",
      "Non-trainable params: 6,271,200\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = ConvNet(train_embedding_weights, MAX_SEQUENCE_LENGTH, len(train_word_index)+1, EMBEDDING_DIM, \n",
    "                len(list(label_names)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 3\n",
    "batch_size = 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 655 samples, validate on 73 samples\n",
      "Epoch 1/3\n",
      "655/655 [==============================] - 2s 3ms/step - loss: 0.8761 - acc: 0.5321 - val_loss: 0.6456 - val_acc: 0.6164\n",
      "Epoch 2/3\n",
      "655/655 [==============================] - 1s 2ms/step - loss: 0.6528 - acc: 0.6145 - val_loss: 0.6397 - val_acc: 0.6644\n",
      "Epoch 3/3\n",
      "655/655 [==============================] - 1s 2ms/step - loss: 0.6345 - acc: 0.6153 - val_loss: 0.6672 - val_acc: 0.6027\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train, y_tr, epochs=num_epochs, validation_split=0.1, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "81/81 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_cnn_data, batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_labels=[]\n",
    "for p in predictions:\n",
    "    prediction_labels.append(labels[np.argmax(p)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.691358024691358"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(data_test.Discrimination_Label==prediction_labels)/len(prediction_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    51\n",
       "0    30\n",
       "Name: Discrimination_Label, dtype: int64"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.Discrimination_Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "w266",
   "language": "python",
   "name": "w266"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
