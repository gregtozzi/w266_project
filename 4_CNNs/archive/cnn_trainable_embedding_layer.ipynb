{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN with a Trainable Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ktrain\n",
    "from ktrain import text\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build test and training sets & define preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_WORDS = 50000\n",
    "MAXLEN = 5000\n",
    "NGRAM_RANGE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, preproc = text.texts_from_csv('../data/train_80_10_10.csv',\n",
    "                                          'cleaned_contents',\n",
    "                                          label_columns=['Discrimination_Label'],\n",
    "                                          val_filepath='../data/test_80_10_10.csv',\n",
    "                                          max_features=NUM_WORDS,\n",
    "                                          maxlen=MAXLEN,\n",
    "                                          ngram_range=NGRAM_RANGE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _build_cnn(maxlen, max_features, embed_dim, filters, kernels,\n",
    "               dropout=0.1,\n",
    "               loss_func='categorical_crossentropy',\n",
    "               activation = 'softmax', metrics=['accuracy'],\n",
    "               verbose=1, optimizer='adam'):\n",
    "    \n",
    "    embedding_matrix = np.ones((max_features, 1))\n",
    "    embedding_matrix[0] = 0\n",
    "\n",
    "    # set up the model\n",
    "    inp = tf.keras.layers.Input(shape=(maxlen,))\n",
    "    x = tf.keras.layers.Embedding(max_features, embed_dim, input_length=maxlen, \n",
    "                                  trainable=True)(inp)\n",
    "    x0 = tf.keras.layers.Conv1D(filters=filters,\n",
    "                               kernel_size=kernels[0],\n",
    "                               activation='relu')(x)\n",
    "    x0 = tf.keras.layers.MaxPool1D(pool_size=maxlen - kernels[0] + 1)(x0)\n",
    "\n",
    "    x1 = tf.keras.layers.Conv1D(filters=filters,\n",
    "                                kernel_size=kernels[1],\n",
    "                                activation='relu')(x)\n",
    "    x1 = tf.keras.layers.MaxPool1D(pool_size=maxlen - kernels[1] + 1)(x1)\n",
    "    \n",
    "    x2 = tf.keras.layers.Conv1D(filters=filters,\n",
    "                                kernel_size=kernels[2],\n",
    "                                activation='relu')(x)\n",
    "    x2 = tf.keras.layers.MaxPool1D(pool_size=maxlen - kernels[2] + 1)(x2)\n",
    "    \n",
    "    x3 = tf.keras.layers.Conv1D(filters=filters,\n",
    "                                kernel_size=kernels[3],\n",
    "                                activation='relu')(x)\n",
    "    x3 = tf.keras.layers.MaxPool1D(pool_size=maxlen - kernels[3] + 1)(x3)\n",
    "\n",
    "    x4 = tf.keras.layers.Conv1D(filters=filters,\n",
    "                                kernel_size=kernels[4],\n",
    "                                activation='relu')(x)\n",
    "    x4 = tf.keras.layers.MaxPool1D(pool_size=maxlen - kernels[4] + 1)(x4)\n",
    "\n",
    "    x = tf.keras.layers.concatenate([x0, x1, x2, x3, x4])\n",
    "\n",
    "    x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(dropout)(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    outputs = tf.keras.layers.Dense(2, activation=activation)(x)\n",
    "    model = tf.keras.Model(inputs=inp, outputs=outputs)\n",
    "    model.compile(loss=loss_func,\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = _build_cnn(5000, 50000, 100, filters=32, kernels=[2, 3, 4, 5, 6], dropout=0.4)\n",
    "learner = ktrain.get_learner(model, train_data=train, val_data=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find a good initial learning rate\n",
    "\n",
    "This is a method that was developed at the Naval Research Laboratory.  It's been promoted by Jeremy Howard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.lr_find(show_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.autofit(0.001, early_stopping=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.validate(class_names=preproc.get_classes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "X_test = pd.read_csv('../data/test.csv')['cleaned_contents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = ktrain.get_predictor(learner.model, preproc=preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.explain('As the perpetrator is the sole breadwinner for his family, I reduce his sentence by two years.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
