{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN with a loya2Vec Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ktrain\n",
    "from ktrain import text\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from gensim.models import Word2Vec\n",
    "from gensim import utils\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from random import sample\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute custom Word2Vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_WORDS = 33000\n",
    "MAXLEN = 5000\n",
    "DIMS = 300\n",
    "NGRAM_RANGE = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to do the heavy lifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_corpus(corpus_path, text_column='contents', max_features=33000, maxlen=5000, class_names=[0,1]):\n",
    "    \"\"\"\n",
    "    Takes a corpus of texts stored in a csv file and processes them\n",
    "    through ktrain's preprocessor in preparation for using them in\n",
    "    gensim's Word2Vec model.\n",
    "    \"\"\"\n",
    "    preproc = ktrain.text.preprocessor.StandardTextPreprocessor(max_features=max_features,\n",
    "                                                                maxlen=maxlen,\n",
    "                                                                class_names=class_names)\n",
    "    full_corpus = pd.read_csv(corpus_path)\n",
    "    full_corpus_text = full_corpus[text_column]\n",
    "    dummy_labels = np.zeros(len(full_corpus_text))\n",
    "    X, dummy_y = preproc.preprocess_train(full_corpus_text, dummy_labels)\n",
    "    X = list(X)\n",
    "    corpus = [preproc.undo(doc).split(' ') for doc in X]\n",
    "    return preproc, corpus\n",
    "\n",
    "\n",
    "def build_wv_model(corpus, dims, save_path=None, workers=8):\n",
    "    \"\"\"\n",
    "    Builds, returns, and saves the Word2Vec-like model developed\n",
    "    from the corpus returned by preprocess_corpus.\n",
    "    \"\"\"\n",
    "    WV = Word2Vec(sentences=corpus, size=dims, workers=8)\n",
    "    vocab = WV.wv.index2word\n",
    "    vocab_len = len(vocab)\n",
    "    embeddings = np.array([WV.wv.get_vector(word) for word in vocab])\n",
    "    text_to_token = {word: i for word, i in zip(vocab, range(vocab_len))}\n",
    "    token_to_text = {i: word for word, i in zip(vocab, range(vocab_len))}\n",
    "    model = {'embeddings': embeddings,\n",
    "             'text_to_token': text_to_token,\n",
    "             'token_to_text': token_to_text,\n",
    "             'vocab': vocab,\n",
    "             'vocab_len': len(vocab)}\n",
    "    if save_path is not None:\n",
    "        with open(save_path, 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "    return model\n",
    "\n",
    "\n",
    "def embed_word(word, wv_model, dims):\n",
    "    if word in wv_model['vocab']:\n",
    "        token = wv_model['text_to_token'][word]\n",
    "        return wv_model['embeddings'][token]\n",
    "    else:\n",
    "        return np.zeros(dims)\n",
    "    \n",
    "\n",
    "def build_embeddings(preproc, wv_model, dims):\n",
    "    preproc_vocab = preproc.undo(range(NUM_WORDS)).split(' ')\n",
    "    Embeddings = [embed_word(word, wv_model, dims) for word in preproc_vocab]\n",
    "    Embeddings = np.stack(Embeddings)\n",
    "    return(Embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the full 13K document corpus using the ktrain preprocessor - This takes some time\n",
    "\n",
    "Using the ktrain preprocessor on the front end ensures that the tokens that are fed to GENSIM to create the embeddings are as close to the same as will be used as input to the model as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "language: en\n",
      "Word Counts: 132011\n",
      "Nrows: 13384\n",
      "13384 train sequences\n",
      "train sequence lengths:\n",
      "\tmean : 2218\n",
      "\t95percentile : 5989\n",
      "\t99percentile : 11259\n",
      "x_train shape: (13384,5000)\n",
      "y_train shape: (13384, 1)\n",
      "Is Multi-Label? False\n",
      "CPU times: user 5min 23s, sys: 2.63 s, total: 5min 26s\n",
      "Wall time: 5min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preproc, corpus = preprocess_corpus('../data/ICAAD_FIJI.csv', max_features=NUM_WORDS, maxlen=MAXLEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 49s, sys: 2.89 s, total: 9min 52s\n",
      "Wall time: 1min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "wv_model = build_wv_model(corpus, DIMS, save_path='./loya2Vec/loya2Vec.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.5 s, sys: 24 ms, total: 21.5 s\n",
      "Wall time: 21.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Embeddings = build_embeddings(preproc, wv_model, DIMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "90% of the challenge here is to map the embeddings properly between the Word2Vec model and the ktrain preprocessor.  The following is currently necessary, but is likely patching an error above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Embeddings = np.zeros(Embeddings.shape)\n",
    "\n",
    "for i in range(33000):\n",
    "    proc_word = preproc.tok.sequences_to_texts([[i]])\n",
    "    try:\n",
    "        wv_token = wv_model['text_to_token'][proc_word[0]]\n",
    "        model_Embeddings[i] = wv_model['embeddings'][wv_token]\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_neighbors(embedding_model, text):\n",
    "    \"\"\"\n",
    "    Takes a trained embedding model and input text and returns\n",
    "    the closest five neighbors to the text in the model.\n",
    "    \"\"\"\n",
    "    text_token = embedding_model['text_to_token'][text]\n",
    "    closest_embeddings = cosine_similarity(embedding_model['embeddings'][text_token].reshape(1,-1),\n",
    "                                           embedding_model['embeddings']).argsort()\n",
    "    print(closest_embeddings)\n",
    "    return [embedding_model['token_to_text'][token] for token in closest_embeddings[0][-5:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_neighbors(preproc, embeddings, text):\n",
    "    \"\"\"\n",
    "    Takes a trained embedding model and input text and returns\n",
    "    the closest five neighbors to the text in the model.\n",
    "    \"\"\"\n",
    "    text_token = preproc.tok.texts_to_sequences([text])[0][0]\n",
    "    closest_embeddings = cosine_similarity(embeddings[text_token].reshape(1,-1),\n",
    "                                           embeddings).argsort()\n",
    "    print(closest_embeddings)\n",
    "    return [preproc.tok.sequences_to_texts([[token]]) for token in closest_embeddings[0][-5:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the embeddings are functioning properly.  Yes, feeding this thing English profanity returns Fijian profanity.  I have arrived as a data scientist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1780 6530 2986 ... 5100 6510 5271]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['eldest'], ['ilisavani'], ['bread'], ['winner'], ['breadwinner']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest_neighbors(preproc, model_Embeddings, 'breadwinner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 934   18 3623 ...  386  769  128]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['nasinu'], ['nausori'], ['lautoka'], ['labasa'], ['suva']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest_neighbors(preproc, model_Embeddings, 'suva')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19214 14388 13032 ...  2724   324   394]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[\"complainant's\"], ['girl'], [\"victim's\"], ['complainant'], ['victim']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest_neighbors(preproc, model_Embeddings, 'victim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2801  175   96 ... 6275 8920 3821]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['auckland'], ['perth'], ['melbourne'], ['brisbane'], ['sydney']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest_neighbors(preproc, model_Embeddings, 'sydney')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = pd.read_csv('../data/train_80_10_10.csv')\n",
    "x_train = Train.cleaned_contents\n",
    "y_train = Train.Discrimination_Label\n",
    "\n",
    "Test = pd.read_csv('../data/val_80_10_10.csv')\n",
    "x_test = Test.cleaned_contents\n",
    "y_test = Test.Discrimination_Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "647 test sequences\n",
      "test sequence lengths:\n",
      "\tmean : 1491\n",
      "\t95percentile : 3900\n",
      "\t99percentile : 7614\n",
      "x_test shape: (647,5000)\n",
      "y_test shape: (647, 2)\n",
      "81 test sequences\n",
      "test sequence lengths:\n",
      "\tmean : 1514\n",
      "\t95percentile : 4159\n",
      "\t99percentile : 5506\n",
      "x_test shape: (81,5000)\n",
      "y_test shape: (81, 2)\n"
     ]
    }
   ],
   "source": [
    "train = preproc.preprocess_test(x_train, y_train)\n",
    "test = preproc.preprocess_test(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _build_cnn(maxlen, max_features, embed_dim, filters, kernels,\n",
    "               embeddings, dropout=0.1, density=64,\n",
    "               loss_func='categorical_crossentropy',\n",
    "               activation = 'softmax', metrics=['accuracy'],\n",
    "               verbose=1, optimizer='adam'):\n",
    "    \n",
    "    embedding_matrix = np.ones((max_features, 1))\n",
    "    embedding_matrix[0] = 0\n",
    "\n",
    "    # set up the model\n",
    "    inp = tf.keras.layers.Input(shape=(maxlen,))\n",
    "    x = tf.keras.layers.Embedding(max_features, embed_dim, input_length=maxlen, \n",
    "                                  trainable=False)(inp)\n",
    "    x0 = tf.keras.layers.Conv1D(filters=filters,\n",
    "                               kernel_size=kernels[0],\n",
    "                               activation='relu')(x)\n",
    "    x0 = tf.keras.layers.MaxPool1D(pool_size=maxlen - kernels[0] + 1)(x0)\n",
    "\n",
    "    x1 = tf.keras.layers.Conv1D(filters=filters,\n",
    "                                kernel_size=kernels[1],\n",
    "                                activation='relu')(x)\n",
    "    x1 = tf.keras.layers.MaxPool1D(pool_size=maxlen - kernels[1] + 1)(x1)\n",
    "    \n",
    "    x2 = tf.keras.layers.Conv1D(filters=filters,\n",
    "                                kernel_size=kernels[2],\n",
    "                                activation='relu')(x)\n",
    "    x2 = tf.keras.layers.MaxPool1D(pool_size=maxlen - kernels[2] + 1)(x2)\n",
    "    \n",
    "    x3 = tf.keras.layers.Conv1D(filters=filters,\n",
    "                                kernel_size=kernels[3],\n",
    "                                activation='relu')(x)\n",
    "    x3 = tf.keras.layers.MaxPool1D(pool_size=maxlen - kernels[3] + 1)(x3)\n",
    "\n",
    "    x4 = tf.keras.layers.Conv1D(filters=filters,\n",
    "                                kernel_size=kernels[4],\n",
    "                                activation='relu')(x)\n",
    "    x4 = tf.keras.layers.MaxPool1D(pool_size=maxlen - kernels[4] + 1)(x4)\n",
    "\n",
    "    x = tf.keras.layers.concatenate([x0, x1, x2, x3, x4])\n",
    "\n",
    "    x = tf.keras.layers.Dense(density, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(dropout)(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    outputs = tf.keras.layers.Dense(2, activation=activation)(x)\n",
    "    model = tf.keras.Model(inputs=inp, outputs=outputs)\n",
    "    model.compile(loss=loss_func,\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=metrics)\n",
    "    \n",
    "    model.layers[1].set_weights([embeddings])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = _build_cnn(MAXLEN, len(model_Embeddings), DIMS, filters=32, kernels=[2, 3, 4, 5, 6], embeddings=model_Embeddings, dropout=0.4, density=64)\n",
    "learner = ktrain.get_learner(model, train_data=train, val_data=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 5000)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 5000, 300)    9899700     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 4999, 32)     19232       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 4998, 32)     28832       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 4997, 32)     38432       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 4996, 32)     48032       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 4995, 32)     57632       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 1, 32)        0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 1, 32)        0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 1, 32)        0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 1, 32)        0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 1, 32)        0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1, 160)       0           max_pooling1d[0][0]              \n",
      "                                                                 max_pooling1d_1[0][0]            \n",
      "                                                                 max_pooling1d_2[0][0]            \n",
      "                                                                 max_pooling1d_3[0][0]            \n",
      "                                                                 max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1, 64)        10304       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1, 64)        0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 64)           0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            130         flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 10,102,294\n",
      "Trainable params: 202,594\n",
      "Non-trainable params: 9,899,700\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "learner.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sure the pre-trained embeddings are in place, fixed, and functioning properly in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((learner.model.layers[1].weights[0].numpy() == model_Embeddings) - 1).sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_output = tf.keras.backend.function(model.layers[0].input, model.layers[1].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_doc = train[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([104,   1, 186,  32, 674,   3, 251,  80, 743, 513], dtype=int32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_doc[4600:4610]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['whether the parties are known to each other • considering']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc.tok.sequences_to_texts([[104,   1, 186,  32, 674,   3, 251,  80, 743, 513]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((embedding_output([[104]]) == model_Embeddings[104]) - 1).sum() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a fairly long winded way to get to yes, but getting the embeddings to map properly between gensim and ktrain was a serious pain point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find a good initial learning rate\n",
    "\n",
    "This is a method that was developed at the Naval Research Laboratory.  It's been promoted by Jeremy Howard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulating training for different learning rates... this may take a few moments...\n",
      "Train on 647 samples\n",
      "Epoch 1/10\n",
      "647/647 [==============================] - 5s 8ms/sample - loss: 3.3090 - accuracy: 0.4714\n",
      "Epoch 2/10\n",
      "647/647 [==============================] - 3s 4ms/sample - loss: 3.1023 - accuracy: 0.4838\n",
      "Epoch 3/10\n",
      "647/647 [==============================] - 3s 4ms/sample - loss: 3.1639 - accuracy: 0.4776\n",
      "Epoch 4/10\n",
      "647/647 [==============================] - 3s 4ms/sample - loss: 2.8976 - accuracy: 0.4730\n",
      "Epoch 5/10\n",
      "647/647 [==============================] - 3s 4ms/sample - loss: 1.5085 - accuracy: 0.5703\n",
      "Epoch 6/10\n",
      "647/647 [==============================] - 3s 4ms/sample - loss: 0.6921 - accuracy: 0.6167\n",
      "Epoch 7/10\n",
      "647/647 [==============================] - 3s 4ms/sample - loss: 2.6796 - accuracy: 0.5425\n",
      "Epoch 8/10\n",
      "647/647 [==============================] - 3s 5ms/sample - loss: 5.1054 - accuracy: 0.5688\n",
      "Epoch 9/10\n",
      "647/647 [==============================] - 3s 4ms/sample - loss: 7.0573 - accuracy: 0.5518\n",
      "Epoch 10/10\n",
      "647/647 [==============================] - 3s 5ms/sample - loss: 0.8896 - accuracy: 0.5286\n",
      "\n",
      "\n",
      "done.\n",
      "Visually inspect loss plot and select learning rate associated with falling loss\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3zU9f3A8dc7GzKYYSSMsBEZASIIOMCJiqJ14BZFcY9fW1ttq23t1tZqtQ6cYF0VF4qiWEVQZtgbAdkrhJFNkrv374/7JsSYhCTc9+5yeT8fj3tw973Pfb/vS8i977NFVTHGGGMAIoIdgDHGmNBhScEYY0w5SwrGGGPKWVIwxhhTzpKCMcaYcpYUjDHGlIsKdgB11bp1a01LSwt2GMYY06AsXrx4v6omH6tcg0sKaWlpZGZmBjsMY4xpUERka23KWfORMcaYcpYUjDHGlLOkYIwxppwlBWOMMeUsKRhjjClnScEYY0w5SwrGGFMHe3OKyMo9EuwwXGNJwRhj6uBn/13Obf9ZHOwwXGNJwRhj6iCnqITFWw+y81BhsENxhSUFY4ypA4/Xt1vljFV7ghyJOywpGGNMHZQlhU9X7g5yJO5wNSmIyBYRWSkiy0TkRwsWic+/RGSjiKwQkUFuxmOMMcfL6+xrn7n1IHsOFwU5Gv8LRE1hlKqmq2pGFc+dB/RwbhOBZwMQjzHG1JvHq/RqmwjAZ6vDrwkp2M1HY4Ep6jMfaC4i7YMckzHGVEsVerRNoGfbBD4JwyYkt5OCAp+LyGIRmVjF86nA9gqPdzjHjDEmJHlUiYwQzuvbnoVbDoTdnAW3k8IpqjoIXzPRnSJyWn1OIiITRSRTRDKzsrL8G6ExxtSBx6tEinB+v/aohl8TkqtJQVV3Ov/uA94HhlQqshPoWOFxB+dY5fNMUtUMVc1ITj7mxkHGGOMar1eJiBB6tk2ga3I801eEVxOSa0lBROJFJLHsPnAOsKpSsWnA9c4opJOBw6oaXj9hY0xY8aivpiAiXJyeyrzN2WzclxfssPzGzZpCW+AbEVkOLASmq+oMEblNRG5zynwCbAY2Ai8Ad7gYjzHGHDePFyIiBICrh3YiJiqCV+d+H+So/Me1PZpVdTMwoIrjz1W4r8CdbsVgjDH+5lUl0vk63TohlovTU3h38U5+fk4vmjeNCW5wfhDsIanGGNOglHU0l7lxRBcKSzxMXbwjiFH5jyUFY4ypA69qefMRwAntk+iX2oyPlu8KYlT+Y0nBGGPqwOtVIirUFAAuHNCe5TsOszU7P0hR+Y8lBWOMqYOyyWsVXdA/BYCPw2B4qiUFY4ypA6+XH9UUUps3IaNzi7BoQrKkYIwxdeCpMPqoogsHpLBuTy4b9uYGPig/sqRgjDF1UHn0UZnz+rUjQuDjBl5bsKRgjDG15HU22ImI+HFSaJMYx7BurZi2fBfq7LnQEFlSMMaYWvI4H/ZV1RQALuyfwpbsAlbtzAlkWH5lScEYY2rJU0NNAWB033ZERwofLvvRup4NhiUFY4yppbJWocpDUss0bxrDyF5t+GDZLko93gBG5j+WFIwxppbKmo+qyQkAXDa4A/vzjjDnu/0Bisq/LCkYY0wtlTcfVdOnADCqVxtaNI1m6pKGuRaSJQVjjKmlstFH1TUfAcRERTA2PZWZq/c2yK06LSkYY0wtlY8+qqn9CLh+WGcU5c+frA1EWH5lScEYY2rJW4vmI4CuyQncfno33l+6k28aWN+CJQVjjKml2tYUAO4Y1Z1OLZvy98/Xux2WX1lSMMaYWirraK5u8lpFcdGRXHtyJ5ZtP8SmrIazh7PrSUFEIkVkqYh8XMVz40UkS0SWObeb3Y7HGGPqq2yeQnWT1yq7OD2VyAjh3Qa0K1sgagr3AjX1trytqunO7cUAxGOMMfVSXlOo5Sdnm6Q4TuvRmveX7ix/bahzNSmISAfgAsA+7I0xDd7RyWu1qykAXDq4A7sPFzF3U8PocHa7pvAE8Augpvnel4rIChGZKiIdXY7HGGPqrbajjyo664S2JMVFNZgmJNeSgoiMAfap6uIain0EpKlqf2AmMLmac00UkUwRyczKynIhWmOMOba6jD4qExcdyYUDUpixeg+5RSVuheY3btYURgAXicgW4C3gDBH5T8UCqpqtqmVT/l4EBld1IlWdpKoZqpqRnJzsYsjGGFO92ixzUZVLB3egqMTLJytDfw9n15KCqj6oqh1UNQ24EvhSVa+tWEZE2ld4eBE1d0gbY0xQeZ2G8LrUFAAGdmxO19bxTG0ATUgBn6cgIo+IyEXOw3tEZLWILAfuAcYHOh5jjKmto81HdXudiHB5RkcWbTkY8nMWApIUVHWWqo5x7j+sqtOc+w+q6omqOkBVR6nqukDEY4wx9VHf5iOASwf75iz8d9F2f4flVzaj2Rhjaknr0dFcpk1iHGf2bsPUxTsoLg3dDXgsKRhjTC0dT00B4KohncjOL+Z/a/f6Myy/sqRgjDG1VJ/JaxWd1jOZ9s3ieCuEm5AsKRhjTC3Vd/RRmcgIX4fz7O+y2HGwwI+R+Y8lBWOMqaX6jj6q6IqMDgC8kxmaw1MtKRhjTC3VZ5mLyjq0aMqpPZJ5J3N7SC6SZ0nBGGNqyVOLPZpr48qTOrLrcBGzvwu9ZXssKRhjTC0db0dzmbNOaEur+BjeXhh6Hc6WFIwxppaOZ55CRTFREVw6uANfrN1LVu6RY78ggCwpGGNMLXmOc/RRReNO6kipV3lncWjVFiwpGGNMLR1tPjr+c3VLTuDkri15ff62kOpwtqRgjDG15I/RRxWNH57GzkOFfBFCM5wtKRhjTC35a/RRmbNOaEtKszgmz93il/P5gyUFY4zf7DpUyNmPf82Nryzk89V7gh2O3/lr9FGZqMgIrh3WmbmbstmwN9cv5zxelhSMMX6zfk8u3+3LY8m2Q9zz1lIO5BcHOyS/8vq5pgBw5UmdiImKCJnagiUFY4zfFJZ4APjTJX0pKvHyaoh80PlLffZoPpaW8TFcNCCF95bs5HBh8PdwtqRgjPGbwmJfUuiX2oyzTmjLlHlbyD9SGtyg/MjfHc1lxg9Po7DEwzuZwR+eaknBGOM3ZTWFJtGR3D6yG4cKSkLig85fykaO+rOmANA3tRmDO7fgtflbyxNPsLieFEQkUkSWisjHVTwXKyJvi8hGEVkgImlux2OMcU+RkxTiYiIZ3LkFAzo2Z8q84H/Q+Uv56CM/1xQAbhiextbsAmZt2Of3c9dFIGoK9wJrq3luAnBQVbsD/wT+FoB4jDEuKWs+ahIdCcD44Z3ZvD+fORv3BzMsv/E6fQriwifneX3b0SYxllfnbvX/yevA1aQgIh2AC4AXqykyFpjs3J8KnCniQgo2xgREYYmH6Egh2tlw4Px+7WmdEMOr334f5Mj8w82aQnRkBNcM7czsDVlsysrz+/lry+2awhPAL4DqdqlOBbYDqGopcBhoVbmQiEwUkUwRyczKCr2lZo0xPgXFHuKcWgJAbFQkNwxL46v1WXy9oeH/7box+qiiq4Z2JDpSeG1e8GoLriUFERkD7FPVxcd7LlWdpKoZqpqRnJzsh+iMMW4oKvGUNx2VueW0rnRvk8AD764gpyj4Qy6Ph1ujj8q0SYzjgn7tmbp4B3lBGrXlZk1hBHCRiGwB3gLOEJH/VCqzE+gIICJRQDMg28WYjDEuKizx0CTmh0khLjqSxy7rz96cIh6bsT5IkfmHP1dJrc4Nw9PIO1LKu4uDs12na0lBVR9U1Q6qmgZcCXypqtdWKjYNuMG5f5lTJjyGKRjTCBUW/7imADCwUwuuH5bG6wu2smrn4SBE5h/+XCW1OgM7tWBAh2ZMnrclKKO2Aj5PQUQeEZGLnIcvAa1EZCPwU+CBQMdjjPGfwpIf9ilU9H9n96RF0xge/nAVDfW7n6oSIeD2eJgbhqexOSufb4IwaisgSUFVZ6nqGOf+w6o6zblfpKqXq2p3VR2iqpsDEY8xxh1FJR6axlSdFJo1ieb+c3uxZNshZn/XMIeoerzqatNRmQv6+0ZtBWM9JJvRbIzxm8IqOporumRQKsmJsbz8zY+HqJZ6qhukGDo8qq51MlcUGxXJVUM68eX6fWzNznf9ehVZUjDG+E1hsYe4amoK4Puwu+7kzny9IYuN+44uFb0vt4j+v/+cGat2ByLMevN6A5MUAK4Z2plIkYAvKmhJwRjjN9V1NFd09VDfUtGvfLul/NjSbYcoKPbw9FcbQ7q/weN1d+RRRe2axXHRgBTeXrSdwwWBG8prScEY4zfHaj4CaJ0QyyXpqby7ZAcHnf0W1uzKAWDVzhwWfH/A9Tjry+t0NAfKzad2paDYw+sLAzeZzZKCMcZvqpqnUJUbT0mjqMTLm4u2AbB6Vw6dWjalZXwML1XR3xAqAtXRXKZPShKn9mjNK99u4UipJyDXtKRgjPELr1cpKvFWOyS1ot7tkhjRvRVT5m6lxONl7e4c0js259qhnfhi7V6+3x/YztXa8mhgkwLAxNO6kpV7hA+X7QrI9RpVUgiX5XuNCUVHSn2jh6obklrZTSO6sCeniLcWbmPnoUL6pCRx7bDOREdE8EqILqAXyI7mMqd0b80J7ZN4YfbmgPS3NJqk8NnqPQz8w0z25hQFOxRjwlLFDXZqY1SvNnRpHc+jztIXJ6Yk0SYxjovSU3gncweHCkJvf2dvEGoKIsLE07rw3b48ZgVgUcFGkxRSmzfhcGEJ3zTQSTPGhLq6JoWICOHGEWnkOgu/ndA+CYAJp3ShsMTzg9FJocLjdW8xvJqM6Z9CSrM4lm475Pq1Gk1S6NM+iVbxMcz5ruEv32tMKCos9n241zRPobJLB3UgKS6KtkmxtE6IBXzJ4YJ+7Xnu601sP1DgSqz1FYyaAvj2Wvj8p6fz07N7un6tRpMUIiKEU3q05puN2da3YIwLCot9fQq1rSkAxMdG8YeL+3LfWT/8sPv1BScQIcIjH6/xa4zHy+MN7JDUihJiowJynUaTFMDXYbM/7wjr9uQeu7Axpk7q2nxUZmx6KlcN6fSDYynNm3DXGd2ZuWYvi7ce9FuMx8ujSkSwskKANKqkcGoP3wY91oRkjP+VJ4UY/3ysjB+eRrMm0Tz39Sa/nM8fvF51ZSvOUNKokkK7ZnH0bJvAzDV7gx2KMWGnsLispuCfZo742ChuGJ7GzDV7+W5vaNTuAz15LRgaVVIAuHxwRzK3HmTljoa70YcxoaiovKZQt+ajmowfnkaT6EieDZHagjdAq6QGU6NLCuOGdCQhNooX5tjWDcb4U337FGrSMj6GK4d0ZNqyXew4GPyRSFZTCENJcdGMO6kj01fuZtehwmCHY0zYKCj2f1IA36JwAC/OCf4sZ69iHc3h6IZhaXi8yvQVob12uzENSVnzUZyfOprLpDZvwtj0VN5atI3svCN+PXddeVWJDO+c4F5SEJE4EVkoIstFZLWI/L6KMuNFJEtEljm3m92Kp6JOrZrSu10iM9dah7Mx/lJY7CFCICbS/x8rt4/sypFSb9BXULXmo+NzBDhDVQcA6cBoETm5inJvq2q6c3vRxXh+4Jw+bcnccqB8PXdjzPEpLPHQNCbKlU3tu7dJ5IJ+7Zk8d0tQ/2Y9XnXl/YUS15KC+uQ5D6OdW8hMJT6rT1u8Cl+t3xfsUIwJC4Ulnlotm11fd5/Rg/xiDy8HcQVVX/ORJYV6E5FIEVkG7ANmquqCKopdKiIrRGSqiHSs5jwTRSRTRDKzsvwz8axvSjPaJsXy+WprQjLGH4qKPX6buFaVXu0SOa9vO179dktAt6esyJqPjpOqelQ1HegADBGRvpWKfASkqWp/YCYwuZrzTFLVDFXNSE5O9ktsERHChf1TmLF6D28u3OaXcxrTmNVmK87jdfcZPcg9Usorc4NTW/DY6CP/UNVDwFfA6ErHs1W1bDjBi8DgQMRT5v7RvRjZK5lfvb+S8a8sZPLcLYG8vDFhpaDY/aTQJyWJc/q05eVvvienKPC1Bd8yFwG/bEC5OfooWUSaO/ebAGcD6yqVaV/h4UXAWrfiqUpsVCTPXTuY8cPT2JyVz2+nrWafbcJjTL243adQ5p4ze5BTVMrLQRiJFKylswPJzZpCe+ArEVkBLMLXp/CxiDwiIhc5Ze5xhqsuB+4BxrsYT5XioiP57YUn8s9x6QAs2RY6KzIa05AUlXj8usRFdfqmNuPcE9vy4pzvAz4SyROE7TgDrVZJQUTuFZEk8XlJRJaIyDk1vUZVV6jqQFXtr6p9VfUR5/jDqjrNuf+gqp6oqgNUdZSqrqvpnG7qm5pETGREQHY2MiYcHcgvDtia/z87pxf5xaU8Pzuwy9VYTeGom1Q1BzgHaAFcB/zVtaiCIDYqkhNTk6ymYEw9ZOUeYcfBQvqlNgvI9Xq2TWTsgBRenfs9+3ID1+Tr8dp+CmXKfgrnA6+p6uoKx8LGoE4tWLHjMMWl3mCHYkyDsnjrAQAy0loE7Jr3ndWTEo/yzFeBW0HVq8HZozmQapsUFovI5/iSwmcikgiE3SfnoE4tOFLqZe3uHPKczcSNMceWueUgMVER9A1QTQEgrXU8lw/uwBsLtrEzQItbemz0UbkJwAPASapagG928o2uRRUkAzs1B+D6lxcy6JGZbNyXd4xX1KxsgTBjwl3m1oP0T21GbJT7Hc0V3XNmDwAe/3xDQK5nzUdHDQPWq+ohEbkW+A0QdrvUpDRvQkbnFnRs2QRFeX3B1mO+Zm9OEX/5dC3rnX2fVZWPlu/iyknz6PPwDP78yVpUQ2Z1D2P8rqjEw+pdhxkcwKajMinNm3DjiDTeW7qD1bvc/0iyZS6OehYoEJEBwM+ATcAU16IKoqm3D+fju0/l3BPb8e7iHcf8tj9l3hae/3ozo5+czZin5jD6iTnc/eZS9uUc4fSeyUyavZm/f77eEoMJWyt2HKbEo2R0bhmU698xqjvNm0Tzp+nufwGzZS6OKlXfT3ss8LSq/htIdC+s4Lt6aCdyikrL91woLvVWmSD+t3Yf6R2bc88ZPWgVH0tCXBR/v3wAX/z0dF4efxJXDenEv7/axL/+tzHQb8GYgFjv7J/cNzUpKNdv1iSae8/swdxN2Xy5zt0FLhvDJju1HVScKyIP4huKeqqIRODrVwhbw7q2onubBB58byXTV+5m8daDlHi8XDO0E3ef2YOkuGi2Hyhg3Z5cfnPBCeW7Q1X2p4v7UuLx8s8vNvD5mj10atmUoV1acn6/9rRJigvwuzLG/3IKfctNtGgaE7QYrjm5M1PmbeXPn6zl9J7JRLmwpwNY81FF4/Dtj3CTqu7Bt8DdY65FFQJEhMk3DeHKIR1ZsyuH03om+9Zc+XYLE15dRFGJh/85m/SceULbas8TESH87dL+3HdWD5ITY1m16zC/+2gN5z4xm1nr9zF/czZfrd9nW4OaBivvSClREUJsVPA2coyOjOCB83qzKSufNxdtd+06jaH5qFY1BVXdIyKvAyeJyBhgoaqGZZ9CRanNm/DI2L48Mvbo4q5n9WnLXW8sZfwrC8nOK6ZbcjxdWsfXeJ7ICOG+s3qWP163J8c5x6IflHv8igH8ZFAH/76JKuw4WMAzszYRHxPJ9cPS6NiyaflzXq+Se6SUZk3CuiJo/Ci3qITEOHc216mLs/u0ZUiXljwxcwMXp6eQGOf//8NerxLmFYXaJQURuQJfzWAWvklrT4nI/ao61cXYQtKY/ikczC/m8ZkbOFhQws/P6XnsF1XSu10S798xnA+X7SK1eRPiY6P40/Q1PDpjPef3a++XRcXKOtwq/6F+tX4ft762GMH3refFb76nf2ozLhyQwui+7bjz9SUs33GY3u0SOb1nMmee0JaT0loE/Q/ehK7colJXPoDrSkT4zQUncNHT3/LMrE38cnRvv1/D0wiaj6Q2vfXOgnVnq+o+53Ey8IWz1WZAZWRkaGZmZqAvW6USj5doP7VdztuUzVUvzOeaoZ0oLvVyUXoKp/Y4undE5Wt5vIrHq8RUUWX3eJWJUzI5VFjClJuGEO+sR1Pq8XLOE7MR4LUJQxGBqZk7+GLdPpZv9635FBcdwQ3D0lix4zCZWw9Q4lGGdW3Fz87pSUZacEaXmNB206uL2JtTxPR7Tg12KAD839vLmL5yN1/9fCSpzZv49dy9fvMp44en8eD5J/j1vIEgIotVNeNY5Wrb0RxRlhAc2QRoL4ZQ5q+EADCsWytO7dGa1xf4Nvz5bPUept9zKklx0Tz62TreXrSdK4d05Kohndi4L48nv/iOXYcLuf307pzbty1tEuNoGe/r6Hvyf9/xv3X7EIE731jCi9dnEBUZwftLd7I5K5/nrh1EivPHcveZPbj7zB7M25TNW4u2ceOILqR39E3iyz9SyjuZ23nqy41c9tw8BnduwZNXppMQG8XL33zPmAEp9Gwb1oPQTC3kFZWSGBeYhfBq4+fn9uKTlbt5bMY6nrhyoF/P7dXwn7xW25rCY0B/4E3n0Dhghar+0sXYqhRKNQV/25dTxLLth+jSOp6fPDOXuJhIcgpLKPF4ObVHMnO+y8Lr/Lq6t0mga+t4Pl9zdDvR3u0SiYwQ1uzO4ScDOzC4cwt+9f5KLujXnttHduOWKZm0Sojho7tOqVNzUEFxKVMX7+Dvn60nITaKuOhINu/PJzpSGN23PaUeL2P6p3B+v3aowkcrdvHNd/u5YXhaQJc9MMEx+onZdGjRlBdvOOaX0IB5dMY6npm1iQ/vHMEA50uOP3R9cDp3jOzOz8/t5bdzBopfawqqer+IXAqMcA5NUtX3jydA82NtkuI458R2ADw+Lp1/fL6eC/q154qMjvRJSeK7vbms35tL26Q4BnZsTlRkBGt25bAlO5+t2QXM3bQfgLtGdef2kd1oGhNFQXEpf5y+lukrd9MqPoY/jO1b5/6BpjFRXD8sjcGdW3D9SwspKPHwwvUZfLJyN/M3Z6MKn67aQ7/UZhzIL2bnoUKiIoT3lu5k4mlduffMHgHZfMUER25RKUkhVFMAuH1kN95etJ0/TV/L27ee7Lc+MZunUIGqvgu862IspoKz+7Tl7D4/HOrao20iPSo11/RJSaJPim/S0O0ju/3oPDef2pWkuGgWbTnAL0b3Jjkxtt4xnZjSjM/+7zQAWifElsdX6vHy0jff89nqPaR3bM795/bi9J7J/OXTtTw7axMzVu1h8o1D6NSqaU2nNw1U2eijUJIYF819Z/fkoQ9W8fmavZzrfNk6Hl6nmh7uHc01/iZFJBeoqn1JAFXV4ExhNHVyxUkdueKkjn45V+uEHyeVqMgIbj29G7ee/sOk9OhlA7hoQCp3vL6Yu95cwtTbhlfZMV5XBcWlzFyzl2837qddUhxnntDWr00EpvZUlbwjoTH6qLKrTurI5Llb+Oun6xjVq81x/9/zOE3tLs2LCxk1vj1VTVTVpCpuiZYQTG2c0qM1j17WnxU7DvO7j1ZzpNRDicfL4cLqN13/fn8+by/axrOzNrHBWUKhzJFSDz95Zi73vrWMGav28PRXG7n8+Xnlo6dMYBUUe/AqJIRYTQF8X1Z+dX5vvt+fz+S5W477fB6npmDNR/UkInHAbCDWuc5UVf1tpTKx+BbWG4xvRNM4Vd3iVkwmOEb3bc+EU7rw0jff8/X6LPKOlJJ3pJSfDEzltpHd6JacQHGplznfZfHWou18sXYvZeMfHvtsHef3a8+gTi04o3cb3lu6k3V7cvnnuAGMHZDKwYJixv77W26ZksmHd42gfTP/DkE0Ncst8u07EmrNR2VG9WrDqF7JPPHFBi4ckEK7ZvVfWsbr/KcM90123PxNHgHOUNU8EYkGvhGRT1V1foUyE4CDqtpdRK4E/oZvZJMJMw+N6cNpPZN5btYmUpo3IT42krcWbeedxTvo0SaB7QcLKCrx0jI+hrtGdefSQR1oGhPJc19v5sNlO/l4xW7+MH0NESJcnJ7CJQN9M79bJcTy4g0ZXPbsPMY9P5/Xbx76gxnaxl25Rb4aXyg2H4FvQtvvL+rL2f/8mj9MX8O/rx5U73N5rE/h+DirqpbtUhPt3Cr3T4wFfufcnwo8LSKits50WDq9ZzKn9zw6Ie/uM3rwzuLtzNuUzWk9kxnRvRWn9kj+wfyPhy/sw0NjTmDX4SLeXriNZTsO8/CFJ/7gvL3bJfGfm4dyw8sLufy5efzn5qF0b5MQsPfVmOUeCe2aAkCnVk25Y2R3/vnFBq48KesHk0LrwuvsNRnuzUeudpmISKSILAP2ATNVdUGlIqnAdgBVLcW3cU+rKs4zUUQyRSQzKyvLzZBNACUnxnLHyO68NmEoD43pwxm921Y5IVBESG3ehJ+e04spNw0pn6RXUXrH5rx968mUepVxz89j1c6w2wMqJJU1H4XakNTKbj29K51bNeXhD339WvVR3tEc3jnB3aSgqh5VTce3quoQEel7rNdUc55JqpqhqhnJyfXL8ib89W6XxH9vPZnYqAiuemE+i7ceDHZIYa+s+SghNjSbj8rERUfy+4tO5Pv9+bwwe3O9zlHefGQ1heOnqoeAr4DRlZ7aCXQEEJEooBm+Dmdj6qVrcgLv3D6cVvExXPfSAqsxuCwvxDuaKxrZqw3n9W3HU19uZPuBgjq/vqxV25qP6klEkkWkuXO/CXA2sK5SsWnADc79y4AvrT/BHK/U5k34763DaNYkmolTMsnKPRLskMJWqI8+quyhMX2IjBB+/9HqOm/debT5yJJCfbUHvhKRFcAifH0KH4vIIyJykVPmJaCViGwEfgo84GI8phFpkxTHC9dncKCgmFtfy6x3O7KpWW5RCSIQH9MwkkJK8ybcd1YPvli7j09X7anTaxvLPAXXkoKqrlDVgaraX1X7quojzvGHVXWac79IVS9X1e6qOkRV69fYZ0wV+qY24x+Xp7Nk2yF+/f4q1zd1b4xyikpJiI1qUB+UN43oQt/UJB7+cBWHCopr/bqy0UdWUzCmAbugf3vuPbMHUxfv4OEPV5d/2zP+kXeklMTYhlFLKBMVGcGjlw7gUEEJf5y+ttav85T3KbgVWWgI87dnDNx3Vg9uPb0rr83fyp2vL6HE4w12SGHDtxheaI88qkqflCRuO70bUxfvYPaG2g1zL28+spqCMV+w6FwAABcSSURBVA2biPDgeSfw0Jg+zFi9h7vfWGqJwU9yQ2yDnbq464zudEuO58H3VpLvTMKriVdtSKoxYWXCKV347YW+xPDnT2rfbGCq15CTQlx0JH+7tD+7Dhfy2Gfrj1m+sSxzYUnBNCo3jujC+OFpvPLtFmZW2LXO1E/ekVISGmDzUZmMtJbcMCyNyfO2sHjrgRrLem2egjHh6cHze9M3NYmfvr3smB8EpmahuMFOXd1/bi9SmjXh/ndWUFhc/dBlG31kTJiKjYpk0nUZtE6M5doXF5ZvY2rqLreo4Y0+qiw+NopHL+vP5v35/PXT6psVPdanYEz4SnFmPXds2YRbJmeycocth1FXHq9ypNRL0wYyca0mI7q35sYRaUyet7Xa0Ug2ec2YMJecGMtrE4bSvGkM419ZWK/1cBqzwhJfU0uTmPD4GPnl6N50b5PA/VOXVzmpzWvLXBgT/tomxfHahCGUepUJkxeVr/ppjq2s/b1JGNQUwDca6Ylx6WTnFfPQh6t/9PzReQqBjiywLCmYRq9rcgLPXDOITVn5/PLdFbYcRi2VJ4XoyCBH4j99U5tx75k9+Gj5LqYt3/WD57zWfGRM4zGie2t+dk5PPlm5h49W7A52OA1CQYlvwlfTmPBJCgC3j+zGwE7N+c37K9lzuKj8uHU0G9PITDy1K+kdm/Pwh6vYl1t07Bc0ckebj8IrKURFRvD4FemUeJT/e3tZebORLXNhTCMTFRnB3y8fQEGxx1ZVrYVwbD4q06V1PI+MPZF5m7N5+suNAJT9d7CagjGNSPc2Cdx/Ti9mrtnL+0t3BjuckFY2+ijcmo/KXDa4A5cMTOXJ/21g/uZsW+bCmMbqplO6kNG5BQ99sIoNe3ODHU7IKgjjmgL4FlL8w8V96dwqnnvfWsr+PN8OfrZ0tjGNTGSE8NTVA2kSE8XEKZkcLrBhqlU5Ok8hPJMCQEJsFE9dNZCD+SX8bYZvN2FrPjKmEWrfrAnPXzeInYcKuevNJbY5TxXCuU+hor6pzfjV+b056Hw5sOajehKRjiLylYisEZHVInJvFWVGishhEVnm3B52Kx5j6mpw55b8YWxf5ny3v/xbojmqrPkoHJa5OJYbhqdxTp+2AERHhvd3aTd/m6XAz1R1iYgkAotFZKaqrqlUbo6qjnExDmPq7cohnVizO4dJszfTp30SFw9MDXZIIaOs+Sg2Krw/JMHXv/CPKwbw1fosOrdqGuxwXOXab1NVd6vqEud+LrAWsL8o0+A8NKYPQ7q05JfvrmDVTls4r0xhcSlNoiPDfoZvmcS4aC4akIJY89HxE5E0YCCwoIqnh4nIchH5VEROrOb1E0UkU0Qys7Jqt5+qMf4SHRnBM9cMomV8DHe9saRWWzc2BoUlnrAdjtqYuZ4URCQBeBe4T1VzKj29BOisqgOAp4APqjqHqk5S1QxVzUhOTnY3YGOq0DohlifGpbPtQAG/nfbjxdIao4JiD3Fh3sncGLmaFEQkGl9CeF1V36v8vKrmqGqec/8TIFpEWrsZkzH1NbRrK+4c1Z2pi3fw5TrbyrOw2GoK4cjN0UcCvASsVdXHqynTzimHiAxx4sl2KyZjjtfdZ/SgZ9sEHvpgdaNvRios8YT1HIXGys2awgjgOuCMCkNOzxeR20TkNqfMZcAqEVkO/Au4Um3BGRPCYqIi+PMl/dh5qJDHPlsf7HCCqqDYE/ZzFBoj14akquo3QI3d9Kr6NPC0WzEY44aMtJaMH57Gq3O3cHrPZEb1bhPskIKiqMRDy/iYYIdh/Cz8Bxgb44IHzutN73aJ/Pyd5ew6VBjscIKiwPoUwpIlBWPqIS46kqevHkhxqZfrXlrAgfwf7+kb7gqLPTSJDv/ZzI2NJQVj6ql7m0ReGn8SOw4WMmHyIo6UeoIdUkD5OprtIyTc2G/UmOMwpEtLnhiXztJth/j9R5VXcAlvBcWljWLdo8bGkoIxx+m8fu257fRuvLFgGx80ko15vF6lqMRrk9fCkCUFY/zg/nN7MbhzC347bTV7c8J/f+ei0vDeda0xs6RgjB9ERgiPXdafohIPv3x3Bd4w338h3Hdda8wsKRjjJ12TE/j1BScwa30Wj8/cEOxwXFW+wY7VFMKO9RIZ40fXndyZNbtyePqrjfRom8DY9PBcLb58K06rKYQdqykY40ciwiNj+zK0S0vun7qCpdsOBjskVxQWW59CuLKkYIyfxURF8Oy1g2mXFMfE1xaH5YznAms+CluWFIxxQcv4GF68IYPCYg+3TMmkoDi8VlQtLPG9H2s+Cj+WFIxxSc+2iTx11UDW7s7hjteXUFQSPjOeC4u9ADZ5LQxZUjDGRaN6t+FPl/Rj1vosbpmSGTaJoazmYzWF8GNJwRiXXTWkE49e2p9vNu5nwuRF5Z20DVlZcrM+hfBjScGYALjipI78/bIBzNuUzfhXFjb4Xdusozl8WVIwJkAuHdyBf45LZ9GWA4x/ZSF5DTgx2Izm8OXmHs0dReQrEVkjIqtF5N4qyoiI/EtENorIChEZ5FY8xoSCsempPHXVIJZsO8R1Ly0gp6gk2CHVS25RKU2iI4mMqHFzRdMAuVlTKAV+pqp9gJOBO0WkT6Uy5wE9nNtE4FkX4zEmJFzQvz3/vnogK3cc5roXF3C4oOElhm0H8unUsmmwwzAucC0pqOpuVV3i3M8F1gKV5/yPBaaoz3yguYi0dysmY0LF6L7tefbawazZncM1L83nYAPbue37/fmktbakEI4C0qcgImnAQGBBpadSge0VHu/gx4nDmLB0dp+2TLougw1787j6xQVk5x0Jdki14vEq2w8UktYqPtihGBe4nhREJAF4F7hPVXPqeY6JIpIpIplZWVn+DdCYIBrVuw0vXp/B5qw8rn5hAfsbQGLYdaiQYo+XtNaWFMKRq0lBRKLxJYTXVfW9KorsBDpWeNzBOfYDqjpJVTNUNSM5OdmdYI0JktN6JvPy+JPYeiCfKyfNZ1+Ib9KzJTsfwGoKYcrN0UcCvASsVdXHqyk2DbjeGYV0MnBYVXe7FZMxoWpE99a8euMQdh0q5MpJ89lzOHQTw5bsAgDrUwhTbtYURgDXAWeIyDLndr6I3CYitzllPgE2AxuBF4A7XIzHmJB2ctdWTLlpCPtyjzBu0ryQXV11y/584qIjaJsYF+xQjAtcW81KVb8BahzErKoK3OlWDMY0NBlpLZkyYQg3vLSQcZPm8cbNJ9MxxIZ+btmfT1qreCJsjkJYshnNxoSYQZ1a8PotQzlcUMKVk+azzWmuCRVbsvPp3Cq0EpXxH0sKxoSg/h2a88YtJ5NfXMq4SfP4fn9+sEMCKgxHtZFHYcuSgjEhqm9qM964+WSOlHoZ9/w8NmXlBTsk9uYUUezx2mzmMGZJwZgQ1icliTdvORmvKj95Zi4fLN2JrysuOLLzfDOvWyfEBi0G4y5LCsaEuF7tEpl623C6Jsdz39vL+N201UFLDNn5vsl1reJjgnJ94z5LCsY0AGmt45l623BuPqULk+dt5TcfrKLU4w14HAecNZpaWlIIW7bBqjENRGSE8OsLTiA6KoJnZ21i4748nrp6IG0COF+gLCm0irfmo3BlNQVjGhAR4Zeje/P4FQNYvuMQF/zrGxZszg7Y9bPzi4mKEJKa2PfJcGVJwZgG6CeDOvDhnaeQGBvF1S8u4LmvNwWkn+FAXjEt4mPwrWJjwpElBWMaqF7tEpl29ymMPrEdf/10Hbf9Z7Hrez9n5xdbJ3OYs6RgTAOWEBvF01cP5KExfZi5Zi+XPjvX1YluB/KPWCdzmLOkYEwDJyJMOKULr944hN2Hizj/yTm8sWCbK81JB/KLLSmEOUsKxoSJ03omM+O+UxnUuTm/en8lN0/OJCvXv5v2WPNR+LOkYEwYad+sCa/dNJSHx/Rhzsb9jH5iNjPX7PXLuYtLveQWldLShqOGNUsKxoSZiAjhplO68PHdp9A2KY5bpmTywLsrjrsT+mCBM3EtwWoK4cySgjFhqmfbRD64cwS3j+zG25nbOe/JOSzeerDe5ytb98iaj8KbJQVjwlhMVAS/HN2btycOw+NVLntuLne+sYSN+3LrfC5b4qJxsKRgTCMwpEtLZtx3Kref3o1Z6/Yx+ok5PDpjHYXFnlqfwxbDaxxcSwoi8rKI7BORVdU8P1JEDlfYv/lht2IxxkBiXDS/GN2b2b8Yxdj0VJ6ZtYmz//k1M1btxuM99vBVqyk0Dm7WFF4FRh+jzBxVTXduj7gYizHG0Sohln9cMYA3bzmZ2KgIbvvPEkb9fRYfLqt5r4YD+cWIQPOmlhTCmWtJQVVnAwfcOr8x5vgM69aKGfedxtNXDyQxLop731rGuOfn8+KczezNKfpR+ez8Ylo0jSEywtY9CmfB7lMYJiLLReRTETkxyLEY0+hER0Ywpn8K0+46hd9d2If9eUf44/S1jHxsFk9/+R1FJb4+B69XWb79EG2TArdMtwmOYK5/uwTorKp5InI+8AHQo6qCIjIRmAjQqVOnwEVoTCMRGSGMH9GF8SO6sDkrj7/NWMffP9/Amwu38+sLTuBQQQmrd+Xwz3EDgh2qcZm4udyuiKQBH6tq31qU3QJkqOr+msplZGRoZmamX+IzxlRv7qb9PPLRGtbtySVCICOtJW9PPNmWzW6gRGSxqmYcq1zQmo9EpJ04/7tEZIgTS+B2CzHG1Gh4t9ZMv+dU/nxJP9I7NudPF/e1hNAIuNZ8JCJvAiOB1iKyA/gtEA2gqs8BlwG3i0gpUAhcqcHajdwYU6XICOHqoZ24eqg12zYWriUFVb3qGM8/DTzt1vWNMcbUXbBHHxljjAkhlhSMMcaUs6RgjDGmnCUFY4wx5SwpGGOMKWdJwRhjTDlLCsYYY8q5usyFG0QkC9hah5c0Aw7X8bnKxys+rup+5X9bAzUu11GHGKt73mKse5z+jLHsWHSQY6wpNrd+3w01xmPFGe5/N51VNfmYEatqWN+ASXV9rvLxio+rul/Fv5n+irG65y1G//y+6xtj2f1gx1hTbG79vhtqjMfz+w73v5uKt8bQfPRRPZ6rfPyjY9yv/G9dHet1VT1vMdY+jpqeq2+Mx7pWTfwZY8XHx4q3LsIxxqqO299NJQ2u+aghEJFMrcVqhMFkMfpHQ4gRGkacFqN/HG+MjaGmEAyTgh1ALViM/tEQYoSGEafF6B/HFaPVFIwxxpSzmoIxxphylhSMMcaUs6RgjDGmnCWFABORCBH5k4g8JSI3BDueqojISBGZIyLPicjIYMdTHRGJF5FMERkT7FiqIiInOD/DqSJye7DjqYqIXCwiL4jI2yJyTrDjqY6IdBWRl0RkarBjqcj5PzjZ+RleE+x4qlLXn50lhToQkZdFZJ+IrKp0fLSIrBeRjSLywDFOMxboAJQAO0I0RgXygLgQjhHgl8B//R2fv2JU1bWqehtwBTAiRGP8QFVvAW4Dxvk7Rj/GuVlVJ7gRX2V1jPcnwFTnZ3hRIOKra4x1/tkdz8y3xnYDTgMGAasqHIsENgFdgRhgOdAH6Ad8XOnWBngAuNV57dQQjTHCeV1b4PUQjfFs4EpgPDAmFGN0XnMR8ClwdajG6LzuH8CgUP27qfA6v//NHGe8DwLpTpk33I6tPjHW9Wfn2h7N4UhVZ4tIWqXDQ4CNqroZQETeAsaq6l+AHzVriMgOoNh56AnFGCs4CMSGYoxOs1Y8vj/MQhH5RFW9oRSjc55pwDQRmQ684a/4/BWjiAjwV+BTVV3iz/j8GWcg1SVefDXpDsAyAtjyUscY19Tl3NZ8dPxSge0VHu9wjlXnPeBcEXkKmO1mYBXUKUYR+YmIPA+8Bjztcmxl6hSjqv5aVe/D90H7gj8TQg3q+nMcKSL/cn6Wn7gdnKOu/x/vBs4CLhOR29wMrJK6/ixbichzwEARedDt4KpQXbzvAZeKyLP4aZmJ41BljHX92VlNIcBUtQAISNtofanqe/j+s4c8VX012DFUR1VnAbOCHEaNVPVfwL+CHcexqGo2vn6PkKKq+cCNwY6jJnX92VlN4fjtBDpWeNzBORZKLEb/sBj9p6HEWaYhxOuXGC0pHL9FQA8R6SIiMfg6P6cFOabKLEb/sBj9p6HEWaYhxOufGAPVWx4ON+BNYDdHh5NOcI6fD2zA1/P/a4vRYrQYG16cDSleN2O0BfGMMcaUs+YjY4wx5SwpGGOMKWdJwRhjTDlLCsYYY8pZUjDGGFPOkoIxxphylhSM60QkLwDXuE1Ernf7OpWuebGI9Knn6x527v9ORH7u/+jqzlmr6eNjlOknIq8GKCQTBLb2kWkwRCRSVatcWVZVnwv0NYGL8S3tXKdVKIFfEMC19/1JVVeKSAcR6aSq24Idj/E/qymYgBKR+0VkkYisEJHfVzj+gYgsFpHVIjKxwvE8EfmHiCwHhjmP/yQiy0Vkvoi0dcqVf+MWkVki8jcRWSgiG0TkVOd4UxH5r4isEZH3RWSBiGRUEeMW5/VLgMtF5BYn5uUi8q5znuH4PtgfE5FlItLNuc1w3sccEeldxbl7AkdUdX8Vz6U772mFE18L5/hJzrFlIvKYVNpYxSnTXkRmO2VWVXjPo0VkiRP7/5xjQ0RknogsFZG5ItKrivPFi28jl4VOubEVnv4I3xIKJgxZUjABI77tHnvgW/c9HRgsIqc5T9+kqoOBDOAeEWnlHI8HFqjqAFX9xnk8X1UH4Ft6/JZqLhelqkOA+4DfOsfuAA6qah/gIWBwDeFmq+ogVX0LeE9VT3KuuRbfkgJz8a0rc7+qpqvqJmAScLfzPn4OPFPFeUcA1e1bMAX4par2B1ZWiPsVfBszpVP9HhxXA585ZQYAy0QkGXgBuNSJ/XKn7DrgVFUdCDwM/LmK8/0a+NL5GY7Cl/zinecygVOricM0cNZ8ZALpHOe21HmcgC9JzMaXCC5xjnd0jmfj+xB8t8I5ivE12QAsxrcDW1Xeq1Amzbl/CvAkgKquEpEVNcT6doX7fUXkj0BzJ+bPKhcWkQRgOPCOiJQdrmqDovZAVhWvbwY0V9WvnUOTnXM1BxJVdZ5z/A2q3oRmEfCyiEQDH6jqMvFtRDRbVb933vMBp2wzYLKI9MC39Wp0Fec7B7ioQn9HHNAJX1LcB6RU8RoTBiwpmEAS4C+q+vwPDvo+vM4ChqlqgYjMwvchBFBUqU2/RI8u2OWh+v/DR2pRpib5Fe6/ClysqstFZDwwsoryEcAh55t6TQrxfSj7lfp24joNuAB4VUQex7dzXlX+AHylqpeIb/euWVWUEXw1jPVVPBeH732YMGTNRyaQPgNucr5VIyKpItIG34fkQSch9AZOdun63wJXONcu2w+4NhKB3c638GsqHM91nkNVc4DvReRy5/wiIgOqONdaoHvlg6p6GDhY1hcAXAd8raqHgFwRGeocr7ItX0Q6A3tV9QXgRXz7984HThORLk6Zlk7xZhxdZ398Ne/5M+Bucao9IjKwwnM9gR/1a5jwYEnBBIyqfo6v+WOeiKwEpuL7UJ0BRInIWnz7Bc93KYRngGQRWQP8EVgNHK7F6x4CFuBLKusqHH8LuN/piO2GL2FMcDrFV+PbH7ey2fi2RZQqnrsBX9v9Cnx9Lo84xycAL4jIMnx9KlXFPBJYLiJLgXHAk6qaBUwE3nNiKmsSexT4i1O2ulrUH/A1K60QkdXO4zKjgOnVvM40cLZ0tmk0RCQSiFbVIudD/Augl6oWBziOJ4GPVPWLWpZPUNU85/4DQHtVvdfNGGuIJRb4GjhFVUuDEYNxl/UpmMakKfCV0wwkwB2BTgiOPwNDj1nqqAvEt+F6FLCV6pt8AqET8IAlhPBlNQVjjDHlrE/BGGNMOUsKxhhjyllSMMYYU86SgjHGmHKWFIwxxpSzpGCMMabc/wMgLiZ8HmHF9AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.lr_find(show_plot=True, max_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reduce_on_plateau automatically enabled at patience=2\n",
      "\n",
      "\n",
      "begin training using triangular learning rate policy with max lr of 0.001...\n",
      "Train on 647 samples, validate on 81 samples\n",
      "Epoch 1/1024\n",
      "647/647 [==============================] - 5s 7ms/sample - loss: 2.0475 - accuracy: 0.5301 - val_loss: 0.8105 - val_accuracy: 0.4815\n",
      "Epoch 2/1024\n",
      "647/647 [==============================] - 3s 5ms/sample - loss: 0.7684 - accuracy: 0.6074 - val_loss: 0.7096 - val_accuracy: 0.5062\n",
      "Epoch 3/1024\n",
      "647/647 [==============================] - 3s 5ms/sample - loss: 0.6144 - accuracy: 0.6801 - val_loss: 0.6642 - val_accuracy: 0.6420\n",
      "Epoch 4/1024\n",
      "647/647 [==============================] - 3s 5ms/sample - loss: 0.5863 - accuracy: 0.6754 - val_loss: 0.6732 - val_accuracy: 0.5926\n",
      "Epoch 5/1024\n",
      "640/647 [============================>.] - ETA: 0s - loss: 0.5612 - accuracy: 0.7016\n",
      "Epoch 00005: Reducing Max LR on Plateau: new max lr will be 0.0005 (if not early_stopping).\n",
      "647/647 [==============================] - 3s 5ms/sample - loss: 0.5629 - accuracy: 0.7032 - val_loss: 0.6891 - val_accuracy: 0.6667\n",
      "Epoch 6/1024\n",
      "647/647 [==============================] - 3s 5ms/sample - loss: 0.5015 - accuracy: 0.7527 - val_loss: 0.6771 - val_accuracy: 0.6173\n",
      "Epoch 7/1024\n",
      "640/647 [============================>.] - ETA: 0s - loss: 0.4521 - accuracy: 0.7922\n",
      "Epoch 00007: Reducing Max LR on Plateau: new max lr will be 0.00025 (if not early_stopping).\n",
      "647/647 [==============================] - 3s 5ms/sample - loss: 0.4571 - accuracy: 0.7898 - val_loss: 0.7176 - val_accuracy: 0.6296\n",
      "Epoch 8/1024\n",
      "640/647 [============================>.] - ETA: 0s - loss: 0.4437 - accuracy: 0.7844Restoring model weights from the end of the best epoch.\n",
      "647/647 [==============================] - 3s 5ms/sample - loss: 0.4426 - accuracy: 0.7852 - val_loss: 0.6867 - val_accuracy: 0.6543\n",
      "Epoch 00008: early stopping\n",
      "Weights from best epoch have been loaded into model.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0c02e60748>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.autofit(10e-4, early_stopping=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.18      0.29        33\n",
      "           1       0.63      0.96      0.76        48\n",
      "\n",
      "    accuracy                           0.64        81\n",
      "   macro avg       0.69      0.57      0.53        81\n",
      "weighted avg       0.68      0.64      0.57        81\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 6, 27],\n",
       "       [ 2, 46]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.validate(class_names=preproc.get_classes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "X_test = pd.read_csv('../data/test_80_10_10.csv')['cleaned_contents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = ktrain.get_predictor(learner.model, preproc=preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = predictor.predict(list(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "\n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=0\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.710</b>, score <b>-0.898</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.663\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 90.33%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.235\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(0, 100.00%, 98.54%); opacity: 0.80\" title=\"-0.008\">as</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.45%); opacity: 0.82\" title=\"-0.071\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.67%); opacity: 0.82\" title=\"-0.100\">accused</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.58%); opacity: 0.88\" title=\"0.361\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 69.84%); opacity: 0.93\" title=\"0.630\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.14%); opacity: 0.83\" title=\"0.128\">sole</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.05%); opacity: 0.81\" title=\"0.048\">breadwinner</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.47%); opacity: 0.81\" title=\"-0.042\">for</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 72.87%); opacity: 0.91\" title=\"-0.542\">his</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.20%); opacity: 0.82\" title=\"0.109\">family</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 90.66%); opacity: 0.83\" title=\"0.118\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 84.41%); opacity: 0.85\" title=\"-0.246\">reduce</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-0.943\">his</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 75.02%); opacity: 0.90\" title=\"-0.481\">sentence</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.68%); opacity: 0.86\" title=\"0.285\">by</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 61.26%); opacity: 0.99\" title=\"0.901\">two</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 76.86%); opacity: 0.89\" title=\"0.432\">years</span><span style=\"opacity: 0.80\">.</span>\n",
       "    </p>\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.explain('As the accused is the sole breadwinner for his family, I reduce his sentence by two years.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.18      0.29        33\n",
      "           1       0.63      0.96      0.76        48\n",
      "\n",
      "    accuracy                           0.64        81\n",
      "   macro avg       0.69      0.57      0.53        81\n",
      "weighted avg       0.68      0.64      0.57        81\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 6, 27],\n",
       "       [ 2, 46]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.evaluate(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
