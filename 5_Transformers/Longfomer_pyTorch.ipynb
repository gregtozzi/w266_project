{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Longformer using Pytorch. Longformer huggingface not available for Tensorflow at time of writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "colab_type": "code",
    "id": "uZzLMaRbAXDK",
    "outputId": "c7fab41e-4cd5-432b-aa73-cab9c69b4dce"
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "BR1HWv08QD4Q",
    "outputId": "bbc69b4f-ebb9-4810-9ec7-1a0bcf8d3050"
   },
   "outputs": [],
   "source": [
    "!pip install torch-lr-finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "hBCF_21D_5KE",
    "outputId": "5e42ef79-1a69-4500-8af6-0e5e32ecc3ce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "#!pip install pytorch-model-summary\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import time\n",
    "import datetime\n",
    "import re\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Graphing\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns \n",
    "\n",
    "# PyTorch Imports\n",
    "import torch # a tensor library\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "#Huggingface Transformers\n",
    "import transformers\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "from transformers import LongformerModel, LongformerTokenizer, LongformerConfig\n",
    "from transformers import LongformerForSequenceClassification, AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I0mwc0VTAOgD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gAePwUbO_5KJ"
   },
   "source": [
    "## Model Set Up\n",
    "Set up the model and the configuration we need\n",
    "\n",
    "- max_len - how many tokens will be used from the document.\n",
    "- batch_size - reduce if memory issues. paper reccomends 16-32\n",
    "- num epochs\n",
    "\n",
    "- tokenizer - this should be a pretrined tokenizer, e.g. distilBert. \n",
    "- model - make sure it uses the same tokenizer for generating the weights\n",
    "\n",
    "#### input files\n",
    "- train.csv: heading removed, dates and URL replcaed, un-cased, sentence breaks and punctuation included  \n",
    "- train_lcase.csv: heading removed, dates and URL replcaed, lower cased, sentence breaks and punctuation removed\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "aFp1pXBE_5KK",
    "outputId": "90d020a5-9776-4d44-ff09-7dd17f48ac95"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "train_file = \"train.csv\"\n",
    "test_file = \"test.csv\"\n",
    "\n",
    "\n",
    "max_len = 512\n",
    "batch_size = 8\n",
    "num_epochs = 15\n",
    "lr = 3e-5\n",
    "use_global_mask = False\n",
    "\n",
    "config = LongformerConfig.from_pretrained('allenai/longformer-base-4096',\n",
    "    #attention_mode = 'sliding_chunks',\n",
    "    num_labels=2,\n",
    "    dropout = 0.2,\n",
    "    attention_dropout = 0.2,\n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False\n",
    "    )\n",
    "\n",
    "\n",
    "tokenizer = LongformerTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
    "model = LongformerForSequenceClassification.from_pretrained('allenai/longformer-base-4096', config = config)\n",
    "                                                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B9nGgXJ__5KP"
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OLXtZpdM_5KQ"
   },
   "outputs": [],
   "source": [
    "# Function to get data\n",
    "def get_data(fname):\n",
    "    df = pd.read_csv(fname)\n",
    "    df = df[['cleaned_contents', 'Discrimination_Label']]\n",
    "    df = df.rename(columns = {'cleaned_contents':'text', 'Discrimination_Label':'label'})\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LBui4eey_5KT"
   },
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OVqvnRhN_5KW"
   },
   "outputs": [],
   "source": [
    "# Function to format elapsed time \n",
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y-zpq1n3_5KZ"
   },
   "outputs": [],
   "source": [
    "# Function to tokenize data and return tensors for input ids, attention mask and labels\n",
    "def tokenize_plus(df):\n",
    "\n",
    "    sentences = df['text'].values\n",
    "    labels = df['label'].values\n",
    "\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    for sent in sentences:\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "                            sent,                     \n",
    "                            add_special_tokens = True, \n",
    "                            max_length = max_len,    \n",
    "                            truncation = True,\n",
    "                            pad_to_max_length = True,\n",
    "                            return_attention_mask = True, \n",
    "                            return_tensors = 'pt'    \n",
    "                       )\n",
    "\n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "    # Convert the lists into tensors.\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    return input_ids, attention_masks, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V8t7crx7_5Kd"
   },
   "outputs": [],
   "source": [
    "# Function to semi manually okenize data and return tensors for input ids, attention mask and labels\n",
    "# Adds ability to add global attention mask =2 for <s> tokens (x=0)\n",
    "\n",
    "def tokenize_manual(df, att=True):\n",
    "    tokenized = df['text'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, \n",
    "                                                             max_length=max_len, \n",
    "                                                             truncation=True)))\n",
    "    padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
    "    attention_mask = np.where(padded != 0, 1, 0)\n",
    "    if att:\n",
    "        for i in range(len(padded)):\n",
    "            idx = [i for i, x in enumerate(padded[i]) if x == 0]\n",
    "            attention_mask[i][idx] = 2\n",
    "    \n",
    "    input_ids = torch.tensor(padded) \n",
    "    attention_mask = torch.tensor(attention_mask)\n",
    "\n",
    "    labels = df['label']\n",
    "    labels = torch.tensor(labels)\n",
    "    \n",
    "    return input_ids, attention_mask, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YgBt-yJg_5Kh"
   },
   "source": [
    "# Fine Tuning and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "nC7d03GT_5Kh",
    "outputId": "34516306-90ae-4929-92e9-13712991cd28"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SENTENCE\\n\\n\\t1.\\tYou are charged as follows:\\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SENTENCE\\n\\n\\t1.\\tJOSEFA KOTOBALAVU, you were ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SENTENCE\\n\\n1. The Director of Public Prosecut...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SENTENCE\\n\\n\\t1.\\tMOHOMMED NABI UD- DEAN, you ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JUDGMENT OF THE COURT\\n\\nBackground\\n\\n[1] The...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  SENTENCE\\n\\n\\t1.\\tYou are charged as follows:\\...      0\n",
       "1  SENTENCE\\n\\n\\t1.\\tJOSEFA KOTOBALAVU, you were ...      1\n",
       "2  SENTENCE\\n\\n1. The Director of Public Prosecut...      1\n",
       "3  SENTENCE\\n\\n\\t1.\\tMOHOMMED NABI UD- DEAN, you ...      1\n",
       "4  JUDGMENT OF THE COURT\\n\\nBackground\\n\\n[1] The...      0"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_data(train_file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LvrITmM4_5Kl"
   },
   "outputs": [],
   "source": [
    "# Get tokenized labels\n",
    "\n",
    "if use_global_mask:\n",
    "    input_ids, attention_masks, labels = tokenize_manual(df)\n",
    "else:\n",
    "    input_ids, attention_masks, labels = tokenize_plus(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "624PVM1aCIVA",
    "outputId": "cfa405d8-4d97-4102-af9c-f4eccbd0a01e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Tesla P100-PCIE-16GB'"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What GPU are we using?\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "uzfxBgOVCP9c",
    "outputId": "281ed670-a64e-45b7-8bf0-c51527785ad2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized:  ['S', 'ENT', 'ENCE', 'ĊĊ', 'ĉ', '1', '.', 'ĉ', 'You', 'Ġare', 'Ġcharged', 'Ġas', 'Ġfollows', ':', 'Ċ', 'Ċ', 'First', 'ĠCount', 'Ċ', 'Statement', 'Ġof', 'ĠOff', 'ence', 'Ċ', 'Ċ', 'R', 'ape', ':', 'ĠContrary', 'Ġto', 'ĠSections', 'Ġ149', 'Ġand', 'Ġ150', 'Ġof', 'Ġthe', 'ĠPenal', 'ĠCode', ',', 'ĠCap', 'Ġ17', '.', 'Ċ', 'Ċ', 'Part', 'icular', 's', 'Ġof', 'ĠOff', 'ence', 'Ċ', 'Ċ', 'S', 'ere', 'ma', 'ia', 'ĠDel', 'a', 'Ġbetween', 'Ġthe', 'Ġ1', 'st', 'ĠJanuary', ',', 'Ġ2007', 'Ġto', 'Ġ31', 'st', 'Ġday', 'Ġof', 'ĠDecember', ',', 'Ġ2007', ',', 'Ġat', 'ĠN', 'ade', 'le', 'i', 'ĠVillage', ',', 'ĠV', 'at', 'uk', 'oul', 'a', ',', 'ĠTav', 'ua', 'Ġin', 'Ġthe', 'ĠWestern', 'ĠDivision', ',', 'Ġhad', 'Ġunlawful', 'Ġcarn', 'al', 'Ġknowledge', 'Ġof', 'ĠN', 'N', ',', 'Ġwithout', 'Ġher', 'Ġconsent', '.', 'Ċ', 'Ċ', 'Second', 'ĠCount', 'Ċ', 'Statement', 'Ġof', 'ĠOff', 'ence', 'Ċ', 'Ċ', 'R', 'ape', ':', 'ĠContrary', 'Ġto', 'ĠSection', 'Ġ207', 'Ġ(', '1', ')', 'Ġand', 'Ġ(', '2', ')', 'Ġ(', 'a', ')', 'Ġof', 'Ġthe', 'ĠCrimes', 'ĠDec', 'ree', 'Ġ44', 'Ġof', 'Ġ2009', '.', 'Ċ', 'Ċ', 'Part', 'icular', 's', 'Ġof', 'ĠOff', 'ence', 'Ċ', 'Ċ', 'S', 'ere', 'ma', 'ia', 'ĠDel', 'a', 'Ġbetween', 'Ġthe', 'Ġ1', 'st', 'ĠJuly', 'Ġ2012', 'Ġto', 'Ġthe', 'Ġ31', 'st', 'ĠJuly', 'Ġ2012', ',', 'Ġat', 'ĠN', 'ade', 'le', 'i', 'ĠVillage', ',', 'ĠV', 'at', 'uk', 'oul', 'a', ',', 'ĠTav', 'ua', 'Ġin', 'Ġthe', 'ĠWestern', 'ĠDivision', 'Ġpenetrated', 'Ġthe', 'Ġvagina', 'Ġof', 'ĠN', 'N', ',', 'Ġwith', 'Ġhis', 'Ġpenis', ',', 'Ġwithout', 'Ġher', 'Ġconsent', '.', 'ĊĊ', 'ĉ', '1', '.', 'ĉ', 'On', 'Ġ28', 'th', 'ĠNovember', 'Ġ2013', 'Ġyou', 'Ġpleaded', 'Ġguilty', 'Ġto', 'Ġboth', 'Ġcharges', 'Ġagainst', 'Ġyou', 'Ġand', 'Ġadmitted', 'Ġthe', 'ĠSummary', 'Ġof', 'ĠFacts', 'Ġon', 'Ġ4', 'th', 'ĠDecember', 'Ġ2013', '.', 'ĊĊ', 'ĉ', '2', '.', 'ĉ', 'The', 'ĠSummary', 'Ġof', 'ĠFacts', 'Ġsubmitted', 'Ġby', 'Ġthe', 'ĠState', 'ĠCounsel', 'Ġstates', 'Ġas', 'Ġfollows', ':', 'Ċ', 'Ċ', 'The', 'Ġaccused', ',', 'ĠSere', 'ma', 'ia', 'ĠDel', 'a', 'Ġis', 'Ġ38', 'Ġyears', 'Ġof', 'ĠN', 'ade', 'le', 'i', 'ĠVillage', ',', 'ĠV', 'at', 'uk', 'oul', 'a', ',', 'ĠTav', 'ua', '.', 'ĠThe', 'Ġcomplainant', 'Ġin', 'Ġthis', 'Ġcase', 'Ġis', 'Ġone', 'ĠN', 'N', ',', 'Ġ10', 'Ġyears', 'Ġof', 'Ġthe', 'Ġsame', 'Ġvillage', '.', 'Ċ', 'Ċ', 'The', 'Ġcomplainant', 'Ġwas', 'Ġ10', 'Ġyears', 'Ġold', ',', 'Ġschooling', 'Ġin', 'ĠN', 'ade', 'le', 'i', 'ĠCatholic', 'ĠSchool', 'Ġwhen', 'Ġthe', 'Ġfirst', 'Ġincident', 'Ġtook', 'Ġplace', '.', 'ĠShe', 'Ġcould', 'Ġrecall', 'Ġthat', 'Ġin', 'Ġthe', 'Ġyear', 'Ġ2007', 'Ġduring', 'Ġthe', 'Ġsecond', 'Ġterm', 'Ġschool', 'Ġand', 'Ġin', 'Ġparticular', 'Ġon', 'Ġthe', 'Ġday', 'Ġshe', 'Ġdid', 'Ġnot', 'Ġgo', 'Ġto', 'Ġschool', 'Ġthe', 'Ġcomplainant', 'Ġwas', 'Ġtold', 'Ġby', 'Ġher', 'Ġmother', 'Ġto', 'Ġgo', 'Ġand', 'Ġhave', 'Ġher', 'Ġbath', 'Ġin', 'Ġthe', 'Ġriver', 'Ġnext', 'Ġto', 'Ġthe', 'Ġvillage', '.', 'ĠShe', 'Ġleft', 'Ġher', 'Ġhome', 'Ġalone', 'Ġto', 'Ġhave', 'Ġher', 'Ġbath', 'Ġand', 'Ġon', 'Ġthe', 'Ġway', 'Ġback', 'Ġshe', 'Ġmet', 'Ġthe', 'Ġaccused', 'Ġsitting', 'Ġnext', 'Ġto', 'Ġthe', 'Ġriver', 'Ġbank', '.', 'ĠThe', 'Ġaccused', 'Ġapproached', 'Ġthe', 'Ġcomplainant', 'Ġand', 'Ġasked', 'Ġher', 'Ġto', 'Ġaccompany', 'Ġher', 'Ġto', 'Ġthe', 'Ġgu', 'ava', 'Ġpatch', 'Ġto', 'Ġcollect', 'Ġgu', 'av', 'as', '.', 'ĠThe', 'Ġcomplainant', 'Ġtrusted', 'Ġthe', 'Ġaccused', 'Ġand', 'Ġfollowed', 'Ġhim', ',', 'Ġsuddenly', 'Ġthe', 'Ġaccused', 'Ġtold', 'Ġher', 'Ġto', 'Ġstop', 'Ġand', 'Ġlie', 'Ġdown', 'Ġon', 'Ġthe', 'Ġground', '.', 'ĠHe', 'Ġthen', 'Ġapproached', 'Ġher', 'Ġto', 'Ġremove', 'Ġher', 'Ġclothes', 'Ġand', 'Ġwarned', 'Ġher', 'Ġif', 'Ġshe', 'Ġdoesn', \"'t\", 'Ġthen', 'Ġhe', 'Ġwill', 'Ġbeat', 'Ġher', 'Ġwith', 'Ġa', 'Ġgu', 'ava', 'Ġstick', '.', 'ĠThe', 'Ġcomplainant', 'Ġwas', 'Ġscared', 'Ġwhen', 'Ġshe', 'Ġheard', 'Ġthis', 'Ġand', 'Ġfollowed', 'Ġthe', 'Ġaccused', \"'s\", 'Ġinstructions', '.', 'ĠWhen', 'Ġthe', 'Ġcomplainant', 'Ġgot', 'Ġund', 'ressed', 'Ġhe', 'Ġsaw', 'Ġthe', 'Ġaccused', 'Ġkneeling', 'Ġdown', 'Ġand', 'Ġusing', 'Ġhis', 'Ġtongue', 'Ġto', 'Ġlick', 'Ġher', 'Ġvagina', '.', 'ĠThe', 'Ġaccused', 'Ġthen', 'Ġun', 'z', 'ipped', 'Ġhis', 'ĠÂ', '¾', 'Ġpants', 'Ġand', 'Ġthen', 'Ġinserted', 'Ġhis', 'Ġerected', 'Ġpenis', 'Ġinto', 'Ġthe', 'Ġcomplainant', \"'s\", 'Ġvagina', '.', 'ĠShe', 'Ġwas', 'Ġin', 'Ġgreat', 'Ġpain', 'Ġand', 'Ġstarted', 'Ġcrying', '.', 'ĠShe', 'Ġwas', 'Ġhelpless', 'Ġas', 'Ġthe', 'Ġaccused', 'Ġon', 'Ġtop', 'Ġof', 'Ġher', '.', 'ĠShe', 'Ġcould', 'Ġfeel', 'Ġthat', 'Ġher', 'Ġvagina', 'Ġwas', 'Ġwet', '.', 'ĠWhen', 'Ġthe', 'Ġaccused', 'Ġrealized', 'Ġthat', 'Ġthe', 'Ġcomplainant', 'Ġwas', 'Ġcrying', ',', 'Ġhe', 'Ġinformed', 'Ġher', 'Ġto', 'Ġget', 'Ġup', ',', 'Ġget', 'Ġdressed', 'Ġand', 'Ġnot', 'Ġto', 'Ġinform', 'Ġanyone', 'Ġabout', 'Ġthis', 'Ġincident', '.', 'ĠWhen', 'Ġthe', 'Ġcomplainant', 'Ġwas', 'Ġwalking', 'Ġto', 'Ġthe', 'Ġriver', 'Ġshe', 'Ġcould', 'Ġfeel', 'Ġdrops', 'Ġof', 'Ġblood', 'Ġcoming', 'Ġout', 'Ġof', 'Ġher', 'Ġvagina', '.', 'ĠShe', 'Ġthen', 'Ġhad', 'Ġher', 'Ġbath', 'Ġand', 'Ġwent', 'Ġhome', 'Ġwithout', 'Ġinforming', 'Ġanyone', 'Ġas', 'Ġshe', 'Ġwas', 'Ġscared', 'Ġof', 'Ġthe', 'Ġaccused', 'Ġas', 'Ġhe', 'Ġmight', 'Ġdo', 'Ġsomething', 'Ġto', 'Ġher', '.', 'Ċ', 'Ċ', 'The', 'Ġsecond', 'Ġincident', 'Ġhappened', 'Ġsometimes', 'Ġin', 'ĠJuly', 'Ġ2012', 'Ġwhen', 'Ġthe', 'Ġcomplainant', \"'s\", 'Ġfather', 'Ġwas', 'Ġcutting', 'Ġcane', 'Ġat', 'ĠKor', 'o', 'ĠNo', '.', '2', '.', 'ĠThe', 'Ġcomplainant', \"'s\", 'Ġfamily', 'Ġwere', 'Ġresiding', 'Ġat', 'Ġan', 'ĠIndian', 'Ġman', \"'s\", 'Ġhouse', 'Ġin', 'ĠKor', 'o', 'ĠNo', '.', '2', '.', 'ĠDuring', 'Ġtheir', 'Ġstay', 'Ġin', 'ĠJuly', 'Ġ2012', ',', 'Ġone', 'Ġafternoon', 'Ġafter', 'Ġreturning', 'Ġfrom', 'Ġschool', 'Ġthe', 'Ġcomplainant', 'Ġwas', 'Ġinformed', 'Ġby', 'Ġher', 'Ġneighbours', 'Ġthat', 'Ġher', 'Ġmother', 'Ġand', 'Ġfather', 'Ġwere', 'Ġboth', 'Ġin', 'Ġthe', 'Ġfarm', '.', 'ĠShe', 'Ġentered', 'Ġthe', 'Ġhouse', 'Ġwhere', 'Ġthe', 'Ġfamily', 'Ġwas', 'Ġstaying', ',', 'Ġto', 'Ġher', 'Ġaston', 'ishment', 'Ġshe', 'Ġsaw', 'Ġthe', 'Ġaccused', 'Ġlying', 'Ġon', 'Ġthe', 'Ġfloor', '.', 'ĠShe', 'Ġquestioned', 'Ġher', 'Ġas', 'Ġto', 'Ġwhat', 'Ġhe', 'Ġis', 'Ġdoing', 'Ġhere', 'Ġand', 'Ġthe', 'Ġaccused', 'Ġinformed', 'Ġher', 'Ġthat', 'Ġhe', 'Ġis', 'Ġjust', 'Ġvisiting', '.', 'ĠThe', 'Ġcomplainant', 'Ġwas', 'Ġmoving', 'Ġin', 'Ġthe', 'Ġroom', 'Ġto', 'Ġfind', 'Ġher', 'Ġclothes', 'Ġwhen', 'Ġshe', 'Ġwas', 'Ġtold', 'Ġby', 'Ġthe', 'Ġaccused', 'Ġto', 'Ġsit', 'Ġon', 'Ġthe', 'Ġbed', '.', 'ĠShe', 'Ġtried', 'Ġto', 'Ġsee', 'Ġif', 'Ġanyone', 'Ġwas', 'Ġcoming', '.', 'ĠShe', 'Ġsaw', 'Ġher', 'Ġbrother', 'Ġat', 'Ġa', 'Ġdistant', 'Ġbut', 'Ġstill', 'Ġfar', 'Ġfrom', 'Ġher', 'Ġroom', '.', 'ĠThe', 'Ġaccused', 'Ġthen', 'Ġund', 'ressed', 'Ġthe', 'Ġcomplainant', 'Ġand', 'Ġhimself', 'Ġand', 'Ġinserted', 'Ġhis', 'Ġerected', 'Ġpenis', 'Ġinto', 'Ġthe', 'Ġcomplainant', \"'s\", 'Ġvagina', '.', 'ĠHe', 'Ġhad', 'Ġforceful', 'Ġsexual', 'Ġintercourse', 'Ġwith', 'Ġher', 'Ġfor', 'Ġtwo', 'Ġminutes', 'Ġas', 'Ġhe', 'Ġsaw', 'Ġthe', 'Ġcomplainant', \"'s\", 'Ġbrother', 'Ġapproaching', 'Ġthe', 'Ġroom', '.', 'ĠHe', 'Ġthen', 'Ġtold', 'Ġthe', 'Ġcomplainant', 'Ġto', 'Ġdress', 'Ġup', 'Ġand', 'Ġthen', 'Ġleft', 'Ġthe', 'Ġroom', 'Ġafter', 'Ġwarning', 'Ġthe', 'Ġcomplainant', '.', 'Ċ', 'Ċ', 'The', 'Ġaccused', 'Ġwas', 'Ġarrested', ',', 'Ġinterviewed', 'Ġunder', 'Ġcaution', 'Ġto', 'Ġwhich', 'Ġhe', 'Ġadmitted', 'Ġthe', 'Ġoffence', '.', 'ĊĊ', 'ĉ', '1', '.', 'ĉ', 'After', 'Ġcarefully', 'Ġconsidering', 'Ġthe', 'ĠPle', 'a', 'Ġof', 'Ġyou', 'Ġto', 'Ġbe', 'Ġunequiv', 'ocal', ',', 'Ġthis', 'ĠCourt', 'Ġfound', 'Ġyou', 'Ġguilty', 'Ġfor', 'Ġtwo', 'Ġcounts', 'Ġof', 'ĠRape', 'Ġand', 'Ġaccordingly', 'Ġyou', 'Ġare', 'Ġconvicted', 'Ġfor', 'Ġtwo', 'Ġcounts', 'Ġof', 'ĠRape', 'Ġunder', 'ĠSection', 'Ġ149', 'Ġand', 'Ġ150', 'Ġof', 'Ġthe', 'ĠPenal', 'ĠCode', ',', 'ĠCap', '17', '.', 'ĊĊ', 'ĉ', '2', '.', 'ĉ', 'Acc', 'used', 'ĠSere', 'ma', 'ia', 'ĠDel', 'a', 'Ġyou', 'Ġstand', 'Ġconvicted', 'Ġfor', 'Ġtwo', 'Ġcounts', 'Ġof', 'ĠRape', '.', 'ĊĊ', 'ĉ', '3', '.', 'ĉ', 'The', 'Ġtariff', 'Ġfor', 'Ġrape', 'Ġis', 'Ġwell', 'Ġsettled', 'Ġsince', 'Ġthe', 'ĠJudgment', 'Ġof', 'ĠHis', 'ĠLords', 'hip', 'ĠMr', '.', 'ĠA', '.', 'H', '.', 'C', '.', 'T', '.', 'ĠGates', 'Ġin', 'ĠState', 'Ġv', 'ĠMar', 'awa', '.', 'Ġ[', '2004', ']', 'ĠF', 'J', 'HC', 'Ġ338', ';', 'ĠH', 'AC', 'Ġ00', '16', 'T', '.', '2003', 'S', 'Ġ(', '23', 'ĠApril', 'Ġ2004', ').', 'ĠThe', 'Ġstarting', 'Ġpoint', 'Ġof', 'Ġa', 'Ġrape', 'Ġof', 'Ġan', 'Ġadult', 'Ġis', 'Ġ7', 'Ġyears', '.', 'ĠThe', 'Ġtariff', 'Ġis', 'Ġ7', 'Ġyears', 'Ġto', 'Ġ15', 'Ġyears', '.', 'ĊĊ', 'ĉ', '4', '.', 'ĉ', 'In', 'ĠMohamed', 'ĠKas', 'im', 'Ġv', 'ĠThe', 'ĠState', 'Ġ(', 'un', 'reported', ')', 'ĠFiji', 'ĠCourt', 'Ġof', 'ĠAppeal', 'ĠCr', '.', 'ĠCase', 'ĠNo', '.', 'Ġ14', 'Ġof', 'Ġ1993', ';', 'Ġ27', 'ĠMay', 'Ġ1994', ',', 'ĠThe', 'ĠCourt', 'Ġof', 'ĠAppeal', 'Ġobserved', ':', 'Ġ', 'Ċ', 'Ċ', '\"', 'We', 'Ġconsider', 'Ġthat', 'Ġat', 'Ġany', 'Ġrape', 'Ġcase', 'Ġwithout', 'Ġaggrav', 'ating', 'Ġor', 'Ġmitigating', 'Ġfeatures', 'Ġthe', 'Ġstarting', 'Ġpoint', 'Ġfor', 'Ġsentencing', 'Ġan', 'Ġadult', 'Ġshould', 'Ġbe', 'Ġa', 'Ġterm', 'Ġof', 'Ġimprisonment', 'Ġof', 'Ġseven', 'Ġyears', '.', 'ĠIt', 'Ġmust', 'Ġbe', 'Ġrecognized', 'Ġby', 'Ġthe', 'ĠCourts', 'Ġthat', 'Ġthe', 'Ġcrime', 'Ġof', 'Ġrape', 'Ġhas', 'Ġbecome', 'Ġaltogether', 'Ġtoo', 'Ġfrequent', 'Ġand', 'Ġthat', 'Ġthe', 'Ġsentences', 'Ġimposed', 'Ġby', 'Ġthe', 'ĠCourts', 'Ġfor', 'Ġthat', 'Ġcrime', 'Ġmust', 'Ġmore', 'Ġnearly', 'Ġreflect', 'Ġthe', 'Ġunderstandable', 'Ġpublic', 'Ġoutrage', '.', 'ĠWe', 'Ġmust', 'Ġstress', ',', 'Ġhowever', ',', 'Ġthat', 'Ġthe', 'Ġparticular', 'Ġcircumstances', 'Ġof', 'Ġa', 'Ġcase', 'Ġwill', 'Ġmean', 'Ġthat', 'Ġthere', 'Ġare', 'Ġcases', 'Ġwhere', 'Ġthe', 'Ġproper', 'Ġsentence', 'Ġmay', 'Ġbe', 'Ġsubstantially', 'Ġhigher', 'Ġor', 'Ġsubstantially', 'Ġlower', 'Ġthan', 'Ġthat', 'Ġstarting', 'Ġpoint', '.\"', 'ĊĊ', 'ĉ', '1', '.', 'ĉ', 'The', 'Ġtariff', 'Ġfor', 'Ġthe', 'Ġrape', 'Ġof', 'Ġchildren', 'Ġdiffers', 'Ġfrom', 'Ġthat', 'Ġof', 'Ġadults', 'Ġand', 'Ġtakes', 'Ġthe', 'Ġtariff', 'Ġof', 'Ġ10', 'Ġto', 'Ġ15', 'Ġyears', '.', 'Ġ', 'ĊĊ', 'ĉ', '2', '.', 'ĉ', 'In', 'ĠState', 'Ġv', 'ĠMario', 'ĠTau', 'vol', 'i', 'Ġ[', '2011', ']', 'ĠF', 'J', 'HC', 'Ġ216', ',', 'ĠH', 'AC', 'Ġ0', '27', '.', '2011', 'ĠHis', 'ĠLords', 'hip', 'ĠMr', '.', 'ĠPaul', 'ĠMad', 'igan', 'Ġheld', 'Ġthat', ':', 'Ċ', 'Ċ', '\"', 'R', 'ape', 'Ġof', 'Ġchildren', 'Ġis', 'Ġa', 'Ġvery', 'Ġserious', 'Ġoffence', 'Ġin', 'Ġdeed', 'Ġand', 'Ġit', 'Ġseems', 'Ġto', 'Ġbe', 'Ġvery', 'Ġprevalent', 'Ġin', 'ĠFiji', 'Ġat', 'Ġthe', 'Ġtime', '.', 'ĠThe', 'Ġlegislation', 'Ġhad', 'Ġdictated', 'Ġharsh', 'Ġpenalties', 'Ġand', 'Ġthe', 'ĠCourts', 'Ġare', 'Ġimposing', 'Ġthose', 'Ġpenalties', 'Ġin', 'Ġorder', 'Ġto', 'Ġreflect', 'Ġsociety', \"'s\", 'Ġabhor', 'rence', 'Ġfor', 'Ġsuch', 'Ġcrimes', '.', 'ĠOur', 'Ġnation', \"'s\", 'Ġchildren', 'Ġmust', 'Ġbe', 'Ġprotected', 'Ġand', 'Ġthey', 'Ġmust', 'Ġbe', 'Ġallowed', 'Ġto', 'Ġdevelop', 'Ġto', 'Ġsexual', 'Ġmaturity', 'Ġunm', 'ol', 'ested', '.', 'ĠPsych', 'ologists', 'Ġtell', 'Ġus', 'Ġthat', 'Ġthe', 'Ġeffect', 'Ġof', 'Ġsexual', 'Ġabuse', 'Ġon', 'Ġchildren', 'Ġin', 'Ġtheir', 'Ġlater', 'Ġdevelopment', 'Ġis', 'Ġprofound', '.\"', 'Ċ', 'Ċ', 'In', 'Ġthis', 'Ġcase', 'Ġ42', 'Ġyear', 'Ġstep', 'Ġfather', 'Ġwas', 'Ġsentenced', 'Ġfor', 'Ġ13', 'Ġyears', 'Ġwith', 'Ġnon', 'Ġparole', 'Ġperiod', 'Ġof', 'Ġ10', 'Ġyears', 'Ġfor', 'Ġdigital', 'Ġrape', 'Ġof', 'Ġ14', 'Ġyear', 'Ġold', 'Ġstep', 'Ġdaughter', '.', 'ĊĊ', 'ĉ', '1', '.', 'ĉ', 'In', 'ĠState', 'Ġv', 'ĠAnthony', 'Ġ[', '2012', ']', 'ĠF', 'J', 'HC', 'Ġ101', '3', ';', 'ĠH', 'AC', 'Ġ151', '.', '2010', 'ĠHis', 'ĠLords', 'hip', 'ĠMr', '.', 'ĠPri', 'yn', 'atha', 'ĠNaw', 'ana', 'Ġheld', 'Ġthat', ':', 'Ċ', 'Ċ', '\"', 'The', 'Ġaccused', \"'s\", 'Ġengagement', 'Ġin', 'Ġhis', 'Ġunilateral', 'Ġsexual', 'Ġactivity', 'Ġwith', 'Ġa', 'Ġlittle', 'Ġgirl', 'Ġwho', 'Ġwas', 'Ġinsensitive', 'Ġto', 'Ġsuch', 'Ġactivity', 'Ġis', 'Ġmost', 'Ġabhor', 'rent', '.', 'ĠThis', 'Ġkind', 'Ġof', 'Ġimmoral', 'Ġact', 'Ġon', 'Ġa', 'Ġlittle', 'Ġgirl', 'Ġof', 'ĠMB', \"'s\", 'Ġstanding', 'Ġis', 'Ġbound', 'Ġto', 'Ġyield', 'Ġadverse', 'Ġresults', 'Ġand', 'Ġpsychological', 'Ġtrauma', ',', 'Ġthe', 'Ġeffect', 'Ġof', 'Ġwhich', 'Ġis', 'Ġindeed', 'Ġdifficult', 'Ġto', 'Ġforesee', 'Ġand', 'Ġasses', 'Ġeven', 'Ġby', 'Ġpsychologists', 'Ġand', 'Ġsoc', 'i', 'ologists', '.', 'ĠThe', 'Ġdep', 'ravity', 'Ġof', 'Ġthe', 'Ġaccused', 'Ġin', 'Ġcommitting', 'Ġthe', 'Ġoffence', 'Ġshould', 'Ġbe', 'Ġdenounced', 'Ġto', 'Ġsave', 'Ġlittle', 'Ġchildren', 'Ġfor', 'Ġtheir', 'Ġown', 'Ġfuture', ';', 'Ġand', ',', 'Ġthe', 'Ġmen', 'Ġof', 'Ġthe', 'Ġaccused', \"'s\", 'Ġcaliber', 'Ġshould', 'Ġnot', 'Ġbe', 'Ġallowed', 'Ġto', 'Ġdeny', 'Ġthe', 'Ġchildren', 'Ġof', 'Ġtheir', 'Ġlegitimate', 'Ġplace', 'Ġin', 'Ġthe', 'Ġcommunity', '.', 'ĠIn', 'Ġpassing', 'Ġdown', 'Ġthe', 'Ġsentence', 'Ġin', 'Ġcase', 'Ġof', 'Ġthis', 'Ġnature', ',', 'Ġdeterrence', 'Ġis', 'Ġtherefore', ',', 'Ġof', 'Ġparamount', 'Ġimportance', '.\"', 'Ġ', 'ĊĊ', 'ĉ', '1', '.', 'ĉ', 'Considering', 'Ġthe', 'Ġabove', ',', 'ĠI', 'Ġcommence', 'Ġyour', 'Ġsentence', 'Ġat', 'Ġ13', 'Ġyears', 'Ġimprisonment', 'Ġfor', 'Ġeach', 'Ġcharge', 'Ġof', 'ĠRape', '.', 'ĊĊ', 'ĉ', '2', '.', 'ĉ', 'Agg', 'rav', 'ating', 'Ġfactors', ';', 'Ċ', 'ĉ', 'ĉ', '(', 'a', ')', 'ĠThe', 'Ġvictim', 'Ġwas', 'Ġof', 'Ġa', 'Ġyounger', 'Ġand', 'Ġtender', 'Ġage', ',', 'Ċ', 'ĉ', 'ĉ', '(', 'b', ')', 'ĠVictim', 'Ġwas', 'Ġsubjected', 'Ġto', 'Ġmore', 'Ġthan', 'Ġone', 'Ġsexual', 'Ġact', ',', 'Ċ', 'ĉ', 'ĉ', '(', 'c', ')', 'ĠYou', 'Ġhad', 'Ġmade', 'Ġthe', 'Ġvictim', 'Ġsexually', 'Ġactive', 'Ġat', 'Ġa', 'Ġyoung', 'Ġage', ',', 'Ċ', 'ĉ', 'ĉ', '(', 'd', ')', 'ĠYou', 'Ġhad', 'Ġtraumat', 'ized', 'Ġthe', 'Ġlife', 'Ġof', 'Ġthe', 'Ġvictim', '.', 'Ċ', 'Ċ', 'Considering', 'Ġall', ',', 'ĠI', 'Ġincrease', 'Ġyour', 'Ġsentence', 'Ġby', 'Ġ3', 'Ġyears', ',', 'Ġnow', 'Ġthe', 'Ġsentence', 'Ġis', 'Ġ16', 'Ġyears', 'Ġimprisonment', '.', 'ĊĊ', 'ĉ', '1', '.', 'ĉ', 'Mit', 'igating', 'Ġcircumstances', ':', 'Ċ', 'Ċ', '(', 'a', ')', 'ĠYou', 'Ġare', 'Ġfirst', 'Ġoffender', 'Ġat', 'Ġthe', 'Ġage', 'Ġof', 'Ġ38', 'Ġyears', 'Ġuntil', 'Ġyou', 'Ġwere', 'Ġconvicted', 'Ġand', 'Ġsentenced', 'Ġby', 'Ġthis', 'ĠCourt', 'Ġon', 'Ġ29', '.', '11', '.', '2013', '.', 'Ġ', 'Ċ', 'Considering', 'Ġall', ',', 'ĠI', 'Ġreduce', 'Ġ1', 'Ġyear', 'Ġfrom', 'Ġyour', 'Ġsentence', 'Ġnow', 'Ġyour', 'Ġsentence', 'Ġis', 'Ġ15', 'Ġyears', 'Ġimprisonment', '.', 'ĊĊ', 'ĉ', '1', '.', 'ĉ', 'For', 'Ġthe', 'Ġguilty', 'Ġplea', ',', 'ĠI', 'Ġdeduct', 'Ġ3', 'Ġyears', 'Ġand', 'Ġnow', 'Ġyour', 'Ġsentence', 'Ġis', 'Ġ12', 'Ġyears', '.', 'ĊĊ', 'ĉ', '2', '.', 'ĉ', 'You', 'Ġwere', 'Ġin', 'Ġrem', 'and', 'Ġfrom', 'Ġ12', '.', '6', '.', '2013', 'Ġfor', 'Ġa', 'Ġperiod', 'Ġof', 'Ġ5', 'Ġmonths', '.', 'ĠThat', 'Ġperiod', 'Ġwas', 'Ġdeducted', 'Ġin', 'Ġthe', 'Ġsentence', 'Ġof', 'ĠH', 'AC', 'Ġ125', '/', '2013', '.', 'ĊĊ', 'ĉ', '3', '.', 'ĉ', 'Considering', 'ĠSection', 'Ġ18', 'Ġ(', '1', ')', 'Ġof', 'Ġthe', 'ĠSent', 'encing', 'Ġand', 'ĠPen', 'alties', 'ĠDec', 'ree', ',', 'ĠI', 'Ġimpose', 'Ġ11', 'Ġyears', 'Ġas', 'Ġnon', 'Ġparole', 'Ġperiod', '.', 'ĊĊ', 'ĉ', '4', '.', 'ĉ', 'Your', 'Ġsentences', 'Ġare', 'Ġas', 'Ġfollows', ':', 'Ġ', 'Ċ', 'ĉ', 'ĉ', '(', 'i', ')', 'Ġ1', 'st', 'Ġcount', 'Ġof', 'ĠRape', 'Ġ-', 'Ġ12', 'Ġyears', 'Ġ', 'Ċ', 'ĉ', 'ĉ', '(', 'ii', ')', 'Ġ2', 'nd', 'Ġcount', 'Ġof', 'ĠRape', 'Ġ-', 'Ġ12', 'Ġyears', 'Ġ', 'ĊĊ', 'ĉ', '5', '.', 'ĉ', 'The', 'ĠFiji', 'ĠCourt', 'Ġof', 'ĠAppeal', 'Ġin', 'ĠV', 'uk', 'it', 'oga', 'Ġv', 'ĠState', 'Ġ[', '2013', ']', 'ĠF', 'J', 'CA', 'Ġ19', ';', 'ĠAA', 'U', 'Ġ00', '49', '.', '2008', 'Ġ(', '13', 'ĠMarch', 'Ġ2013', ')', 'Ġcited', 'Ġwith', 'Ġapproval', 'Ġthe', 'Ġfollowing', 'Ġcitation', 'Ġof', 'ĠD', '.', 'A', '.', 'ĠThomas', ',', 'ĠPrinciples', 'Ġof', 'ĠSent', 'encing', 'Ġ(', '2', 'nd', 'Ġedition', ',', 'Ġ1979', ')', 'Ġp', '.', 'Ġ56', '-', '57', 'Ġwhich', 'Ġwas', 'Ġcited', 'Ġin', 'ĠHigh', 'ĠCourt', 'Ġof', 'ĠAustralia', 'Ġjudgment', 'ĠMill', 'Ġv', 'ĠThe', 'ĠQueen', 'Ġ[', '1988', ']', 'ĠH', 'CA', 'Ġ70', ':', 'Ċ', 'Ċ', '\"', 'The', 'Ġeffect', 'Ġof', 'Ġthe', 'Ġtotality', 'Ġprinciple', 'Ġis', 'Ġto', 'Ġrequire', 'Ġa', 'Ġsent', 'encer', 'Ġwho', 'Ġhas', 'Ġpassed', 'Ġa', 'Ġseries', 'Ġof', 'Ġsentences', ',', 'Ġeach', 'Ġproperly', 'Ġcalculated', 'Ġin', 'Ġrelation', 'Ġto', 'Ġthe', 'Ġoffence', 'Ġfor', 'Ġwhich', 'Ġit', 'Ġis', 'Ġimposed', 'Ġand', 'Ġeach', 'Ġproperly', 'Ġmade', 'Ġconsecutive', 'Ġin', 'Ġaccordance', 'Ġwith', 'Ġthe', 'Ġprinciples', 'Ġgoverning', 'Ġconsecutive', 'Ġsentences', ',', 'Ġto', 'Ġreview', 'Ġthe', 'Ġaggregate', 'Ġsentence', 'Ġand', 'Ġconsider', 'Ġwhether', 'Ġthe', 'Ġaggregate', 'Ġis', \"Ġ'\", 'just', 'Ġand', 'Ġappropriate', \"'.\", 'ĠThe', 'Ġprinciple', 'Ġhas', 'Ġbeen', 'Ġstated', 'Ġmany', 'Ġtimes', 'Ġin', 'Ġvarious', 'Ġforms', ':', \"Ġ'\", 'when', 'Ġa', 'Ġnumber', 'Ġof', 'Ġoffences', 'Ġare', 'Ġbeing', 'Ġdealt', 'Ġwith', 'Ġand', 'Ġspecific', 'Ġpunishments', 'Ġin', 'Ġrespect', 'Ġof', 'Ġthem', 'Ġare', 'Ġbeing', 'Ġto', 'tted', 'Ġup', 'Ġto', 'Ġmake', 'Ġa', 'Ġtotal', ',', 'Ġit', 'Ġis', 'Ġalways', 'Ġnecessary', 'Ġfor', 'Ġthe', 'Ġcourt', 'Ġto', 'Ġtake', 'Ġa', 'Ġlast', 'Ġlook', 'Ġat', 'Ġthe', 'Ġtotal', 'Ġjust', 'Ġto', 'Ġsee', 'Ġwhether', 'Ġit', 'Ġlooks', 'Ġwrong', \"';\", 'Ġ\"', 'when', '...', 'Ġcases', 'Ġof', 'Ġmultipl', 'icity', 'Ġof', 'Ġoffences', 'Ġcome', 'Ġbefore', 'Ġthe', 'Ġcourt', ',', 'Ġthe', 'Ġcourt', 'Ġmust', 'Ġnot', 'Ġcontent', 'Ġitself', 'Ġby', 'Ġdoing', 'Ġthe', 'Ġarithmetic', 'Ġand', 'Ġpassing', 'Ġthe', 'Ġsentence', 'Ġwhich', 'Ġthe', 'Ġarithmetic', 'Ġproduces', '.', 'ĠIt', 'Ġmust', 'Ġlook', 'Ġat', 'Ġthe', 'Ġtotality', 'Ġof', 'Ġthe', 'Ġcriminal', 'Ġbehavior', 'Ġand', 'Ġask', 'Ġitself', 'Ġwhat', 'Ġis', 'Ġthe', 'Ġappropriate', 'Ġsentence', 'Ġfor', 'Ġall', 'Ġthe', 'Ġoffences', '.\"', 'ĊĊ', 'ĉ', '1', '.', 'ĉ', 'Considering', 'Ġthe', 'Ġtotality', 'Ġprinciple', ',', 'ĠI', 'Ġorder', 'Ġthe', 'Ġsentences', 'Ġof', 'Ġboth', 'Ġcharges', 'Ġto', 'Ġrun', 'Ġconcurrently', '.', 'ĊĊ', 'ĉ', '2', '.', 'ĉ', 'Further', 'Ġyou', 'Ġare', 'Ġalready', 'Ġserving', 'Ġa', 'Ġsentence', 'Ġof', 'Ġ11', 'Ġyears', 'Ġ7', 'Ġmonths', 'Ġgiven', 'Ġto', 'Ġyou', 'Ġon', 'Ġ29', '.', '11', '.', '2013', '.', 'ĠYou', 'Ġhave', 'Ġpleaded', 'Ġguilty', 'Ġto', 'Ġall', 'Ġthe', 'Ġcharges', 'Ġin', 'Ġfive', 'Ġseparate', 'Ġsimilar', 'Ġcases', '.', 'Ċ', 'If', 'Ġseparate', 'Ġsentences', 'Ġare', 'Ġgiven', 'Ġfor', 'Ġeach', 'Ġof', 'Ġthese', 'Ġcases', 'Ġit', 'Ġwill', 'Ġhave', 'Ġa', 'Ġcrushing', 'Ġeffect', 'Ġon', 'Ġyou', '.', 'ĠThe', 'ĠState', 'Ġhad', 'Ġconceded', 'Ġthis', 'Ġposition', '.', 'ĠThus', ',', 'ĠI', 'Ġorder', 'Ġthis', 'Ġsentence', 'Ġto', 'Ġrun', 'Ġconcurrently', 'Ġwith', 'Ġthe', 'Ġsentences', 'Ġyou', 'Ġare', 'Ġalready', 'Ġserving', '.', 'ĊĊ', 'ĉ', '1', '.', 'ĉ', 'There', 'Ġwas', 'Ġreport', 'Ġfrom', 'Ġpsychiatrist', 'ĠVictor', 'ĠHerald', 'ĠWass', 'on', 'Ġthat', 'Ġyou', 'Ġare', 'Ġfit', 'Ġto', 'Ġplea', '.', 'ĠThe', 'Ġdoctor', 'Ġwas', 'Ġcalled', 'Ġto', 'Ġgive', 'Ġevidence', '.', 'ĠAccording', 'Ġto', 'Ġhim', 'Ġyou', 'Ġhad', 'Ġschizophrenia', '.', 'ĠNow', 'Ġyou', 'Ġare', 'Ġtreated', 'Ġand', 'Ġfit', 'Ġto', 'Ġplea', '.', 'ĠFurther', 'Ġsuch', 'Ġtreatment', 'Ġcould', 'Ġbe', 'Ġcontinued', 'Ġwhile', 'Ġyou', 'Ġare', 'Ġin', 'Ġrem', 'and', '.', 'ĠOnce', 'Ġyou', 'Ġare', 'Ġserved', 'Ġthe', 'Ġterm', ',', 'Ġa', 'Ġcommunity', 'Ġtreatment', 'Ġorder', 'Ġcould', 'Ġbe', 'Ġissued', 'Ġif', 'Ġneeded', '.', 'Ċ', 'Ċ', 'Summary', 'ĊĊ', 'ĉ', '1', '.', 'ĉ', 'You', 'Ġare', 'Ġsentenced', 'Ġto', 'Ġ12', 'Ġyears', 'Ġimprisonment', '.', 'ĠYou', 'Ġwill', 'Ġnot', 'Ġbe', 'Ġeligible', 'Ġfor', 'Ġparole', 'Ġuntil', 'Ġyou', 'Ġcomplete', 'Ġserving', 'Ġ11', 'Ġyears', 'Ġof', 'Ġimprisonment', '.', 'ĠThis', 'Ġsentence', 'Ġto', 'Ġrun', 'Ġconcurrently', 'Ġwith', 'Ġother', 'Ġsentences', 'Ġalready', 'Ġordered', '.', 'ĊĊ', 'ĉ', '2', '.', 'ĉ', 'Pr', 'ison', 'Ġauthorities', 'Ġare', 'Ġdirected', 'Ġto', 'Ġcontinue', 'Ġwith', 'Ġthe', 'Ġtreatment', 'Ġof', 'Ġyou', 'Ġacting', 'Ġunder', 'ĠSection', 'Ġ86', 'Ġ(', '1', ')', 'Ġ&', 'Ġ(', '2', ')', 'Ġof', 'Ġthe', 'ĠMental', 'ĠHealth', 'ĠDec', 'ree', ',', 'Ġ2010', '.', 'Ġ', 'ĊĊ', 'ĉ', '3', '.', 'ĉ', '30', 'Ġdays', 'Ġto', 'Ġappeal', 'Ġto', 'ĠCourt', 'Ġof', 'ĠAppeal', '.', 'Ċ', 'Ċ', 'S', 'ud', 'h', 'arsh', 'ana', 'ĠDe', 'ĠSilva', 'Ċ', 'J', 'UD', 'GE', 'Ċ', 'Ċ', 'AT', 'ĠLA', 'UT', 'OK', 'A', 'Ċ', 'On', 'Ġ06', 'th', 'ĠDecember', 'Ġ2013', 'Ċ', 'Ċ', 'Sol', 'icit', 'ors', 'Ġfor', 'Ġthe', 'ĠState', ':', 'ĠOffice', 'Ġof', 'Ġthe', 'ĠDirector', 'Ġof', 'ĠPublic', 'ĠPro', 'secution', 'Ċ', 'Sol', 'icit', 'ors', 'Ġfor', 'Ġthe', 'ĠAcc', 'used', ':', 'ĠOffice', 'Ġof', 'Ġthe', 'ĠLegal', 'ĠAid', 'ĠCommission', 'Ġ', 'ĊĊ', 'Ċ', 'Pac', 'L', 'II', ':', 'ĠCopyright', 'ĠPolicy', 'Ġ|', 'ĠDis', 'claim', 'ers', 'Ġ|', 'ĠPrivacy', 'ĠPolicy', 'Ġ|', 'ĠFeedback', 'Ċ', 'URL', ':', 'Ġ<', 'URL', '>', 'ĊĊ', 'ĊĊ', 'Ċ']\n"
     ]
    }
   ],
   "source": [
    "# Print the original sentence.\n",
    "#print(' Original: ', df['text'][0])\n",
    "\n",
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(df['text'][0]))\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "#print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "Kb0EqWUrM5eJ",
    "outputId": "e1b6d7a7-004c-4b95-fe81-688f42c1cece"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f8f6b826630>"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['text'].apply(lambda x: len(x.split()) if len(x.split())<4000 else 4000).plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "fsfAKFdTNS__",
    "outputId": "5ef8cc83-9d21-471d-de19-c6482b98cbf9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>len_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>647.000000</td>\n",
       "      <td>647.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.571870</td>\n",
       "      <td>1516.514683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.495191</td>\n",
       "      <td>1698.831551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>750.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1123.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1635.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>28652.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            label       len_txt\n",
       "count  647.000000    647.000000\n",
       "mean     0.571870   1516.514683\n",
       "std      0.495191   1698.831551\n",
       "min      0.000000     99.000000\n",
       "25%      0.000000    750.500000\n",
       "50%      1.000000   1123.000000\n",
       "75%      1.000000   1635.500000\n",
       "max      1.000000  28652.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['len_txt'] =df['text'].apply(lambda x: len(x.split()))\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "v4qEn_AONl0V",
    "outputId": "af859620-fc59-4c35-ab63-3855fe556148"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "358"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['len_txt'] > 1024]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N4iGX0oA_5Ko"
   },
   "outputs": [],
   "source": [
    "# Combine the training inputs into a TensorDataset.\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "hjaZOiqV_5Kq",
    "outputId": "e41f6ac0-cc37-4899-a0d8-81d5b8e0c66c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "647\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "# check size of embeddings\n",
    "print(len(input_ids))\n",
    "print(len(input_ids[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n_X8c-AaDqTI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-LUl293eOESc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "4SSD8wCT_5Ks",
    "outputId": "a951d267-47ec-49a8-811d-f1d3236d4788"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  582 training samples\n",
      "   65 validation samples\n"
     ]
    }
   ],
   "source": [
    "# Create a 90-10 train-validation split.\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-YSQ87ha_5Kv"
   },
   "outputs": [],
   "source": [
    "# Create the DataLoaders for our training and validation sets.\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V4sVuVoL_5K0"
   },
   "outputs": [],
   "source": [
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = lr, \n",
    "                  eps = 1e-8 \n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "OpCOLW4q_5Kx",
    "outputId": "bd0bf7ba-d7e2-4cff-ce7d-48f624f0394e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LongformerForSequenceClassification(\n",
       "  (longformer): LongformerModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(4098, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): LongformerEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (classifier): LongformerClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tell pytorch to run this model on the GPU.\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "colab_type": "code",
    "id": "NH3yaw18CYcb",
    "outputId": "3f1712f6-5b5c-4c49-ad53-5fb1bae6bfc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 275 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "longformer.embeddings.word_embeddings.weight            (50265, 768)\n",
      "longformer.embeddings.position_embeddings.weight         (4098, 768)\n",
      "longformer.embeddings.token_type_embeddings.weight          (1, 768)\n",
      "longformer.embeddings.LayerNorm.weight                        (768,)\n",
      "longformer.embeddings.LayerNorm.bias                          (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "longformer.encoder.layer.0.attention.self.query.weight    (768, 768)\n",
      "longformer.encoder.layer.0.attention.self.query.bias          (768,)\n",
      "longformer.encoder.layer.0.attention.self.key.weight      (768, 768)\n",
      "longformer.encoder.layer.0.attention.self.key.bias            (768,)\n",
      "longformer.encoder.layer.0.attention.self.value.weight    (768, 768)\n",
      "longformer.encoder.layer.0.attention.self.value.bias          (768,)\n",
      "longformer.encoder.layer.0.attention.self.query_global.weight   (768, 768)\n",
      "longformer.encoder.layer.0.attention.self.query_global.bias       (768,)\n",
      "longformer.encoder.layer.0.attention.self.key_global.weight   (768, 768)\n",
      "longformer.encoder.layer.0.attention.self.key_global.bias       (768,)\n",
      "longformer.encoder.layer.0.attention.self.value_global.weight   (768, 768)\n",
      "longformer.encoder.layer.0.attention.self.value_global.bias       (768,)\n",
      "longformer.encoder.layer.0.attention.output.dense.weight   (768, 768)\n",
      "longformer.encoder.layer.0.attention.output.dense.bias        (768,)\n",
      "longformer.encoder.layer.0.attention.output.LayerNorm.weight       (768,)\n",
      "longformer.encoder.layer.0.attention.output.LayerNorm.bias       (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "classifier.dense.weight                                   (768, 768)\n",
      "classifier.dense.bias                                         (768,)\n",
      "classifier.out_proj.weight                                  (2, 768)\n",
      "classifier.out_proj.bias                                        (2,)\n"
     ]
    }
   ],
   "source": [
    "# Get all of the model's parameters as a list of tuples.\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zvoMRhpaQVcC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vmZH3X0J_5K1"
   },
   "outputs": [],
   "source": [
    "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "epochs = num_epochs\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "total_steps = len(train_dataloader) * epochs\n",
    "warmup_steps = total_steps * 0.1\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = warmup_steps, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "1GsKTWcy_5K3",
    "outputId": "97e1820f-eb0d-41ba-80ff-d91a3b780f22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 15 ========\n",
      "Training...\n",
      "  Batch    16  of     73.    Elapsed: 0:00:15.\n",
      "  Batch    32  of     73.    Elapsed: 0:00:29.\n",
      "  Batch    48  of     73.    Elapsed: 0:00:44.\n",
      "  Batch    64  of     73.    Elapsed: 0:00:58.\n",
      "\n",
      "  Average training loss: 0.67\n",
      "  Training epcoh took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.65\n",
      "  Validation Loss: 0.67\n",
      "  Validation took: 0:00:02\n",
      "\n",
      "======== Epoch 2 / 15 ========\n",
      "Training...\n",
      "  Batch    16  of     73.    Elapsed: 0:00:15.\n",
      "  Batch    32  of     73.    Elapsed: 0:00:29.\n",
      "  Batch    48  of     73.    Elapsed: 0:00:44.\n",
      "  Batch    64  of     73.    Elapsed: 0:00:58.\n",
      "\n",
      "  Average training loss: 0.68\n",
      "  Training epcoh took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.64\n",
      "  Validation Loss: 0.64\n",
      "  Validation took: 0:00:02\n",
      "\n",
      "======== Epoch 3 / 15 ========\n",
      "Training...\n",
      "  Batch    16  of     73.    Elapsed: 0:00:15.\n",
      "  Batch    32  of     73.    Elapsed: 0:00:29.\n",
      "  Batch    48  of     73.    Elapsed: 0:00:44.\n",
      "  Batch    64  of     73.    Elapsed: 0:00:58.\n",
      "\n",
      "  Average training loss: 0.66\n",
      "  Training epcoh took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.67\n",
      "  Validation Loss: 0.64\n",
      "  Validation took: 0:00:02\n",
      "\n",
      "======== Epoch 4 / 15 ========\n",
      "Training...\n",
      "  Batch    16  of     73.    Elapsed: 0:00:15.\n",
      "  Batch    32  of     73.    Elapsed: 0:00:29.\n",
      "  Batch    48  of     73.    Elapsed: 0:00:44.\n",
      "  Batch    64  of     73.    Elapsed: 0:00:58.\n",
      "\n",
      "  Average training loss: 0.61\n",
      "  Training epcoh took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.65\n",
      "  Validation Loss: 0.79\n",
      "  Validation took: 0:00:02\n",
      "\n",
      "======== Epoch 5 / 15 ========\n",
      "Training...\n",
      "  Batch    16  of     73.    Elapsed: 0:00:15.\n",
      "  Batch    32  of     73.    Elapsed: 0:00:29.\n",
      "  Batch    48  of     73.    Elapsed: 0:00:44.\n",
      "  Batch    64  of     73.    Elapsed: 0:00:58.\n",
      "\n",
      "  Average training loss: 0.56\n",
      "  Training epcoh took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.62\n",
      "  Validation Loss: 0.81\n",
      "  Validation took: 0:00:02\n",
      "\n",
      "======== Epoch 6 / 15 ========\n",
      "Training...\n",
      "  Batch    16  of     73.    Elapsed: 0:00:15.\n",
      "  Batch    32  of     73.    Elapsed: 0:00:29.\n",
      "  Batch    48  of     73.    Elapsed: 0:00:44.\n",
      "  Batch    64  of     73.    Elapsed: 0:00:58.\n",
      "\n",
      "  Average training loss: 0.43\n",
      "  Training epcoh took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.56\n",
      "  Validation Loss: 0.82\n",
      "  Validation took: 0:00:02\n",
      "\n",
      "======== Epoch 7 / 15 ========\n",
      "Training...\n",
      "  Batch    16  of     73.    Elapsed: 0:00:15.\n",
      "  Batch    32  of     73.    Elapsed: 0:00:29.\n",
      "  Batch    48  of     73.    Elapsed: 0:00:44.\n",
      "  Batch    64  of     73.    Elapsed: 0:00:58.\n",
      "\n",
      "  Average training loss: 0.33\n",
      "  Training epcoh took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.61\n",
      "  Validation Loss: 1.10\n",
      "  Validation took: 0:00:02\n",
      "\n",
      "======== Epoch 8 / 15 ========\n",
      "Training...\n",
      "  Batch    16  of     73.    Elapsed: 0:00:15.\n",
      "  Batch    32  of     73.    Elapsed: 0:00:29.\n",
      "  Batch    48  of     73.    Elapsed: 0:00:44.\n",
      "  Batch    64  of     73.    Elapsed: 0:00:58.\n",
      "\n",
      "  Average training loss: 0.24\n",
      "  Training epcoh took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.58\n",
      "  Validation Loss: 1.69\n",
      "  Validation took: 0:00:02\n",
      "\n",
      "======== Epoch 9 / 15 ========\n",
      "Training...\n",
      "  Batch    16  of     73.    Elapsed: 0:00:15.\n",
      "  Batch    32  of     73.    Elapsed: 0:00:29.\n",
      "  Batch    48  of     73.    Elapsed: 0:00:44.\n",
      "  Batch    64  of     73.    Elapsed: 0:00:58.\n",
      "\n",
      "  Average training loss: 0.21\n",
      "  Training epcoh took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.58\n",
      "  Validation Loss: 2.14\n",
      "  Validation took: 0:00:02\n",
      "\n",
      "======== Epoch 10 / 15 ========\n",
      "Training...\n",
      "  Batch    16  of     73.    Elapsed: 0:00:15.\n",
      "  Batch    32  of     73.    Elapsed: 0:00:29.\n",
      "  Batch    48  of     73.    Elapsed: 0:00:44.\n",
      "  Batch    64  of     73.    Elapsed: 0:00:58.\n",
      "\n",
      "  Average training loss: 0.12\n",
      "  Training epcoh took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.56\n",
      "  Validation Loss: 2.64\n",
      "  Validation took: 0:00:02\n",
      "\n",
      "======== Epoch 11 / 15 ========\n",
      "Training...\n",
      "  Batch    16  of     73.    Elapsed: 0:00:15.\n",
      "  Batch    32  of     73.    Elapsed: 0:00:29.\n",
      "  Batch    48  of     73.    Elapsed: 0:00:44.\n",
      "  Batch    64  of     73.    Elapsed: 0:00:58.\n",
      "\n",
      "  Average training loss: 0.06\n",
      "  Training epcoh took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.57\n",
      "  Validation Loss: 2.79\n",
      "  Validation took: 0:00:02\n",
      "\n",
      "======== Epoch 12 / 15 ========\n",
      "Training...\n",
      "  Batch    16  of     73.    Elapsed: 0:00:15.\n",
      "  Batch    32  of     73.    Elapsed: 0:00:29.\n",
      "  Batch    48  of     73.    Elapsed: 0:00:44.\n",
      "  Batch    64  of     73.    Elapsed: 0:00:58.\n",
      "\n",
      "  Average training loss: 0.03\n",
      "  Training epcoh took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.61\n",
      "  Validation Loss: 2.78\n",
      "  Validation took: 0:00:02\n",
      "\n",
      "======== Epoch 13 / 15 ========\n",
      "Training...\n",
      "  Batch    16  of     73.    Elapsed: 0:00:15.\n",
      "  Batch    32  of     73.    Elapsed: 0:00:29.\n",
      "  Batch    48  of     73.    Elapsed: 0:00:44.\n",
      "  Batch    64  of     73.    Elapsed: 0:00:58.\n",
      "\n",
      "  Average training loss: 0.03\n",
      "  Training epcoh took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.57\n",
      "  Validation Loss: 2.95\n",
      "  Validation took: 0:00:02\n",
      "\n",
      "======== Epoch 14 / 15 ========\n",
      "Training...\n",
      "  Batch    16  of     73.    Elapsed: 0:00:15.\n",
      "  Batch    32  of     73.    Elapsed: 0:00:29.\n",
      "  Batch    48  of     73.    Elapsed: 0:00:44.\n",
      "  Batch    64  of     73.    Elapsed: 0:00:58.\n",
      "\n",
      "  Average training loss: 0.03\n",
      "  Training epcoh took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.60\n",
      "  Validation Loss: 2.85\n",
      "  Validation took: 0:00:02\n",
      "\n",
      "======== Epoch 15 / 15 ========\n",
      "Training...\n",
      "  Batch    16  of     73.    Elapsed: 0:00:15.\n",
      "  Batch    32  of     73.    Elapsed: 0:00:29.\n",
      "  Batch    48  of     73.    Elapsed: 0:00:44.\n",
      "  Batch    64  of     73.    Elapsed: 0:00:58.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.58\n",
      "  Validation Loss: 2.93\n",
      "  Validation took: 0:00:02\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:17:04 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "device = torch.device(\"cuda\")\n",
    "training_stats = []\n",
    "total_t0 = time.time()\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        if step % 16 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        b_input_ids = batch[0].to(device) # input ids\n",
    "        b_input_mask = batch[1].to(device) # attention masks\n",
    "        b_labels = batch[2].to(device) # labels\n",
    "\n",
    "        # Clear previously calculated gradients before performing backward pass. \n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Forward pass\n",
    "        loss, logits = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)\n",
    "\n",
    "        total_train_loss += loss.item() # Accumulate the training loss over all of the batches \n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0. to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            (loss, logits) = model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels)\n",
    "            \n",
    "        # Accumulate the validation loss.\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences, and accumulate over all batches.\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    \n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "colab_type": "code",
    "id": "hQla5mCH_5K4",
    "outputId": "b5e36989-3aeb-49eb-9259-9be5cec280dc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Valid. Loss</th>\n",
       "      <th>Valid. Accur.</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Validation Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0:01:06</td>\n",
       "      <td>0:00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0:01:06</td>\n",
       "      <td>0:00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0:01:06</td>\n",
       "      <td>0:00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0:01:06</td>\n",
       "      <td>0:00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0:01:06</td>\n",
       "      <td>0:00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0:01:06</td>\n",
       "      <td>0:00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.33</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0:01:06</td>\n",
       "      <td>0:00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.24</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0:01:06</td>\n",
       "      <td>0:00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.21</td>\n",
       "      <td>2.14</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0:01:06</td>\n",
       "      <td>0:00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.12</td>\n",
       "      <td>2.64</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0:01:06</td>\n",
       "      <td>0:00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.06</td>\n",
       "      <td>2.79</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0:01:06</td>\n",
       "      <td>0:00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.03</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0:01:06</td>\n",
       "      <td>0:00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.03</td>\n",
       "      <td>2.95</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0:01:06</td>\n",
       "      <td>0:00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.03</td>\n",
       "      <td>2.85</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0:01:06</td>\n",
       "      <td>0:00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0:01:06</td>\n",
       "      <td>0:00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
       "epoch                                                                         \n",
       "1               0.67         0.67           0.65       0:01:06         0:00:02\n",
       "2               0.68         0.64           0.64       0:01:06         0:00:02\n",
       "3               0.66         0.64           0.67       0:01:06         0:00:02\n",
       "4               0.61         0.79           0.65       0:01:06         0:00:02\n",
       "5               0.56         0.81           0.62       0:01:06         0:00:02\n",
       "6               0.43         0.82           0.56       0:01:06         0:00:02\n",
       "7               0.33         1.10           0.61       0:01:06         0:00:02\n",
       "8               0.24         1.69           0.58       0:01:06         0:00:02\n",
       "9               0.21         2.14           0.58       0:01:06         0:00:02\n",
       "10              0.12         2.64           0.56       0:01:06         0:00:02\n",
       "11              0.06         2.79           0.57       0:01:06         0:00:02\n",
       "12              0.03         2.78           0.61       0:01:06         0:00:02\n",
       "13              0.03         2.95           0.57       0:01:06         0:00:02\n",
       "14              0.03         2.85           0.60       0:01:06         0:00:02\n",
       "15              0.01         2.93           0.58       0:01:06         0:00:02"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display Results\n",
    "pd.set_option('precision', 2)\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "colab_type": "code",
    "id": "_QQciFO3_5K7",
    "outputId": "4dff6a0d-9d5b-4184-a461-bd9bf928fe75"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the learning curve.\n",
    "\n",
    "sns.set(style='darkgrid')\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
    "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.xticks([1, 2, 3, 4, 5, 6, 7, 8, 9,10,11,12,13,14,15])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qEChtbKj_5K9"
   },
   "source": [
    "# TEST THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "ISE5rHB7_5K9",
    "outputId": "e48a707f-39f0-401e-aeb0-b785b190a34c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SENTENCE\\n\\n[Name of the victim is suppressed....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JUDGMENT\\n\\nThis is an appeal against convicti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JUDGMENT\\n\\n1. On 13 May 2008, the Appellant, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JUDGMENT\\n[1] On the 17th July 2012 in the Nas...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SENTENCE\\n\\nBackground \\n\\n1. The accused was ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  SENTENCE\\n\\n[Name of the victim is suppressed....      1\n",
       "1  JUDGMENT\\n\\nThis is an appeal against convicti...      1\n",
       "2  JUDGMENT\\n\\n1. On 13 May 2008, the Appellant, ...      1\n",
       "3  JUDGMENT\\n[1] On the 17th July 2012 in the Nas...      0\n",
       "4  SENTENCE\\n\\nBackground \\n\\n1. The accused was ...      1"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Holdout\n",
    "df = get_data(test_file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KQSTZBeA_5K_"
   },
   "outputs": [],
   "source": [
    "# Get tokenized labels\n",
    "if use_global_mask:\n",
    "    input_ids, attention_masks, labels = tokenize_manual(df)\n",
    "else:\n",
    "    input_ids, attention_masks, labels = tokenize_plus(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3J0sZyKc_5LB"
   },
   "outputs": [],
   "source": [
    "# create dataloader from input tensors, to help with memory usage\n",
    "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "8w24knQ3_5LC",
    "outputId": "3ac3c1ad-3855-42ec-d298-f7e6d56d69c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 162 test sentences...\n",
      "    DONE.\n"
     ]
    }
   ],
   "source": [
    "# Prediction on test set\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict \n",
    "for batch in prediction_dataloader:\n",
    "  # Add batch to GPU\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "  \n",
    "  # Unpack the inputs from our dataloader\n",
    "  b_input_ids, b_input_mask, b_labels = batch\n",
    "  \n",
    "  # Telling the model not to compute or store gradients, saving memory and \n",
    "  # speeding up prediction\n",
    "  with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      outputs = model(b_input_ids, token_type_ids=None, \n",
    "                      attention_mask=b_input_mask)\n",
    "\n",
    "  logits = outputs[0]\n",
    "\n",
    "  # Move logits and labels to CPU\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "  \n",
    "  # Store predictions and true labels\n",
    "  predictions.append(logits)\n",
    "  true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CUWhr_fD_5LE",
    "outputId": "2da51848-8a6c-48c8-ad98-77e8654c14a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive samples: 97 of 162 (59.88%)\n"
     ]
    }
   ],
   "source": [
    "print('Positive samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zhPpsYIe_5LF",
    "outputId": "82df1a40-101a-4812-ec55-147e76526b0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision, Recall, F1, Support: (0.6732673267326733, 0.7010309278350515, 0.686868686868687, None)\n"
     ]
    }
   ],
   "source": [
    "# Combine the results across all batches. \n",
    "flat_predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# For each sample, pick the label (0 or 1) with the higher score.\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "\n",
    "# Combine the correct labels for each batch into a single list.\n",
    "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "scores = precision_recall_fscore_support(flat_true_labels, flat_predictions, average='binary')\n",
    "\n",
    "# Calculate the P,R,F1\n",
    "print('Precision, Recall, F1, Support:', scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "72Whs8s6_5LG",
    "outputId": "a9a51462-b811-4af4-e8da-3ee500ed9931"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of good predictions: 100\n",
      "number of bad predictions: 62\n",
      "accuracy 0.6172839506172839\n"
     ]
    }
   ],
   "source": [
    "# get the bad predictions index\n",
    "bad_preds = [idx for idx, elem in enumerate(flat_predictions) if elem != flat_true_labels[idx]] \n",
    "good_preds = [idx for idx, elem in enumerate(flat_predictions) if elem == flat_true_labels[idx]] \n",
    "print(\"number of good predictions:\", len(good_preds))\n",
    "print(\"number of bad predictions:\", len(bad_preds))\n",
    "print(\"accuracy\", len(good_preds)/len(flat_predictions) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "SDMlLYe3_5LH",
    "outputId": "53cc3cf4-aca7-4f74-e0b8-f0db280563b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 1 1 1 1 1 1 1 0 1 0 0 1 1 1 0 1 0 1 1 0 1 0 0 0 1 0 0 1 1 1 1 1 1\n",
      " 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1\n",
      " 0 0 0 0 1 1 0 0 0 0 0 1 0 1 1 0 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1\n",
      " 0 0 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 0 1 0 1 1 1 0 1 0 0\n",
      " 1 0 1 0 1 0 1 0 0 1 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(flat_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zv3QFUTq_5LJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UwxZp1pl_5LK",
    "outputId": "b1c8d600-24f8-4e7f-bc74-829c9fc39be2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tQoKdeBw_5LL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Longfomer22Jul_05",
   "provenance": []
  },
  "environment": {
   "name": "pytorch-gpu.1-4.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
