{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning BERT on long texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we explore different approach to overcome one of the main limitation of BERT (which stands for Bidirectional Encoder Representations from Transformers), the ability to process long document. In fact BERT can only be applied on text that have less than 512 token after tokenization with the Bert Tokenizer.\n",
    "\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "\n",
    "We will implement [this paper, which introduce a new method to deal with Long Documents : RoBERT (Recurrence over BERT)](https://arxiv.org/abs/1910.10781).\n",
    "\n",
    "\n",
    "\n",
    "We will also implement [this paper, which introduce diferents methods to deal with Long Documents and BERT](https://arxiv.org/abs/1905.05583) to see if the RoBERT paper bring some significative improvement on the classification of Long Texts with BERT.\n",
    "\n",
    "This paper introduce 2 main approaches, the **Truncation methods** and the **Hierarchical methods** :\n",
    " * Truncation methods\n",
    "   * head-only\n",
    "   * tail-only\n",
    "   * head+tail\n",
    " * Hierarchical methods\n",
    "   * mean pooling\n",
    "   * max pooling\n",
    " \n",
    "The Truncation methods applies to the input of the BERT model (the Tokens), while the Hierarchical methods applies to the ouputs of the Bert model (the embbeding), we will go into more detail in the respective parts\n",
    "\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "\n",
    "The goal of the original RoBERT article was to solve the following problem: BERT has a fixed input token count; how can we use its power on long texts. This notebook implements the same approach using HuggingFace's `transformers` library and `pytorch`.\n",
    "\n",
    "The dataset used is the *US Consumer Finance Complaints* available on [Kaggle](https://www.kaggle.com/cfpb/us-consumer-finance-complaints).\n",
    "\n",
    "Basically, the article goes as follows:\n",
    "1. Read the data and do some basic preprocessing\n",
    "2. Break the documents into smaller segments with a number of tokens that can be handled by BERT\n",
    "3. Fine-tune BERT on those segments using a classification head\n",
    "4. Combine the segments of each document by using an LSTM. The fixed output size of the LSTM can be used by a single fully connected layer for the final classification.\n",
    "\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "\n",
    "For code clarity, we separated out some parts of the code into python scripts that are fully commented. They will be referenced throughout the notebook.\n",
    "\n",
    "Here is a graph that represents the differents Interaction between the differents Classes :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img/Class_Interactions.png](img/Class_Interactions.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import transformers\n",
    "from transformers import RobertaTokenizer, DistilBertTokenizer, BertTokenizer, RobertaModel, BertModel, AdamW# get_linear_schedule_with_warmup\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import time\n",
    "\n",
    "from utils import *\n",
    "from Custom_Dataset_Class import ICAADDataset1\n",
    "from Bert_Classification import Bert_Classification_Model\n",
    "from RoBERT import RoBERT_Model\n",
    "\n",
    "from BERT_Hierarchical import BERT_Hierarchical_Model\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset used in this work was retrieved from kaggle as said in the paper, these are consumer complaints about financial products and services which are sent by the CFPB (Consumer FinancialProtection  Bureau)  to  the  company  for  answer.\n",
    "\n",
    "The  dataset  consists  of  555957  rows  and  18columns. \n",
    "\n",
    "As our model attempts to predict which product the complaint is about, we only used the consumer-complaint-narrative and product columns.\n",
    "* comsumer-complaint-narrative:  contains the consumer complaint in text format.\n",
    "* product:  label of the product concerned by the complaint\\\n",
    "\n",
    "The final dataset used in this work consists of 555957 rows and 2 columns (one column for the texts and the other for the labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>cleaned_contents</th>\n",
       "      <th>Discrimination_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>82026</td>\n",
       "      <td>SENTENCE\\n\\n[1] On the 4th February, in this C...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>80302</td>\n",
       "      <td>JUDGMENT\\n\\n1. On the 5th October 2010 this ap...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>268881</td>\n",
       "      <td>SENTENCE\\n \\n \\n [1]. Mr. Chandar Kant (Accuse...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>284571</td>\n",
       "      <td>SENTENCE\\n  \\n• Dinesh Narayan you have pleade...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>80785</td>\n",
       "      <td>SENTENCE\\n\\n[Names of the accused persons and ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>268172</td>\n",
       "      <td>RULING\\n \\n  \\n• This is an application for le...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>76397</td>\n",
       "      <td>SENTENCE\\n\\n1. You, SHAMENDRA RAM GIR, are her...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>244532</td>\n",
       "      <td>SENTENCE\\n____________________________________...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>81434</td>\n",
       "      <td>SENTENCE\\n[Child Rape]\\n__________________\\n\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>73114</td>\n",
       "      <td>SENTENCE\\n\\n\\t1.\\tThe accused is before the Co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      docid                                   cleaned_contents  \\\n",
       "325   82026  SENTENCE\\n\\n[1] On the 4th February, in this C...   \n",
       "431   80302  JUDGMENT\\n\\n1. On the 5th October 2010 this ap...   \n",
       "393  268881  SENTENCE\\n \\n \\n [1]. Mr. Chandar Kant (Accuse...   \n",
       "129  284571  SENTENCE\\n  \\n• Dinesh Narayan you have pleade...   \n",
       "399   80785  SENTENCE\\n\\n[Names of the accused persons and ...   \n",
       "330  268172  RULING\\n \\n  \\n• This is an application for le...   \n",
       "299   76397  SENTENCE\\n\\n1. You, SHAMENDRA RAM GIR, are her...   \n",
       "173  244532  SENTENCE\\n____________________________________...   \n",
       "423   81434  SENTENCE\\n[Child Rape]\\n__________________\\n\\n...   \n",
       "180   73114  SENTENCE\\n\\n\\t1.\\tThe accused is before the Co...   \n",
       "\n",
       "     Discrimination_Label  \n",
       "325                     1  \n",
       "431                     0  \n",
       "393                     0  \n",
       "129                     1  \n",
       "399                     0  \n",
       "330                     0  \n",
       "299                     0  \n",
       "173                     1  \n",
       "423                     0  \n",
       "180                     0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset into a pandas dataframe.\n",
    "#df=pd.read_csv(\"./us-consumer-finance-complaints/consumer_complaints.csv\")\n",
    "\n",
    "train_raw = pd.read_csv(\"../../w266_project/data/train.csv\")\n",
    "\n",
    "# Display 10 random rows from the data.\n",
    "train_raw.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f89c6855a10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEICAYAAACJalkVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAeXklEQVR4nO3deZhcVbnv8e/PJCQMgRASMCTBMEScjkJuVDygIpMCKuoDihclcIAcFS9O90r0OIDiNXg9gh7PEVE8hEEEZIrIUSMIOAEmzALeBAikSSANZEAQMfieP9YqslNUdVd3enVXF7/P89TTe6+1a+93r1q73tpD762IwMzMrKQXDXUAZmbW+ZxszMysOCcbMzMrzsnGzMyKc7IxM7PinGzMzKy4jko2kvaW1DWIy5smKSSNHKxlWlmSrpV07CAu72xJpwzW8gbDYLehDSxJR0j6xUDPt6OSzVDLG9neQx2HWV/lH027DHUcNvD6+oMmIs6PiAMGOo4XdLKRNGKoY9gYnbhHNZzWaTjFajYQNqbPD0qykbRU0v+WdLukNZIulDSmUn+cpCWSHpc0X9L2lbqQ9BFJiyU9IenLknaW9HtJayVdJGmTuuV9VtKjeblHVMrPlvQdSVdJehJ4i6TRkr4u6UFJj0g6Q9KmTdZjRJ72UUn3AQf3sM6jJZ0uaXl+nS5pdKX+EEm35nW4V9LbKm21X2W6kySdl4drh+2OkfQgcE0u30PS7yStlnRbde8q7219WdJvc/v9QtKESv1elfcuk3RUJf5W2+WoPP9/y5/vPZL2rdQfLenuvPz7JP1zpW5vSV2STpT0MPCfTeb/mxzPKkn3SzqwUr997jeP5350XF37XSzpvLz8OyS9VNJnJK3M61z/K25nSTfldblC0vj+tn+Dddld0s05lguBMXX1b8/9YnWe56t7mFeftg012c4kXZ8nuU3SnyW9T9IESVfmOB6X9GtJDb8vJO2fP/M1kr4NqFK3s6RrJD2mtN2cL2lcpb7pd0OrMajB4WxVDuX11n8azG+qpEsldee4v53LXyTpc5IeyH3nHElb1cVwdO5TqyR9SNJr87qtrs2nEtNvJZ2W6+6T9I+5fFme/6zK9E23R63fhj6V37dC0tG5bjZwBPDp/Nn+JJfPUfreeULSXZLeXRfbb+r62fGSFgOLc9nLJC3In8ufJL23WXs+JyKKv4ClwE3A9sB44G7gQ7luH+BRYAYwGvg34PrKewOYD2wJvBL4K3A1sBOwFXAXMCtPuzewDvhGntebgSeBXXP92cAaYE9Soh0DnJ7nPx4YC/wE+GqT9fgQcA8wNU//qxzfyAbTfgm4AdgWmAj8DvhyrntdjmP/HMdk4GWVttqvMp+TgPPy8LS8vHOAzYFN83sfAw7K89o/j0/M77kWuBd4aZ7+WmBurtsBeAJ4PzAK2AbYLdf1pV2Oyu3+iTyf9+X1G5/rDwZ2Jn0JvRl4CphR95mdmj+zTZvM/2/AccAI4MPAckC5/jrgP/LnuRvQDexbab+ngbcCI3Pb3Q/8S471OOD+yrKuBR4CXpXb+JKNaf+69dgEeKDSTofm9Tol188AVgKvz+s5i9QfRjdp975sG61sZ7tUxr8KnJHjHAW8sdbedTFMANbmdRmV120dcGyu3yW3yWjSdnA9cHqL3w2txlD7XEbWfY61GI6ih/5TN68RwG3AafkzHgPslev+CViS23cL4FLg3LoYzsjvOYDU7y4nfQdMzp/tm+u2maPzMk8BHgT+PbfVAaRtc4vetkfWb0Nfyu10EGkb27ryvXdK3Xoeltv8RaTt9UlgUiW239T1jQV52ZvmdlmWYx9J6lOPAq/sMQ8MYrL5QGX8a8AZefgs4GuVui1yx5hWWdE9K/WLgBMr4/9K7ryVRt+8Un8R8PlKo59TqVNu5J0rZW+g8uVTtx7XkDeEPH4AzZPNvcBBlfG3Akvz8HeB03poq96SzU6V+hPJHb5S9nPWf8lcC3yuUvcR4Gd5+DPAZQ1i6Gu7HEXdxkv6Avlgk+kvBz5W+cyeAcb00H+OApZUxjfL7fBiUuJ/Fhhbqf8qcHal/RZU6t4B/BkYkcfH5nmNq7TX3Mr0r8jxjehP+9eVv6lBO/2O9cnmO+QfJJX6P5G/oBrMry/bRivbWTXZfAm4olrWJIYjgRvq+k4X+Yu+wfTvAm6p6+/NvhtajaH2ufSUbBr2nwbzegPpx0qjbfpq4COV8V1zG46sxDC5Uv8Y8L7K+CXAxysxLa7U/UN+/3Z179+NXrZH0jb0l7r1XwnskYfPpi7ZNFi3W4FDKrHVJ5t9KuPvA35d9/7vAl/saRmDec7m4crwU6TODim7PlCriIg/kxp5cmX6RyrDf2kwvkVlfFVEPFkZfyAvo2ZZZXgiqeMtyruyq4Gf5fJGtq97/wNNpqtNW62vxjGVlIz6qxrDS4DDavHnddgLmFSZplnbN4ujr+0C8FDkXpc9t76SDpR0Q97lXk365TWhMm13RDzdw7w3WIeIeCoPbpGX8XhEPFG37J76z6MR8WxlvDavmvrPeFRdvH1t/5rtadxO1Xl9qm5eU9mw/9ZrddtoZTur+n+kX/G/yId45jSZboNtIq/bc+OStpX0I0kPSVoLnMeGbQnN+2erMbSiWf+pNxV4ICLWNahrtE2PBLarlPXlu6q+johoNH0r2+NjdTFX2/F5JB2p9YdrV5P25Os/l6r6Pv/6un56BOnHX1PtcIHAclLwAEjanHQ456F+zm/rPI+aHfIyaqob+qOkD/SVETEuv7aKiGYf0gpSZ6zOu5kN1qsujmWkw0qNPEnqWDWNPsDqOiwj/bIeV3ltHhFze4it+t5GcfS1XQAmS1JlfAdgudJ5qkuAr5N+tY0DrqJyXL9uffpqOTBe0ti6Zfe3/8DzP+O/kdqkpr/tv4LG7VSd11fq5rVZRFywEetS06ftLCKeiIhPRcROpL3BT6pyHq5ig20ir1u1/b5Kaq9XR8SWwAfY8LNvqg8x1H5c9rbdtGIZsIManwhvtE2vY8OkUUJ/tseqDbYvSS8Bvgd8FNgmb5N30vPnUt/nr6vrp1tExId7CqIdks0PgaMl7Za/mP4vcGNELN2IeZ4saRNJbwTeDlzcaKKI+Dup0U+TtC2ApMmS3tpkvhcBJ0iaImlroKdfWhcAn5M0UemE/BdIv+ogHdI4WtK++aTjZEkvy3W3AodLGiVpJulYeE/OA94h6a1KFzCMyScMp/TyPoDzgf0kvVfSSEnbSNqtH+0C6bj0CTnuw4CXk5LKJqRj0N3AOqUTswN2WWVELCMdivpqXvdXA8fkdeuvD0h6haTNSIdyflzZE6rXl/b/PenL6YTc3u8hnb+r+R7wIUmvV7K5pIPrEml/9badPUI6FwE8d6HCLjl5rCUdqmzUBj8FXinpPfkL+gQ2/KIfSzpsuVrSZOD/tBpwqzFERDcpaX4gfwb/RPMfc725iZRA5+b2HyNpz1x3AfAJSTtK2oLUhhc22QsaMP3cHqs2+GxJ51yCtE2idDHBq/oQ0pXASyV9MG/vo5QuhHh5T28a8mQTEVcDnyf9+l1B6iSHb8QsHwZWkX6FnE86x3JPD9OfSNpVvyHv5v+SdCy2ke+RjsffBtxMOkHYzCnAQuB24I48/SkAEXET6eTaaaQT6dex/hfT50ltsAo4mfQl0VT+sj0E+Cyp8ywjbdC9frYR8SDpkNangMdJie41ubov7QJwIzCd9CvsK8ChEfFYPrx1AilRrwL+J+lE50B6P+mY+XLgMtKx4wUbMb9zSce5Hyad7D2h2YR9af+IeAZ4D+mY+CrSse9LK/ULSSexv53rl+RpN1oL29lJwLx8WOS9pM/yl6RE8XvgPyLi2gbzfZR0snku6bDcdOC3lUlOJp1AXkNKTD1tM/VaiiE7jtTuj5EulvhdH5bznPyj4h2kCxseJJ1/el+u/gGpb1xPusjkaeB/9Wc5/dDX7bHqLOAV+bO9PCLuIp3P+z0pEf0DG35mPcrb9AGk/rOctJ3ULvBpqnY1j1m/KV0ufWxE7DXUsZhZexryPRszM+t8TjZmZlacD6OZmVlx3rMxM7PihvWNBCdMmBDTpk0b6jDMzIaVRYsWPRoRPf2T9oAb1slm2rRpLFy4cKjDMDMbViT1dPeTInwYzczMinOyMTOz4pxszMysOCcbMzMrrmiyUXoK3x35VtYLc9l4pSe8Lc5/t87lkvQtpScJ3i5pRsnYzMxs8AzGns1bImK3iJiZx+cAV0fEdNLDiGp3Tj6QdOO96cBs0oOkzMysAwzFYbRDgHl5eB7pyX218nMiuQEYJ6nRA6jMzGyYKZ1sgvSUvUWSZuey7SJiBUD+u20un8yGT4ProsFTBCXNlrRQ0sLu7u6CoZuZ2UAp/U+de0bE8vzAnwWSenquTKOnxD3vxm0RcSZwJsDMmTN9Yzczs2GgaLKJiOX570pJl5GeSviIpEkRsSIfJluZJ+9iw8fJTmHDxzmbmbWVaXN+OmTLXjr34CFbdn8UO4yWH6k6tjZMerLbnaSnNM7Kk80CrsjD84Ej81VpewBraofbzMxseCu5Z7MdcFl6fDgjgR9GxM8k/QG4SNIxpMeuHpanv4r0iOIlwFOkxyabmVkHKJZsIuI+1j/Pvlr+GLBvg/IAji8Vj5mZDR3fQcDMzIpzsjEzs+KcbMzMrDgnGzMzK87JxszMinOyMTOz4pxszMysOCcbMzMrzsnGzMyKc7IxM7PinGzMzKw4JxszMyvOycbMzIpzsjEzs+KcbMzMrDgnGzMzK87JxszMinOyMTOz4pxszMysOCcbMzMrzsnGzMyKc7IxM7PinGzMzKw4JxszMyvOycbMzIpzsjEzs+KcbMzMrDgnGzMzK87JxszMinOyMTOz4pxszMysOCcbMzMrzsnGzMyKK55sJI2QdIukK/P4jpJulLRY0oWSNsnlo/P4klw/rXRsZmY2OAZjz+ZjwN2V8VOB0yJiOrAKOCaXHwOsiohdgNPydGZm1gGKJhtJU4CDge/ncQH7AD/Ok8wD3pWHD8nj5Pp98/RmZjbMld6zOR34NPD3PL4NsDoi1uXxLmByHp4MLAPI9Wvy9BuQNFvSQkkLu7u7S8ZuZmYDpFiykfR2YGVELKoWN5g0WqhbXxBxZkTMjIiZEydOHIBIzcystJEF570n8E5JBwFjgC1JezrjJI3Mey9TgOV5+i5gKtAlaSSwFfB4wfjMzGyQFNuziYjPRMSUiJgGHA5cExFHAL8CDs2TzQKuyMPz8zi5/pqIeN6ejZmZDT9D8X82JwKflLSEdE7mrFx+FrBNLv8kMGcIYjMzswJKHkZ7TkRcC1ybh+8DXtdgmqeBwwYjHjMzG1y+g4CZmRXnZGNmZsU52ZiZWXFONmZmVpyTjZmZFedkY2ZmxTnZmJlZcU42ZmZWnJONmZkV52RjZmbFOdmYmVlxTjZmZlack42ZmRXnZGNmZsU52ZiZWXFONmZmVpyTjZmZFedkY2ZmxTnZmJlZcU42ZmZWnJONmZkV52RjZmbFOdmYmVlxTjZmZlack42ZmRXnZGNmZsU52ZiZWXFONmZmVlxLyUbSq0oHYmZmnavVPZszJN0k6SOSxhWNyMzMOk5LySYi9gKOAKYCCyX9UNL+RSMzM7OO0fI5m4hYDHwOOBF4M/AtSfdIek+p4MzMrDO0es7m1ZJOA+4G9gHeEREvz8OnNXnPmHzo7TZJf5R0ci7fUdKNkhZLulDSJrl8dB5fkuunDcD6mZlZG2h1z+bbwM3AayLi+Ii4GSAilpP2dhr5K7BPRLwG2A14m6Q9gFOB0yJiOrAKOCZPfwywKiJ2ISWwU/uzQmZm1n5aTTYHAT+MiL8ASHqRpM0AIuLcRm+I5M95dFR+BWlv6Me5fB7wrjx8SB4n1+8rSX1YFzMza1OtJptfAptWxjfLZT2SNELSrcBKYAFwL7A6ItblSbqAyXl4MrAMINevAbZpMT4zM2tjrSabMZW9FPLwZr29KSKejYjdgCnA64CXN5os/220FxP1BZJmS1ooaWF3d3dLwZuZ2dBqNdk8KWlGbUTS/wD+0upCImI1cC2wBzBO0shcNQVYnoe7SJdWk+u3Ah5vMK8zI2JmRMycOHFiqyGYmdkQajXZfBy4WNKvJf0auBD4aE9vkDSx9g+gkjYF9iNdzfYr4NA82Szgijw8P4+T66+JiOft2ZiZ2fAzsvdJICL+IOllwK6kw133RMTfennbJGCepBGkpHZRRFwp6S7gR5JOAW4BzsrTnwWcK2kJaY/m8L6vjpmZtaOWkk32WmBafs/ukoiIc5pNHBG3A7s3KL+PdP6mvvxp4LA+xGNmZsNES8lG0rnAzsCtwLO5OICmycbMzKym1T2bmcArfA7FzMz6o9ULBO4EXlwyEDMz61yt7tlMAO6SdBPpNjQARMQ7i0RlZmYdpdVkc1LJIMzMrLO1eunzdZJeAkyPiF/m+6KNKBuamZl1ilYfMXAc6eaY381Fk4HLSwVlZmadpdULBI4H9gTWwnMPUtu2VFBmZtZZWk02f42IZ2oj+d5lvgzazMxa0mqyuU7SZ4FNJe0PXAz8pFxYZmbWSVpNNnOAbuAO4J+Bq2j+hE4zM7MNtHo12t+B7+WXmZlZn7R6b7T7aXCOJiJ2GvCIzMys4/Tl3mg1Y0h3Zx4/8OGYmVknaumcTUQ8Vnk9FBGnA/sUjs3MzDpEq4fRZlRGX0Ta0xlbJCIzM+s4rR5G+9fK8DpgKfDeAY/GzMw6UqtXo72ldCBmZta5Wj2M9sme6iPiGwMTjpmZdaK+XI32WmB+Hn8HcD2wrERQZmbWWfry8LQZEfEEgKSTgIsj4thSgZmZWedo9XY1OwDPVMafAaYNeDRmZtaRWt2zORe4SdJlpDsJvBs4p1hUZmbWUVq9Gu0rkv4LeGMuOjoibikXlpmZdZJWD6MBbAasjYhvAl2SdiwUk5mZdZhWHwv9ReBE4DO5aBRwXqmgzMyss7S6Z/Nu4J3AkwARsRzfrsbMzFrUarJ5JiKC/JgBSZuXC8nMzDpNq8nmIknfBcZJOg74JX6QmpmZtajVq9G+Lml/YC2wK/CFiFhQNDIzM+sYvSYbSSOAn0fEfoATjJmZ9Vmvh9Ei4lngKUlbDUI8ZmbWgVq9g8DTwB2SFpCvSAOIiBOKRGVmZh2l1WTz0/xqmaSppFvavBj4O3BmRHxT0njgQtK91ZYC742IVZIEfBM4CHgKOCoibu7LMs3MrD31mGwk7RARD0bEvH7Mex3wqYi4WdJYYFHeMzoKuDoi5kqaA8wh/cPogcD0/Ho98J3818zMhrneztlcXhuQdElfZhwRK2p7JvnRBHcDk4FDgFrymge8Kw8fApwTyQ2ky6wn9WWZZmbWnnpLNqoM79TfhUiaBuwO3AhsFxErICUkYNs82WQ2fBhbVy6rn9dsSQslLezu7u5vSGZmNoh6SzbRZLhlkrYALgE+HhFre5q0l+WngogzI2JmRMycOHFif0IyM7NB1tsFAq+RtJaUCDbNw+TxiIgte3qzpFGkRHN+RFyaix+RNCkiVuTDZCtzeRcwtfL2KcDyPqyLmZm1qR73bCJiRERsGRFjI2JkHq6N95ZoBJwF3B0R36hUzQdm5eFZwBWV8iOV7AGsqR1uMzOz4a3VS5/7Y0/gg6T/z7k1l30WmEu619oxwIPAYbnuKtJlz0tIlz4fXTA2MzMbRMWSTUT8hsbnYQD2bTB9AMeXisfMzIZOX57UaWZm1i9ONmZmVpyTjZmZFedkY2ZmxTnZmJlZcU42ZmZWnJONmZkV52RjZmbFOdmYmVlxTjZmZlack42ZmRXnZGNmZsU52ZiZWXFONmZmVpyTjZmZFedkY2ZmxTnZmJlZcU42ZmZWnJONmZkV52RjZmbFOdmYmVlxTjZmZlack42ZmRXnZGNmZsU52ZiZWXFONmZmVpyTjZmZFedkY2ZmxTnZmJlZcU42ZmZWnJONmZkV52RjZmbFOdmYmVlxxZKNpB9IWinpzkrZeEkLJC3Of7fO5ZL0LUlLJN0uaUapuMzMbPCV3LM5G3hbXdkc4OqImA5cnccBDgSm59ds4DsF4zIzs0FWLNlExPXA43XFhwDz8vA84F2V8nMiuQEYJ2lSqdjMzGxwDfY5m+0iYgVA/rttLp8MLKtM15XLnkfSbEkLJS3s7u4uGqyZmQ2MdrlAQA3KotGEEXFmRMyMiJkTJ04sHJaZmQ2EwU42j9QOj+W/K3N5FzC1Mt0UYPkgx2ZmZoUMdrKZD8zKw7OAKyrlR+ar0vYA1tQOt5mZ2fA3stSMJV0A7A1MkNQFfBGYC1wk6RjgQeCwPPlVwEHAEuAp4OhScZmZ2eArlmwi4v1NqvZtMG0Ax5eKxczMhla7XCBgZmYdzMnGzMyKc7IxM7PinGzMzKw4JxszMyvOycbMzIpzsjEzs+KcbMzMrDgnGzMzK87JxszMinOyMTOz4pxszMysOCcbMzMrzsnGzMyKc7IxM7PinGzMzKw4JxszMyvOycbMzIor9lhoM7PBMm3OT4c6BOuF92zMzKw4JxszMyvOycbMzIpzsjEzs+J8gYBZhxmqk+VL5x48JMu14cF7NmZmVpz3bMxsQPjyY+uJ92zMzKw479lYR/OvbbP24D0bMzMrzsnGzMyKc7IxM7PinGzMzKw4JxszMyuura5Gk/Q24JvACOD7ETF3iEOyAeKrwsxe2Nom2UgaAfw7sD/QBfxB0vyIuGtoI+sc/sI3s6HSNskGeB2wJCLuA5D0I+AQoEiyGcovXt9DysxeaNop2UwGllXGu4DX108kaTYwO4/+WdKfNmKZE4BHN+L9/aJT+/W2IYl1IwyneB1rOcMp3uEUKzp1o+J9yUDG0op2SjZqUBbPK4g4EzhzQBYoLYyImQMxr9KGU6wwvOJ1rOUMp3iHU6ww/OJtp6vRuoCplfEpwPIhisXMzAZQOyWbPwDTJe0oaRPgcGD+EMdkZmYDoG0Oo0XEOkkfBX5OuvT5BxHxx8KLHZDDcYNkOMUKwytex1rOcIp3OMUKwyxeRTzvtIiZmdmAaqfDaGZm1qGcbMzMrLiOTTaSfiBppaQ7K2XjJS2QtDj/3TqXS9K3JC2RdLukGYMc61RJv5J0t6Q/SvpYm8c7RtJNkm7L8Z6cy3eUdGOO98J8oQeSRufxJbl+2mDGm2MYIekWSVcOg1iXSrpD0q2SFuaydu0L4yT9WNI9uf++oY1j3TW3ae21VtLH2zjeT+Tt605JF+Ttrm37ba8ioiNfwJuAGcCdlbKvAXPy8Bzg1Dx8EPBfpP/12QO4cZBjnQTMyMNjgf8PvKKN4xWwRR4eBdyY47gIODyXnwF8OA9/BDgjDx8OXDgE/eGTwA+BK/N4O8e6FJhQV9aufWEecGwe3gQY166x1sU9AniY9M+NbRcv6Z/c7wc2rfTXo9q53/a6TkMdQOEPbBobJps/AZPy8CTgT3n4u8D7G003RHFfQbpHXNvHC2wG3Ey628OjwMhc/gbg53n458Ab8vDIPJ0GMcYpwNXAPsCV+cujLWPNy13K85NN2/UFYMv8hah2j7VB7AcAv23XeFl/R5XxuR9eCby1nfttb6+OPYzWxHYRsQIg/902lze6Vc7kQY4NgLz7uztpb6Ft482HpW4FVgILgHuB1RGxrkFMz8Wb69cA2wxiuKcDnwb+nse3oX1jhXTnjF9IWqR0eyZoz76wE9AN/Gc+RPl9SZu3aaz1DgcuyMNtF29EPAR8HXgQWEHqh4to737boxdasmmmpVvlFA9C2gK4BPh4RKztadIGZYMab0Q8GxG7kfYaXge8vIeYhixeSW8HVkbEompxD/EMedsCe0bEDOBA4HhJb+ph2qGMdyTpUPV3ImJ34EnSYahm2qFtyec53glc3NukDcoGq99uTboR8Y7A9sDmpP7QLJ62aNuevNCSzSOSJgHkvytz+ZDfKkfSKFKiOT8iLs3FbRtvTUSsBq4lHdMeJ6n2j8LVmJ6LN9dvBTw+SCHuCbxT0lLgR6RDaae3aawARMTy/HclcBkpmbdjX+gCuiLixjz+Y1LyacdYqw4Ebo6IR/J4O8a7H3B/RHRHxN+AS4F/pI37bW9eaMlmPjArD88inRuplR+Zrz7ZA1hT260eDJIEnAXcHRHfGAbxTpQ0Lg9vStow7gZ+BRzaJN7aehwKXBP54HJpEfGZiJgSEdNIh06uiYgj2jFWAEmbSxpbGyadW7iTNuwLEfEwsEzSrrloX9IjQdou1jrvZ/0htFpc7Rbvg8AekjbL3w+1tm3LftuSoT5pVOpF6kwrgL+Rsv4xpGOYVwOL89/xeVqRHtx2L3AHMHOQY92LtMt7O3Brfh3UxvG+Grglx3sn8IVcvhNwE7CEdIhidC4fk8eX5PqdhqhP7M36q9HaMtYc12359UfgX3J5u/aF3YCFuS9cDmzdrrHmGDYDHgO2qpS1ZbzAycA9eRs7Fxjdrv22lZdvV2NmZsW90A6jmZnZEHCyMTOz4pxszMysOCcbMzMrzsnGzMyKc7IxM7PinGzMzKy4/wbjcnApIaZj8QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_raw.cleaned_contents.apply(lambda x: len(x.split()) if len(x.split())<800 else 800).plot(kind='hist', title=\"nombre d'ocurence par nombre de mots dans un commentaire\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>Discrimination_Label</th>\n",
       "      <th>len_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>647.000000</td>\n",
       "      <td>647.000000</td>\n",
       "      <td>647.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>148136.561051</td>\n",
       "      <td>0.571870</td>\n",
       "      <td>1516.514683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>89761.801919</td>\n",
       "      <td>0.495191</td>\n",
       "      <td>1698.831551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>69815.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>77546.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>750.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>81436.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1123.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>253296.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1635.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>288617.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28652.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               docid  Discrimination_Label       len_txt\n",
       "count     647.000000            647.000000    647.000000\n",
       "mean   148136.561051              0.571870   1516.514683\n",
       "std     89761.801919              0.495191   1698.831551\n",
       "min     69815.000000              0.000000     99.000000\n",
       "25%     77546.000000              0.000000    750.500000\n",
       "50%     81436.000000              1.000000   1123.000000\n",
       "75%    253296.500000              1.000000   1635.500000\n",
       "max    288617.000000              1.000000  28652.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw['len_txt'] =train_raw.cleaned_contents.apply(lambda x: len(x.split()))\n",
    "train_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(645, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Select only the row with number of words greater than 250:\n",
    "train_raw = train_raw[train_raw.len_txt >249]\n",
    "train_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_contents</th>\n",
       "      <th>Discrimination_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SENTENCE\\n\\n\\t1.\\tYou are charged as follows:\\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SENTENCE\\n\\n\\t1.\\tJOSEFA KOTOBALAVU, you were ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SENTENCE\\n\\n1. The Director of Public Prosecut...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SENTENCE\\n\\n\\t1.\\tMOHOMMED NABI UD- DEAN, you ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JUDGMENT OF THE COURT\\n\\nBackground\\n\\n[1] The...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    cleaned_contents  Discrimination_Label\n",
       "0  SENTENCE\\n\\n\\t1.\\tYou are charged as follows:\\...                     0\n",
       "1  SENTENCE\\n\\n\\t1.\\tJOSEFA KOTOBALAVU, you were ...                     1\n",
       "2  SENTENCE\\n\\n1. The Director of Public Prosecut...                     1\n",
       "3  SENTENCE\\n\\n\\t1.\\tMOHOMMED NABI UD- DEAN, you ...                     1\n",
       "4  JUDGMENT OF THE COURT\\n\\nBackground\\n\\n[1] The...                     0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Select only the column 'consumer_complaint_narrative' and 'product'\n",
    "train_raw = train_raw[['cleaned_contents', 'Discrimination_Label']]\n",
    "train_raw.reset_index(inplace=True, drop=True)\n",
    "train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group similar products\n",
    "#train_raw.at[train_raw['product'] == 'Credit reporting', 'product'] = 'Credit reporting, credit repair services, or other personal consumer reports'\n",
    "#train_raw.at[train_raw['product'] == 'Credit card', 'product'] = 'Credit card or prepaid card'\n",
    "#train_raw.at[train_raw['product'] == 'Prepaid card', 'product'] = 'Credit card or prepaid card'\n",
    "#train_raw.at[train_raw['product'] == 'Payday loan', 'product'] = 'Payday loan, title loan, or personal loan'\n",
    "#train_raw.at[train_raw['product'] == 'Virtual currency', 'product'] = 'Money transfer, virtual currency, or money service'\n",
    "#train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all the different classes\n",
    "#for l in np.unique(train_raw['product']):\n",
    "#    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SENTENCE\\n\\n\\t1.\\tYou are charged as follows:\\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SENTENCE\\n\\n\\t1.\\tJOSEFA KOTOBALAVU, you were ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SENTENCE\\n\\n1. The Director of Public Prosecut...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SENTENCE\\n\\n\\t1.\\tMOHOMMED NABI UD- DEAN, you ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JUDGMENT OF THE COURT\\n\\nBackground\\n\\n[1] The...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  SENTENCE\\n\\n\\t1.\\tYou are charged as follows:\\...      0\n",
       "1  SENTENCE\\n\\n\\t1.\\tJOSEFA KOTOBALAVU, you were ...      1\n",
       "2  SENTENCE\\n\\n1. The Director of Public Prosecut...      1\n",
       "3  SENTENCE\\n\\n\\t1.\\tMOHOMMED NABI UD- DEAN, you ...      1\n",
       "4  JUDGMENT OF THE COURT\\n\\nBackground\\n\\n[1] The...      0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw=train_raw.rename(columns = {'cleaned_contents':'text', 'Discrimination_Label':'label'})\n",
    "train_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing and segmentation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preprocessing:\n",
    "The preprocessing step goes as follows:\n",
    "1. Remove all documents with fewer than 250 tokens. We want to concentrate only on long texts\n",
    "2. Consolidate the classes by combining those that are similar. (e.g.: \"Credit card\" or \"prepaid card\" complaints) :\n",
    " * Credit reporting‘ to ‘Credit reporting, credit repair services, or other personal consumerreports‘.\n",
    " * ‘Credit card‘ to ‘Credit card or prepaid card‘.\n",
    " * ‘Payday loan‘ to ‘Payday loan, title loan or personal loan‘1\n",
    " * ‘Virtual currency‘ to ‘Money transfer, virtual currency or money servic\n",
    "3. Remove all non-word characters\n",
    "4. Encode the labels\n",
    "5. Split the dataset in train set (80%) and validation set (20%).\n",
    "\n",
    "### 2. Segmentation and tokenization:\n",
    "First, each complaint is split into 200-token chunk with an overlap of 50 between each of them. This means that the last 50 tokens of a segment are the first 50 of the next segment.  \n",
    "Then, each segment is tokenized using BERT's tokenizer. This is needed for two main reasons:\n",
    "1. BERT's vocabulary is not made of just English words, but also subwords and single characters\n",
    "2. BERT does not take raw string as inputs. It needs:\n",
    "    - token ids: those values allow BERT to retrieve the tensor representation of a token\n",
    "    - input mask: a tensor of 0s and 1s that shows whether a token should be ignored (0) or not (1) by BERT\n",
    "    - segment ids: those are used to tell BERT what tokens form the first sentence and the second sentence (in the next sentence prediction task)  \n",
    "    \n",
    "The parameter `MAX_SEQ_LENGTH` ensures that any tokenized sentence longer that that number (200 in this case) will be truncated.  \n",
    "Each returned segment is given the same class as the document containing it.\n",
    "\n",
    "PyTorch offers the `Dataset` and `DataLoader` classes that make it easier to group the data reading and preparation operations while decreasing the memory usage in case the dataset is large.  \n",
    "We implemented the above steps in the `Custom_Dataset_Class.py` file. Our dataset class `ConsumerComplaintsDataset1` has a constructor (`__init__`) taking the necessary parameters to load the .csv file, segment the documents, and then tokenize them. It also preprocesses the data as explained in the preprocessing section.    \n",
    "The two other important methods are the following:\n",
    "- `__len__` returns the number of documents\n",
    "- `__getitem__` is the method where most of the work is done. It takes a tensor of idx values and returns the tokenized data:\n",
    "\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "\n",
    "As said above, there is differents approaches for overflowing tokens, we added the differents strategies (described in [the following paper](https://arxiv.org/abs/1905.05583)) via the use of the parameter `approach` in the initialisation of Consumer Complaints Dataset class, here is the differents value of the `approach` parameter to handle that situation :\n",
    "- **all**: overflowing tokens from a document are used to create new 200 token chunk with 50 tokens overlap between them\n",
    "- **head**: overflowing tokens are truncated. Only the first 200 tokens are used.\n",
    "- **tail**: only the last 200 tokens are kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n",
      "Nettoyage des données\n"
     ]
    }
   ],
   "source": [
    "\n",
    "TRAIN_BATCH_SIZE=8\n",
    "EPOCH=3\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "MIN_LEN=249\n",
    "MAX_LEN = 100000\n",
    "CHUNK_LEN=200\n",
    "OVERLAP_LEN=50\n",
    "#MAX_LEN=10000000\n",
    "#MAX_SIZE_DATASET=1000\n",
    "\n",
    "print('Loading BERT tokenizer...')\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "#dataset=ConsumerComplaintsDataset1(\n",
    "dataset=ICAADDataset1(\n",
    "    tokenizer=bert_tokenizer,\n",
    "    min_len=MIN_LEN,\n",
    "    max_len=MAX_LEN,\n",
    "    chunk_len=CHUNK_LEN,\n",
    "    #max_size_dataset=MAX_SIZE_DATASET,\n",
    "    overlap_len=OVERLAP_LEN)\n",
    "\n",
    "\n",
    "#train_size = int(0.8 * len(dataset))\n",
    "#test_size = len(dataset) - train_size\n",
    "#train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_data_loader=DataLoader(\n",
    "    dataset,\n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    sampler=train_sampler,\n",
    "    collate_fn=my_collate1)\n",
    "\n",
    "valid_data_loader=DataLoader(\n",
    "    dataset,\n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    sampler=valid_sampler,\n",
    "    collate_fn=my_collate1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Fine-tuning on the 200 tokens chunks:\n",
    "BERT is fine-tuned on the 200 tokens chunks\n",
    "\n",
    "In our implementation, we put a neural network on top of the pooled output from BERT, each BERT's input token has a embeding as an output, the embedding of the `CLS` token (the first token) corresponds to the pooled output of the all sentence input (the 200 tokens chunk in our case).\n",
    "\n",
    "The neural network is composed of a dense layer with a SoftMax activation function.\n",
    "\n",
    "This Model corresponds to the class `Bert_Classification_Model` defined in the file `Bert_Classification.py`. This class inherits from `torch.nn.Module` which is the parent of all neural network models.\n",
    "\n",
    "Then, in the function `train_loop_fun1` defined in `utils.py`, for each batch, the list of dictionaries containing the values for the token_ids, masks, token_type_ids, and targets are respectively concatenated into `torch.tensors` which are then fed into the model in order to get predictions and apply backpropagation according to the Cross Entropy loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First segmetation approach: all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in this approach, we will consider each chunk of 200 tokens as a new document, so if a document is split into 3 chunk of 200, tokens we will consider each chunks as a new document with the same label.\\\n",
    "We use this approach to fine tune BERT, so this model will be used as an input for RoBERT. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img/each_Chunk_as_Document.png](img/each_Chunk_as_Document.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============== EPOCH 1 / 3 ===============\n",
      "\n",
      "___ batch index = 0 / 65 (0.00%), loss = 0.7147, time = 55.63 secondes ___\n",
      "\n",
      "*** avg_loss : 0.76, time : ~232.0 min (13978.94 sec) ***\n",
      "\n",
      "==> evaluation : avg_loss = 0.74, time : 2507.42 sec\n",
      "\n",
      "=====>\t{'accuracy': 0.424968474148802, 'nb exemple': 1586, 'true_prediction': 674, 'false_prediction': 912}\n",
      "\t§§ model has been saved §§\n",
      "\n",
      "=============== EPOCH 2 / 3 ===============\n",
      "\n",
      "___ batch index = 0 / 65 (0.00%), loss = 0.5090, time = 138.56 secondes ___\n",
      "\n",
      "*** avg_loss : 0.72, time : ~876.0 min (52587.61 sec) ***\n",
      "\n",
      "==> evaluation : avg_loss = 0.73, time : 644.47 sec\n",
      "\n",
      "=====>\t{'accuracy': 0.424968474148802, 'nb exemple': 1586, 'true_prediction': 674, 'false_prediction': 912}\n",
      "\t§§ model has been saved §§\n",
      "\n",
      "=============== EPOCH 3 / 3 ===============\n",
      "\n",
      "___ batch index = 0 / 65 (0.00%), loss = 0.7825, time = 508.83 secondes ___\n",
      "\n",
      "*** avg_loss : 0.71, time : ~163.0 min (9819.55 sec) ***\n",
      "\n",
      "==> evaluation : avg_loss = 0.71, time : 329.12 sec\n",
      "\n",
      "=====>\t{'accuracy': 0.424968474148802, 'nb exemple': 1586, 'true_prediction': 674, 'false_prediction': 912}\n",
      "\t§§ model has been saved §§\n"
     ]
    }
   ],
   "source": [
    "device=\"cpu\"\n",
    "lr=3e-5#1e-3\n",
    "num_training_steps=int(len(dataset) / TRAIN_BATCH_SIZE * EPOCH)\n",
    "\n",
    "model=Bert_Classification_Model().to(device)\n",
    "optimizer=AdamW(model.parameters(), lr=lr)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                        num_warmup_steps = 0,\n",
    "                                        num_training_steps = num_training_steps)\n",
    "val_losses=[]\n",
    "batches_losses=[]\n",
    "val_acc=[]\n",
    "for epoch in range(EPOCH):\n",
    "    t0 = time.time()    \n",
    "    print(f\"\\n=============== EPOCH {epoch+1} / {EPOCH} ===============\\n\")\n",
    "    batches_losses_tmp=train_loop_fun1(train_data_loader, model, optimizer, device)\n",
    "    epoch_loss=np.mean(batches_losses_tmp)\n",
    "    print(f\"\\n*** avg_loss : {epoch_loss:.2f}, time : ~{(time.time()-t0)//60} min ({time.time()-t0:.2f} sec) ***\\n\")\n",
    "    t1=time.time()\n",
    "    output, target, val_losses_tmp=eval_loop_fun1(valid_data_loader, model, device)\n",
    "    print(f\"==> evaluation : avg_loss = {np.mean(val_losses_tmp):.2f}, time : {time.time()-t1:.2f} sec\\n\")\n",
    "    tmp_evaluate=evaluate(target.reshape(-1), output)\n",
    "    print(f\"=====>\\t{tmp_evaluate}\")\n",
    "    val_acc.append(tmp_evaluate['accuracy'])\n",
    "    val_losses.append(val_losses_tmp)\n",
    "    batches_losses.append(batches_losses_tmp)\n",
    "    print(\"\\t§§ model has been saved §§\")\n",
    "    torch.save(model, f\"model1/model_epoch{epoch+1}.pt\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f89c6a5a910>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(np.array([[np.mean(x) for x in batches_losses], [np.mean(x) for x in val_losses]]).T,\n",
    "                   columns=['Training', 'Validation']).plot(title=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f7b44d51690>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(np.array(val_acc).T,\n",
    "                   columns=['Validation']).plot(title=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now we will experience the [Truncation strategies presented in this paper](https://arxiv.org/abs/1905.05583)\n",
    "\n",
    "such as:  \n",
    "* Tunction Method:  \n",
    "    + Head only  \n",
    "    + Tail only  \n",
    "* Hierarchical Method:  \n",
    "    + Mean pooling  \n",
    "    + Max pooling  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Truncation Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "The Truncation methods applies to the input of the BERT model (the Tokens)\n",
    " \n",
    "Usually, the key information of an article is at the beginning and end. We\n",
    "use two different methods of truncate text to perform BERT fine-tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second segmentation approach: head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in this approach, we will keep only the first chunk of 200 tokens for each documents, so if a document is split into 3 chunk of 200, we will only keep the first chunk and we will not keep the last two chunk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img/Head_Truncation.png](img/Head_Truncation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n",
      "Nettoyage des données\n",
      "\n",
      "=============== EPOCH 1 / 1 ===============\n",
      "\n",
      "___ batch index = 0 / 65 (0.00%), loss = 0.6924, time = 6.03 secondes ___\n",
      "\n",
      "*** avg_loss : 0.71, time : ~5.0 min (334.47 sec) ***\n",
      "\n",
      "==> evaluation : avg_loss = 0.69, time : 23.37 sec\n",
      "\n",
      "=====>\t{'accuracy': 0.5813953488372093, 'nb exemple': 129, 'true_prediction': 75, 'false_prediction': 54}\n",
      "\t§§ Truncation head only model has been saved §§\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "RAIN_BATCH_SIZE=8\n",
    "EPOCH=1\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "MIN_LEN=249\n",
    "MAX_LEN = 100000\n",
    "CHUNK_LEN=200\n",
    "OVERLAP_LEN=50\n",
    "#MAX_LEN=10000000\n",
    "#MAX_SIZE_DATASET=1000\n",
    "\n",
    "approach='head'\n",
    "\n",
    "print('Loading BERT tokenizer...')\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "dataset=ICAADDataset1(\n",
    "    tokenizer=bert_tokenizer,\n",
    "    min_len=MIN_LEN,\n",
    "    max_len=MAX_LEN,\n",
    "    chunk_len=CHUNK_LEN,\n",
    "    #max_size_dataset=MAX_SIZE_DATASET,\n",
    "    overlap_len=OVERLAP_LEN,\n",
    "    approach=approach)\n",
    "\n",
    "\n",
    "#train_size = int(0.8 * len(dataset))\n",
    "#test_size = len(dataset) - train_size\n",
    "#train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_data_loader=DataLoader(\n",
    "    dataset,\n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    sampler=train_sampler,\n",
    "    collate_fn=my_collate1)\n",
    "\n",
    "valid_data_loader=DataLoader(\n",
    "    dataset,\n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    sampler=valid_sampler,\n",
    "    collate_fn=my_collate1)\n",
    "\n",
    "\n",
    "device=\"cpu\"\n",
    "lr=3e-5#1e-3\n",
    "num_training_steps=int(len(dataset) / TRAIN_BATCH_SIZE * EPOCH)\n",
    "\n",
    "model=Bert_Classification_Model().to(device)\n",
    "optimizer=AdamW(model.parameters(), lr=lr)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                        num_warmup_steps = 0,\n",
    "                                        num_training_steps = num_training_steps)\n",
    "val_losses=[]\n",
    "batches_losses=[]\n",
    "val_acc=[]\n",
    "for epoch in range(EPOCH):\n",
    "    t0 = time.time()    \n",
    "    print(f\"\\n=============== EPOCH {epoch+1} / {EPOCH} ===============\\n\")\n",
    "    batches_losses_tmp=train_loop_fun1(train_data_loader, model, optimizer, device)\n",
    "    epoch_loss=np.mean(batches_losses_tmp)\n",
    "    print(f\"\\n*** avg_loss : {epoch_loss:.2f}, time : ~{(time.time()-t0)//60} min ({time.time()-t0:.2f} sec) ***\\n\")\n",
    "    t1=time.time()\n",
    "    output, target, val_losses_tmp=eval_loop_fun1(valid_data_loader, model, device)\n",
    "    print(f\"==> evaluation : avg_loss = {np.mean(val_losses_tmp):.2f}, time : {time.time()-t1:.2f} sec\\n\")\n",
    "    tmp_evaluate=evaluate(target.reshape(-1), output)\n",
    "    print(f\"=====>\\t{tmp_evaluate}\")\n",
    "    val_acc.append(tmp_evaluate['accuracy'])\n",
    "    val_losses.append(val_losses_tmp)\n",
    "    batches_losses.append(batches_losses_tmp)\n",
    "    print(f\"\\t§§ Truncation {approach} only model has been saved §§\")\n",
    "    torch.save(model, f\"model_truncation/{approach}_only/model_{approach}_only_epoch{epoch+1}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Third segmetation approach: tail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in this approach, we will keep only the last chunk of 200 tokens for each documents, so if a document is split into 3 chunk of 200, we will only keep the last chunk and we will not keep the first two chunk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img/Tail_Truncation.png](img/Tail_Truncation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n",
      "Nettoyage des données\n",
      "\n",
      "=============== EPOCH 1 / 1 ===============\n",
      "\n",
      "___ batch index = 0 / 65 (0.00%), loss = 0.7183, time = 5.85 secondes ___\n",
      "\n",
      "*** avg_loss : 0.73, time : ~5.0 min (351.94 sec) ***\n",
      "\n",
      "==> evaluation : avg_loss = 0.76, time : 26.05 sec\n",
      "\n",
      "=====>\t{'accuracy': 0.5813953488372093, 'nb exemple': 129, 'true_prediction': 75, 'false_prediction': 54}\n",
      "\t§§ Truncation tail only model has been saved §§\n"
     ]
    }
   ],
   "source": [
    "TRAIN_BATCH_SIZE=8\n",
    "EPOCH=1\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "MIN_LEN=249\n",
    "MAX_LEN = 100000\n",
    "CHUNK_LEN=200\n",
    "OVERLAP_LEN=50\n",
    "#MAX_LEN=10000000\n",
    "#MAX_SIZE_DATASET=1000\n",
    "approach='tail'\n",
    "\n",
    "print('Loading BERT tokenizer...')\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "dataset=ICAADDataset1(\n",
    "    tokenizer=bert_tokenizer,\n",
    "    min_len=MIN_LEN,\n",
    "    max_len=MAX_LEN,\n",
    "    chunk_len=CHUNK_LEN,\n",
    "    #max_size_dataset=MAX_SIZE_DATASET,\n",
    "    overlap_len=OVERLAP_LEN,\n",
    "    approach=approach)\n",
    "\n",
    "\n",
    "#train_size = int(0.8 * len(dataset))\n",
    "#test_size = len(dataset) - train_size\n",
    "#train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_data_loader=DataLoader(\n",
    "    dataset,\n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    sampler=train_sampler,\n",
    "    collate_fn=my_collate1)\n",
    "\n",
    "valid_data_loader=DataLoader(\n",
    "    dataset,\n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    sampler=valid_sampler,\n",
    "    collate_fn=my_collate1)\n",
    "\n",
    "\n",
    "device=\"cpu\"\n",
    "lr=3e-5#1e-3\n",
    "num_training_steps=int(len(dataset) / TRAIN_BATCH_SIZE * EPOCH)\n",
    "\n",
    "model=Bert_Classification_Model().to(device)\n",
    "optimizer=AdamW(model.parameters(), lr=lr)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                        num_warmup_steps = 0,\n",
    "                                        num_training_steps = num_training_steps)\n",
    "val_losses=[]\n",
    "batches_losses=[]\n",
    "val_acc=[]\n",
    "for epoch in range(EPOCH):\n",
    "    t0 = time.time()    \n",
    "    print(f\"\\n=============== EPOCH {epoch+1} / {EPOCH} ===============\\n\")\n",
    "    batches_losses_tmp=train_loop_fun1(train_data_loader, model, optimizer, device)\n",
    "    epoch_loss=np.mean(batches_losses_tmp)\n",
    "    print(f\"\\n*** avg_loss : {epoch_loss:.2f}, time : ~{(time.time()-t0)//60} min ({time.time()-t0:.2f} sec) ***\\n\")\n",
    "    t1=time.time()\n",
    "    output, target, val_losses_tmp=eval_loop_fun1(valid_data_loader, model, device)\n",
    "    print(f\"==> evaluation : avg_loss = {np.mean(val_losses_tmp):.2f}, time : {time.time()-t1:.2f} sec\\n\")\n",
    "    tmp_evaluate=evaluate(target.reshape(-1), output)\n",
    "    print(f\"=====>\\t{tmp_evaluate}\")\n",
    "    val_acc.append(tmp_evaluate['accuracy'])\n",
    "    val_losses.append(val_losses_tmp)\n",
    "    batches_losses.append(batches_losses_tmp)\n",
    "    print(f\"\\t§§ Truncation {approach} only model has been saved §§\")\n",
    "    torch.save(model, f\"model_truncation/{approach}_only/model_{approach}_only_epoch{epoch+1}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the Hierarchical methods applies to the ouputs of the Bert model (the embbeding)\n",
    "The input text is firstly divided into k = L/510 fractions, which is fed into BERT to obtain the representation of the k text fractions. The representation of each fraction is the hidden state of the `[CLS]` tokens of the last layer. Then we use mean pooling, max pooling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Pooling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in this approach, we average the embedding of all k chunks across each dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img/Mean_Pooling_Hierarchical.png](img/Mean_Pooling_Hierarchical.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n",
      "Nettoyage des données\n",
      "\n",
      "=============== EPOCH 1 / 1 ===============\n",
      "\n",
      "___ batch index = 0 / 172 (0.00%), loss = 2.4265, time = 28.89 secondes ___\n",
      "\n",
      "*** avg_loss : 0.83, time : ~133.0 min (7981.14 sec) ***\n",
      "\n",
      "==> evaluation : avg_loss = 0.70, time : 221.92 sec\n",
      "\n",
      "=====>\t{'accuracy': 0.6511627906976745, 'nb exemple': 129, 'true_prediction': 84, 'false_prediction': 45}\n",
      "\t§§ the Hierarchical mean pooling model has been saved §§\n"
     ]
    }
   ],
   "source": [
    "TRAIN_BATCH_SIZE=3\n",
    "EPOCH=1\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "MIN_LEN=249\n",
    "MAX_LEN = 100000\n",
    "CHUNK_LEN=200\n",
    "OVERLAP_LEN=50\n",
    "#MAX_LEN=10000000\n",
    "#MAX_SIZE_DATASET=1000\n",
    "\n",
    "print('Loading BERT tokenizer...')\n",
    "bert_tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\", do_lower_case=True)\n",
    "\n",
    "dataset=ICAADDataset1(\n",
    "    tokenizer=bert_tokenizer,\n",
    "    min_len=MIN_LEN,\n",
    "    max_len=MAX_LEN,\n",
    "    chunk_len=CHUNK_LEN,\n",
    "    #max_size_dataset=MAX_SIZE_DATASET,\n",
    "    overlap_len=OVERLAP_LEN)\n",
    "\n",
    "\n",
    "#train_size = int(0.8 * len(dataset))\n",
    "#test_size = len(dataset) - train_size\n",
    "#train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_data_loader=DataLoader(\n",
    "    dataset,\n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    sampler=train_sampler,\n",
    "    collate_fn=my_collate1)\n",
    "\n",
    "valid_data_loader=DataLoader(\n",
    "    dataset,\n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    sampler=valid_sampler,\n",
    "    collate_fn=my_collate1)\n",
    "\n",
    "\n",
    "device=\"cpu\"\n",
    "lr=3e-5#1e-3\n",
    "num_training_steps=int(len(dataset) / TRAIN_BATCH_SIZE * EPOCH)\n",
    "\n",
    "pooling_method=\"mean\"\n",
    "model_hierarchical=BERT_Hierarchical_Model(pooling_method=pooling_method).to(device)\n",
    "optimizer=AdamW(model_hierarchical.parameters(), lr=lr)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                        num_warmup_steps = 0,\n",
    "                                        num_training_steps = num_training_steps)\n",
    "val_losses=[]\n",
    "batches_losses=[]\n",
    "val_acc=[]\n",
    "for epoch in range(EPOCH):\n",
    "    t0 = time.time()    \n",
    "    print(f\"\\n=============== EPOCH {epoch+1} / {EPOCH} ===============\\n\")\n",
    "    batches_losses_tmp=rnn_train_loop_fun1(train_data_loader, model_hierarchical, optimizer, device)\n",
    "    epoch_loss=np.mean(batches_losses_tmp)\n",
    "    print(f\"\\n*** avg_loss : {epoch_loss:.2f}, time : ~{(time.time()-t0)//60} min ({time.time()-t0:.2f} sec) ***\\n\")\n",
    "    t1=time.time()\n",
    "    output, target, val_losses_tmp=rnn_eval_loop_fun1(valid_data_loader, model_hierarchical, device)\n",
    "    print(f\"==> evaluation : avg_loss = {np.mean(val_losses_tmp):.2f}, time : {time.time()-t1:.2f} sec\\n\")    \n",
    "    tmp_evaluate=evaluate(target.reshape(-1), output)\n",
    "    print(f\"=====>\\t{tmp_evaluate}\")\n",
    "    val_acc.append(tmp_evaluate['accuracy'])\n",
    "    val_losses.append(val_losses_tmp)\n",
    "    batches_losses.append(batches_losses_tmp)\n",
    "    print(f\"\\t§§ the Hierarchical {pooling_method} pooling model has been saved §§\")\n",
    "    torch.save(model_hierarchical, f\"model_hierarchical/{pooling_method}_pooling/model_{pooling_method}_pooling_epoch{epoch+1}.pt\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Max Pooling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in this approach, we take the maximum embedding of all the k chunks across each dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img/Max_Pooling_Hierarchical.png](img/Max_Pooling_Hierarchical.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n",
      "Nettoyage des données\n",
      "\n",
      "=============== EPOCH 1 / 1 ===============\n",
      "\n",
      "___ batch index = 0 / 172 (0.00%), loss = 2.4782, time = 19.44 secondes ___\n",
      "\n",
      "*** avg_loss : 0.86, time : ~186.0 min (11174.40 sec) ***\n",
      "\n",
      "==> evaluation : avg_loss = 0.69, time : 246.66 sec\n",
      "\n",
      "=====>\t{'accuracy': 0.5813953488372093, 'nb exemple': 129, 'true_prediction': 75, 'false_prediction': 54}\n",
      "\t§§ the Hierarchical max pooling model has been saved §§\n"
     ]
    }
   ],
   "source": [
    "TRAIN_BATCH_SIZE=3\n",
    "EPOCH=1\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "MIN_LEN=249\n",
    "MAX_LEN = 100000\n",
    "CHUNK_LEN=200\n",
    "OVERLAP_LEN=50\n",
    "#MAX_LEN=10000000\n",
    "#MAX_SIZE_DATASET=1000\n",
    "\n",
    "print('Loading BERT tokenizer...')\n",
    "#bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "bert_tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\", do_lower_case=True)\n",
    "\n",
    "dataset=ICAADDataset1(\n",
    "    tokenizer=bert_tokenizer,\n",
    "    min_len=MIN_LEN,\n",
    "    max_len=MAX_LEN,\n",
    "    chunk_len=CHUNK_LEN,\n",
    "    #max_size_dataset=MAX_SIZE_DATASET,\n",
    "    overlap_len=OVERLAP_LEN)\n",
    "\n",
    "\n",
    "#train_size = int(0.8 * len(dataset))\n",
    "#test_size = len(dataset) - train_size\n",
    "#train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_data_loader=DataLoader(\n",
    "    dataset,\n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    sampler=train_sampler,\n",
    "    collate_fn=my_collate1)\n",
    "\n",
    "valid_data_loader=DataLoader(\n",
    "    dataset,\n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    sampler=valid_sampler,\n",
    "    collate_fn=my_collate1)\n",
    "\n",
    "\n",
    "device=\"cpu\"\n",
    "lr=3e-5#1e-3\n",
    "num_training_steps=int(len(dataset) / TRAIN_BATCH_SIZE * EPOCH)\n",
    "\n",
    "pooling_method=\"max\"\n",
    "model_hierarchical=BERT_Hierarchical_Model(pooling_method=pooling_method).to(device)\n",
    "optimizer=AdamW(model_hierarchical.parameters(), lr=lr)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                        num_warmup_steps = 0,\n",
    "                                        num_training_steps = num_training_steps)\n",
    "val_losses=[]\n",
    "batches_losses=[]\n",
    "val_acc=[]\n",
    "for epoch in range(EPOCH):\n",
    "    t0 = time.time()    \n",
    "    print(f\"\\n=============== EPOCH {epoch+1} / {EPOCH} ===============\\n\")\n",
    "    batches_losses_tmp=rnn_train_loop_fun1(train_data_loader, model_hierarchical, optimizer, device)\n",
    "    epoch_loss=np.mean(batches_losses_tmp)\n",
    "    print(f\"\\n*** avg_loss : {epoch_loss:.2f}, time : ~{(time.time()-t0)//60} min ({time.time()-t0:.2f} sec) ***\\n\")\n",
    "    t1=time.time()\n",
    "    output, target, val_losses_tmp=rnn_eval_loop_fun1(valid_data_loader, model_hierarchical, device)\n",
    "    print(f\"==> evaluation : avg_loss = {np.mean(val_losses_tmp):.2f}, time : {time.time()-t1:.2f} sec\\n\")    \n",
    "    tmp_evaluate=evaluate(target.reshape(-1), output)\n",
    "    print(f\"=====>\\t{tmp_evaluate}\")\n",
    "    val_acc.append(tmp_evaluate['accuracy'])\n",
    "    val_losses.append(val_losses_tmp)\n",
    "    batches_losses.append(batches_losses_tmp)\n",
    "    print(f\"\\t§§ the Hierarchical {pooling_method} pooling model has been saved §§\")\n",
    "    torch.save(model_hierarchical, f\"model_hierarchical/{pooling_method}_pooling/model_{pooling_method}_pooling_epoch{epoch+1}.pt\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RoBERT RNN classifier on top of the Fine Tuned Bert Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The input text is firstly divided into k = L/510 fractions, which is fed into the fine tuned BERT (as describe above, *cf: First segmetation approach: all*) to obtain the representation of the k text chunks. The representation of each fraction is the hidden state of the `[CLS]` tokens of the last layer.\n",
    " \n",
    "Each chunk embedding (representation) become the input of an LSTM cell, this way the order is preserved and the length of the document is not a limitation anymore because of the dynamic aspect of the LSTM that allow different variable sequence lengths (accros different batches)\n",
    "\n",
    "we then pass the last hidden state (nbDoc * 100) to a neural network with the same architecture (as describe above, we use the same neural network architecture for classification through the all notebook, [cf: 3. Fine-tuning on the 200 tokens chunks](#3.-Fine-tuning-on-the-200-tokens-chunks:)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img/RoBERT.png](img/RoBERT.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n",
      "Nettoyage des données\n",
      "\n",
      "=============== EPOCH 1 / 3 ===============\n",
      "\n",
      "___ batch index = 0 / 172 (0.00%), loss = 2.2398, time = 10.57 secondes ___\n",
      "\n",
      "*** avg_loss : 0.96, time : ~123.0 min (7434.36 sec) ***\n",
      "\n",
      "==> evaluation : avg_loss = 0.82, time : 231.86 sec\n",
      "\n",
      "=====>\t{'accuracy': 0.5813953488372093, 'nb exemple': 129, 'true_prediction': 75, 'false_prediction': 54}\n",
      "\t§§ the RNN model has been saved §§\n",
      "\n",
      "=============== EPOCH 2 / 3 ===============\n",
      "\n",
      "___ batch index = 0 / 172 (0.00%), loss = 0.9916, time = 20.71 secondes ___\n",
      "\n",
      "*** avg_loss : 0.80, time : ~112.0 min (6735.83 sec) ***\n",
      "\n",
      "==> evaluation : avg_loss = 0.76, time : 233.71 sec\n",
      "\n",
      "=====>\t{'accuracy': 0.5813953488372093, 'nb exemple': 129, 'true_prediction': 75, 'false_prediction': 54}\n",
      "\t§§ the RNN model has been saved §§\n",
      "\n",
      "=============== EPOCH 3 / 3 ===============\n",
      "\n",
      "___ batch index = 0 / 172 (0.00%), loss = 0.7268, time = 20.29 secondes ___\n",
      "\n",
      "*** avg_loss : 0.75, time : ~209.0 min (12596.02 sec) ***\n",
      "\n",
      "==> evaluation : avg_loss = 0.74, time : 232.08 sec\n",
      "\n",
      "=====>\t{'accuracy': 0.5813953488372093, 'nb exemple': 129, 'true_prediction': 75, 'false_prediction': 54}\n",
      "\t§§ the RNN model has been saved §§\n"
     ]
    }
   ],
   "source": [
    "TRAIN_BATCH_SIZE=3\n",
    "EPOCH=3\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "MIN_LEN=249\n",
    "MAX_LEN = 100000\n",
    "CHUNK_LEN=200\n",
    "OVERLAP_LEN=50\n",
    "#MAX_LEN=10000000\n",
    "#MAX_SIZE_DATASET=1000\n",
    "\n",
    "print('Loading BERT tokenizer...')\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "dataset=ICAADDataset1(\n",
    "    tokenizer=bert_tokenizer,\n",
    "    min_len=MIN_LEN,\n",
    "    max_len=MAX_LEN,\n",
    "    chunk_len=CHUNK_LEN,\n",
    "    #max_size_dataset=MAX_SIZE_DATASET,\n",
    "    overlap_len=OVERLAP_LEN)\n",
    "\n",
    "\n",
    "#train_size = int(0.8 * len(dataset))\n",
    "#test_size = len(dataset) - train_size\n",
    "#train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_data_loader=DataLoader(\n",
    "    dataset,\n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    sampler=train_sampler,\n",
    "    collate_fn=my_collate1)\n",
    "\n",
    "valid_data_loader=DataLoader(\n",
    "    dataset,\n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    sampler=valid_sampler,\n",
    "    collate_fn=my_collate1)\n",
    "\n",
    "\n",
    "device=\"cpu\"\n",
    "lr=3e-5#1e-3\n",
    "num_training_steps=int(len(dataset) / TRAIN_BATCH_SIZE * EPOCH)\n",
    "\n",
    "model=torch.load(\"model1/model_epoch1.pt\")\n",
    "\n",
    "model_rnn=RoBERT_Model(bertFineTuned=list(model.children())[0]).to(device)\n",
    "optimizer=AdamW(model_rnn.parameters(), lr=lr)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                        num_warmup_steps = 0,\n",
    "                                        num_training_steps = num_training_steps)\n",
    "val_losses=[]\n",
    "batches_losses=[]\n",
    "val_acc=[]\n",
    "for epoch in range(EPOCH):\n",
    "    t0 = time.time()    \n",
    "    print(f\"\\n=============== EPOCH {epoch+1} / {EPOCH} ===============\\n\")\n",
    "    batches_losses_tmp=rnn_train_loop_fun1(train_data_loader, model_rnn, optimizer, device)\n",
    "    epoch_loss=np.mean(batches_losses_tmp)\n",
    "    print(f\"\\n*** avg_loss : {epoch_loss:.2f}, time : ~{(time.time()-t0)//60} min ({time.time()-t0:.2f} sec) ***\\n\")\n",
    "    t1=time.time()\n",
    "    output, target, val_losses_tmp=rnn_eval_loop_fun1(valid_data_loader, model_rnn, device)\n",
    "    print(f\"==> evaluation : avg_loss = {np.mean(val_losses_tmp):.2f}, time : {time.time()-t1:.2f} sec\\n\")    \n",
    "    tmp_evaluate=evaluate(target.reshape(-1), output)\n",
    "    print(f\"=====>\\t{tmp_evaluate}\")\n",
    "    val_acc.append(tmp_evaluate['accuracy'])\n",
    "    val_losses.append(val_losses_tmp)\n",
    "    batches_losses.append(batches_losses_tmp)\n",
    "    print(\"\\t§§ the RNN model has been saved §§\")\n",
    "    torch.save(model_rnn, f\"model_rnn1/model_rnn_epoch{epoch+1}.pt\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f7b45d28850>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(np.array([[np.mean(x) for x in batches_losses], [np.mean(x) for x in val_losses]]).T,\n",
    "                   columns=['Training', 'Validation']).plot(title=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f89c733bb90>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(np.array(val_acc).T,\n",
    "                   columns=['Validation']).plot(title=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>after one epoch</th>\n",
       "      <th>all</th>\n",
       "      <th>head only</th>\n",
       "      <th>tail only</th>\n",
       "      <th>mean pooling</th>\n",
       "      <th>max pooling</th>\n",
       "      <th>RoBERT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>avg_loss_train</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_loss_val</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "after one epoch   all  head only  tail only  mean pooling  max pooling  RoBERT\n",
       "avg_loss_train   0.76       0.79       0.73          0.83         0.86    0.96\n",
       "avg_loss_val     0.74       0.61       0.76          0.70         0.69    0.82\n",
       "accuracy         0.42       0.58       0.58          0.65         0.58    0.58"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "summary=pd.DataFrame({\"all\":[0.76, 0.74, 0.42], \n",
    "                      \"head only\":[0.79, 0.61, 0.58], \n",
    "                      \"tail only\":[0.73, 0.76, 0.58], \n",
    "                      \"mean pooling\":[0.83, 0.70, 0.65], \n",
    "                      \"max pooling\":[0.86, 0.69, 0.58], \n",
    "                      \"RoBERT\":[0.96, 0.82, 0.58]}, index=[\"avg_loss_train\", \"avg_loss_val\", \"accuracy\"])\n",
    "summary.columns.name = 'after one epoch'\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary (original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_fd811f74_9eee_11ea_938d_e547e2e2711drow0_col5 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_fd811f74_9eee_11ea_938d_e547e2e2711drow1_col5 {\n",
       "            font-weight:  bold;\n",
       "        }    #T_fd811f74_9eee_11ea_938d_e547e2e2711drow2_col5 {\n",
       "            font-weight:  bold;\n",
       "        }</style><table id=\"T_fd811f74_9eee_11ea_938d_e547e2e2711d\" ><thead>    <tr>        <th class=\"index_name level0\" >after one epoch</th>        <th class=\"col_heading level0 col0\" >all</th>        <th class=\"col_heading level0 col1\" >head only</th>        <th class=\"col_heading level0 col2\" >tail only</th>        <th class=\"col_heading level0 col3\" >mean pooling</th>        <th class=\"col_heading level0 col4\" >max pooling</th>        <th class=\"col_heading level0 col5\" >RoBERT</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_fd811f74_9eee_11ea_938d_e547e2e2711dlevel0_row0\" class=\"row_heading level0 row0\" >avg_loss_train</th>\n",
       "                        <td id=\"T_fd811f74_9eee_11ea_938d_e547e2e2711drow0_col0\" class=\"data row0 col0\" >0.74</td>\n",
       "                        <td id=\"T_fd811f74_9eee_11ea_938d_e547e2e2711drow0_col1\" class=\"data row0 col1\" >0.62</td>\n",
       "                        <td id=\"T_fd811f74_9eee_11ea_938d_e547e2e2711drow0_col2\" class=\"data row0 col2\" >0.93</td>\n",
       "                        <td id=\"T_fd811f74_9eee_11ea_938d_e547e2e2711drow0_col3\" class=\"data row0 col3\" >0.62</td>\n",
       "                        <td id=\"T_fd811f74_9eee_11ea_938d_e547e2e2711drow0_col4\" class=\"data row0 col4\" >0.65</td>\n",
       "                        <td id=\"T_fd811f74_9eee_11ea_938d_e547e2e2711drow0_col5\" class=\"data row0 col5\" >0.46</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_fd811f74_9eee_11ea_938d_e547e2e2711dlevel0_row1\" class=\"row_heading level0 row1\" >avg_loss_val</th>\n",
       "                        <td id=\"T_fd811f74_9eee_11ea_938d_e547e2e2711drow1_col0\" class=\"data row1 col0\" >0.57</td>\n",
       "                        <td id=\"T_fd811f74_9eee_11ea_938d_e547e2e2711drow1_col1\" class=\"data row1 col1\" >0.45</td>\n",
       "                        <td id=\"T_fd811f74_9eee_11ea_938d_e547e2e2711drow1_col2\" class=\"data row1 col2\" >0.75</td>\n",
       "                        <td id=\"T_fd811f74_9eee_11ea_938d_e547e2e2711drow1_col3\" class=\"data row1 col3\" >0.47</td>\n",
       "                        <td id=\"T_fd811f74_9eee_11ea_938d_e547e2e2711drow1_col4\" class=\"data row1 col4\" >0.45</td>\n",
       "                        <td id=\"T_fd811f74_9eee_11ea_938d_e547e2e2711drow1_col5\" class=\"data row1 col5\" >0.34</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_fd811f74_9eee_11ea_938d_e547e2e2711dlevel0_row2\" class=\"row_heading level0 row2\" >accuracy</th>\n",
       "                        <td id=\"T_fd811f74_9eee_11ea_938d_e547e2e2711drow2_col0\" class=\"data row2 col0\" >0.83</td>\n",
       "                        <td id=\"T_fd811f74_9eee_11ea_938d_e547e2e2711drow2_col1\" class=\"data row2 col1\" >0.87</td>\n",
       "                        <td id=\"T_fd811f74_9eee_11ea_938d_e547e2e2711drow2_col2\" class=\"data row2 col2\" >0.77</td>\n",
       "                        <td id=\"T_fd811f74_9eee_11ea_938d_e547e2e2711drow2_col3\" class=\"data row2 col3\" >0.87</td>\n",
       "                        <td id=\"T_fd811f74_9eee_11ea_938d_e547e2e2711drow2_col4\" class=\"data row2 col4\" >0.87</td>\n",
       "                        <td id=\"T_fd811f74_9eee_11ea_938d_e547e2e2711drow2_col5\" class=\"data row2 col5\" >0.91</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f1e867eedd0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary=pd.DataFrame({\"all\":[0.74, 0.57, 0.83], \n",
    "                     \"head only\":[0.62, 0.45, 0.87], \n",
    "                      \"tail only\":[0.93, 0.75, 0.77], \n",
    "                      \"mean pooling\":[0.62, 0.47, 0.87], \n",
    "                      \"max pooling\":[0.65, 0.45, 0.87], \n",
    "                      \"RoBERT\":[0.46, 0.34, 0.91]}, index=[\"avg_loss_train\", \"avg_loss_val\", \"accuracy\"])\n",
    "summary.columns.name = 'after one epoch'\n",
    "summary.style.set_properties(\n",
    "    subset=['RoBERT'], \n",
    "    **{'font-weight': 'bold'}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that the RoBERT Model give the best result, so we can conclude that this Model a net State Of the Art improvement in term of the loss function and the accuracy, the second model is the head only, this make sense because we can imagine that the consumer introduce his complain within the first part of his comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "w266",
   "language": "python",
   "name": "w266"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
