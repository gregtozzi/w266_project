{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM model trained on frozed DistilBert embeddings\n",
    "\n",
    "Includes embedding function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EG0yd3HsYgjR"
   },
   "outputs": [],
   "source": [
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2SPqLrOFY0fr",
    "outputId": "d504475d-e853-42d9-df8e-6525d0a4159e"
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "from transformers import DistilBertTokenizer, DistilBertConfig, TFDistilBertModel, TFDistilBertForSequenceClassification\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import textwrap\n",
    "import pickle\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "\n",
    "import keras\n",
    "from keras import Sequential\n",
    "from keras.utils import Sequence\n",
    "from keras.layers import LSTM, Dense, Masking\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Embedding, Dense, Input, concatenate, Layer, Lambda, Dropout, Activation\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, Callback, TensorBoard\n",
    "from keras import layers\n",
    "from keras.layers import Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M6Tl5F6lY7Jo"
   },
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "VlzOtpKtY4uk",
    "outputId": "259f0eed-5ac0-4238-83ef-54b2075253c9"
   },
   "outputs": [],
   "source": [
    "train_file = \"../data/train_80_10_10.csv\"\n",
    "test_file = \"../data/test_80_10_10.csv\"\n",
    "val_file = \"../data/val_80_10_10.csv\"\n",
    "\n",
    "skip_lines = 6\n",
    "max_length = 200\n",
    "split_length = max_length - 2\n",
    "\n",
    "\n",
    "# DistilBert\n",
    "bert_file = 'distilbert-base-uncased'\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(bert_file, do_lower_case=True)\n",
    "bert_model = TFDistilBertForSequenceClassification.from_pretrained(bert_file)\n",
    "\n",
    "# Model Training\n",
    "batch_size = 8\n",
    "epochs = 3\n",
    "learning_rate = 2e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "c1LmabBdY-PE",
    "outputId": "419415f5-373c-41c0-dacb-c0f665700ba4"
   },
   "outputs": [],
   "source": [
    "# Get the GPU device name.\n",
    "device_name = tf.test.gpu_device_name()\n",
    "\n",
    "# The device name should look like the following:\n",
    "if device_name == '/device:GPU:0':\n",
    "    print('Found GPU at: {}'.format(device_name))\n",
    "else:\n",
    "    raise SystemError('GPU device not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-cj5VD5zZBGk"
   },
   "outputs": [],
   "source": [
    "# Function to get data\n",
    "def get_data(fname):\n",
    "    df = pd.read_csv(fname)\n",
    "    df = df[['docid', 'cleaned_contents', 'Discrimination_Label']]\n",
    "    df = df.rename(columns = {'cleaned_contents':'text', 'Discrimination_Label':'label'})\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oo1OnHmMZBM6"
   },
   "outputs": [],
   "source": [
    "# Function to tokenize data and return tensors for input ids, attention mask and labels\n",
    "def tokenize_plus(df):\n",
    "\n",
    "    # Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "    sentences = df['text'].values\n",
    "    labels = df['label'].values\n",
    "\n",
    "    input_ids = []\n",
    "    input_masks = []\n",
    "    input_segments = []\n",
    "\n",
    "    # For every sentence...\n",
    "    for sent in sentences:\n",
    "        inputs = tokenizer.encode_plus(sent, \n",
    "                                       add_special_tokens=True, \n",
    "                                       max_length=max_length, \n",
    "                                       truncation = True,\n",
    "                                       pad_to_max_length=True, \n",
    "                                       return_attention_mask=True,\n",
    "                                       return_token_type_ids=True)\n",
    "\n",
    "        input_ids.append(inputs['input_ids'])\n",
    "        input_masks.append(inputs['attention_mask'])\n",
    "        input_segments.append(inputs['token_type_ids'])   \n",
    "    \n",
    "    labels = df['label']\n",
    "\n",
    "    return np.asarray(input_ids, dtype='int32'), np.asarray(input_masks, dtype='int32'), np.asarray(labels, dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "86ZIJjrcZBTG"
   },
   "outputs": [],
   "source": [
    "# function to split text into smaller chunks of 200 words, overlapping by 50 words\n",
    "def get_split(text1):\n",
    "  l_total = []\n",
    "  l_parcial = []\n",
    "  if len(text1.split())//150 >0:\n",
    "    n = len(text1.split())//150\n",
    "  else: \n",
    "    n = 1\n",
    "  for w in range(n):\n",
    "    if w == 0:\n",
    "      l_parcial = text1.split()[:200]\n",
    "      l_total.append(\" \".join(l_parcial))\n",
    "    else:\n",
    "      l_parcial = text1.split()[w*150:w*150 + 200]\n",
    "      l_total.append(\" \".join(l_parcial))\n",
    "  return l_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ziAr6sTSZBSR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NbFA03LSZM5k"
   },
   "source": [
    "# Data Prep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ffRloI5nZBKH"
   },
   "outputs": [],
   "source": [
    "# GET THE DATA\n",
    "df_train = get_data(train_file)\n",
    "df_test = get_data(test_file)\n",
    "df_val = get_data(val_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wbP3RzNnZTSz"
   },
   "outputs": [],
   "source": [
    "#remove double new lines\n",
    "df_train['text'] = df_train['text'].replace('\\n\\s*\\n', '\\n',regex=True)\n",
    "df_test['text'] = df_test['text'].replace('\\n\\s*\\n', '\\n',regex=True)\n",
    "df_val['text'] = df_val['text'].replace('\\n\\s*\\n', '\\n',regex=True)\n",
    "\n",
    "# strip last n lines\n",
    "df_train['text'] = df_train.apply(lambda L: L.text.rsplit(\"\\n\",skip_lines)[0], axis=1)\n",
    "df_test['text'] = df_test.apply(lambda L: L.text.rsplit(\"\\n\",skip_lines)[0], axis=1)\n",
    "df_val['text'] = df_val.apply(lambda L: L.text.rsplit(\"\\n\",skip_lines)[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "id": "gSwe_v2BZTWq",
    "outputId": "0ab3da03-db6d-4f12-d37c-bce7ffff6280"
   },
   "outputs": [],
   "source": [
    "# split the texts into  chunks & # explode the dataframe\n",
    "df_train['text_split'] = df_train['text'].apply(get_split)\n",
    "df_train = df_train.explode('text_split')\n",
    "\n",
    "# split the texts into   chunks & # explode the dataframe\n",
    "df_val['text_split'] = df_val['text'].apply(get_split)\n",
    "df_val = df_val.explode('text_split')\n",
    "\n",
    "# split the texts into   chunks & # explode the dataframe\n",
    "df_test['text_split'] = df_test['text'].apply(get_split)\n",
    "df_test = df_test.explode('text_split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "PCCdZDSqZiib",
    "outputId": "bf5e89ce-6d03-4cec-86b0-ecc04e4fb21a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>255849</td>\n",
       "      <td>SENTENCE\\n• In a judgment delivered on 9 May 2...</td>\n",
       "      <td>0</td>\n",
       "      <td>SENTENCE • In a judgment delivered on 9 May 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>255849</td>\n",
       "      <td>SENTENCE\\n• In a judgment delivered on 9 May 2...</td>\n",
       "      <td>0</td>\n",
       "      <td>that she blacked out. • She came to in a frien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>255849</td>\n",
       "      <td>SENTENCE\\n• In a judgment delivered on 9 May 2...</td>\n",
       "      <td>0</td>\n",
       "      <td>quality life. Those who find themselves on the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>255849</td>\n",
       "      <td>SENTENCE\\n• In a judgment delivered on 9 May 2...</td>\n",
       "      <td>0</td>\n",
       "      <td>with you as she was asleep. You then raped her...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>288617</td>\n",
       "      <td>SENTENCE\\n• ELIZABETH GOLMAN, you were charged...</td>\n",
       "      <td>1</td>\n",
       "      <td>SENTENCE • ELIZABETH GOLMAN, you were charged ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    docid                                               text  label  \\\n",
       "0  255849  SENTENCE\\n• In a judgment delivered on 9 May 2...      0   \n",
       "0  255849  SENTENCE\\n• In a judgment delivered on 9 May 2...      0   \n",
       "0  255849  SENTENCE\\n• In a judgment delivered on 9 May 2...      0   \n",
       "0  255849  SENTENCE\\n• In a judgment delivered on 9 May 2...      0   \n",
       "1  288617  SENTENCE\\n• ELIZABETH GOLMAN, you were charged...      1   \n",
       "\n",
       "                                          text_split  \n",
       "0  SENTENCE • In a judgment delivered on 9 May 20...  \n",
       "0  that she blacked out. • She came to in a frien...  \n",
       "0  quality life. Those who find themselves on the...  \n",
       "0  with you as she was asleep. You then raped her...  \n",
       "1  SENTENCE • ELIZABETH GOLMAN, you were charged ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6004"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4IkGpWSXZd9i"
   },
   "outputs": [],
   "source": [
    "# get the tokens\n",
    "# Get tokenized labels\n",
    "input_ids, attention_masks, labels = tokenize_plus(df_train)\n",
    "val_input_ids, val_attention_masks, val_labels = tokenize_plus(df_val)\n",
    "test_input_ids, test_attention_masks, test_labels = tokenize_plus(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#That last step took longer than it should, lets save the train output just in case...\n",
    "with open('test_last_hidden_states.pkl', 'wb') as f: \n",
    "  pickle.dump(input_ids, f)\n",
    "with open('attention_masks.pkl', 'wb') as f: \n",
    "  pickle.dump(attention_masks, f)\n",
    "with open('labels.pkl', 'wb') as f: \n",
    "  pickle.dump(labels, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "thoqvzT-ZuHY"
   },
   "source": [
    "# Model to get token embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "Gxd35DEtZxrx",
    "outputId": "97663d88-1c17-4589-f3be-588887f115d0"
   },
   "outputs": [],
   "source": [
    "config = DistilBertConfig(dropout=0.2, attention_dropout=0.2)\n",
    "config.output_hidden_states = False\n",
    "transformer_model = TFDistilBertModel.from_pretrained(bert_file, config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nRIx-Cn4ZeC-"
   },
   "outputs": [],
   "source": [
    "#embedding mode\n",
    "input_ids_in = tf.keras.layers.Input(shape=(200,), name='input_token', dtype='int32')\n",
    "input_masks_in = tf.keras.layers.Input(shape=(200,), name='masked_token', dtype='int32') \n",
    "cls_token = transformer_model(input_ids_in, attention_mask=input_masks_in)[0]\n",
    "model = tf.keras.Model(inputs=[input_ids_in, input_masks_in], outputs = cls_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "SNmTfteudmZf",
    "outputId": "43ea593e-6491-4df3-eabc-37d3e4bc08db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_token (InputLayer)        [(None, 200)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masked_token (InputLayer)       [(None, 200)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_distil_bert_model (TFDistilB ((None, 200, 768),)  66362880    input_token[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 66,362,880\n",
      "Trainable params: 66,362,880\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FpysgjIAaLq3"
   },
   "source": [
    "## Run Model on train, test and val to get feature embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "umVk59bmb4yz"
   },
   "outputs": [],
   "source": [
    "val_last_hidden_states = model.predict([val_input_ids, val_attention_masks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['val_last_hidden_states.pkl.sav']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "filename = 'val_last_hidden_states.pkl.sav'\n",
    "joblib.dump(val_last_hidden_states, filename)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lZuplN2wb4Ld"
   },
   "outputs": [],
   "source": [
    "test_last_hidden_states = model.predict([test_input_ids, test_attention_masks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_last_hidden_states.pkl.sav']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "filename = 'test_last_hidden_states.pkl.sav'\n",
    "joblib.dump(test_last_hidden_states, filename)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hA68e5xzdlRv"
   },
   "outputs": [],
   "source": [
    "last_hidden_states = model.predict([input_ids, attention_masks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "filename = 'train_last_hidden_states.pkl.sav'\n",
    "joblib.dump(last_hidden_states, filename)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2l9igjEnxXWm"
   },
   "outputs": [],
   "source": [
    "with open('test_last_hidden_states.pkl', 'wb') as f: pickle.dump(test_last_hidden_states, f)\n",
    "with open('val_last_hidden_states.pkl', 'wb') as f: pickle.dump(val_last_hidden_states, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fUnEzprmxqL-"
   },
   "outputs": [],
   "source": [
    "with open('train_last_hidden_states.pkl', 'wb') as f: pickle.dump(last_hidden_states, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QHL_yNOAhJDr"
   },
   "source": [
    "## Flatten the dataframes so that each row is a doc, and each feature is a list of embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pSHVTkpH2GYm"
   },
   "outputs": [],
   "source": [
    "#get the pickle file saved earlier\n",
    "with open('train_last_hidden_states.pkl', 'rb') as f: train_last_hidden_states = pickle.load(f)\n",
    "with open('val_last_hidden_states.pkl', 'rb') as f: val_last_hidden_states = pickle.load(f)\n",
    "with open('test_last_hidden_states.pkl', 'rb') as f: test_last_hidden_states = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "antlPXDL2Gh7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VsN3vz6N2Grx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "colab_type": "code",
    "id": "yN7ykDplfMhx",
    "outputId": "2a088546-9c4c-44f1-ec00-b72516f48d72"
   },
   "outputs": [],
   "source": [
    "df_train['feature_split'] = last_hidden_states[:,0,:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S890GgEuajfH"
   },
   "outputs": [],
   "source": [
    "# Put the data back together again - not the feature weights represent\n",
    "df_train = df_train.groupby(['docid', 'text', 'label']).agg(sum).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qBjeuNdCix5Q"
   },
   "outputs": [],
   "source": [
    "# Divide up the feature_split column into equal 768 chunks\n",
    "df_train['features'] = df_train['feature_split'].apply((lambda x: [x[i:i + 768] for i in range(0, len(x), 768)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mflF-VWHZ5ZW"
   },
   "outputs": [],
   "source": [
    "df_test['feature_split'] = test_last_hidden_states[:,0,:].tolist()\n",
    "df_test = df_test.groupby(['docid', 'text', 'label']).agg(sum).reset_index()\n",
    "df_test['features'] = df_test['feature_split'].apply((lambda x: [x[i:i + 768] for i in range(0, len(x), 768)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "znjZv4WeaT5j"
   },
   "outputs": [],
   "source": [
    "df_val['feature_split'] = val_last_hidden_states[:,0,:].tolist()\n",
    "df_val = df_val.groupby(['docid', 'text', 'label']).agg(sum).reset_index()\n",
    "df_val['features'] = df_val['feature_split'].apply((lambda x: [x[i:i + 768] for i in range(0, len(x), 768)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xnXZ1JmU2kLS"
   },
   "outputs": [],
   "source": [
    "df_lstm_train = df_train[['features','label']].copy()\n",
    "df_lstm_test = df_test[['features','label']].copy()\n",
    "df_lstm_val = df_val[['features','label']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xTc-WvHiab3S",
    "outputId": "e722b98a-0cd3-4546-8295-4a9ed4a5a3a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((647, 2), (81, 2), (81, 2))"
      ]
     },
     "execution_count": 145,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check shapes of our new inputs\n",
    "df_lstm_train.shape, df_lstm_test.shape, df_lstm_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dER2BnSdutx6"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('lstm_train.pkl', 'wb') as f: pickle.dump(df_lstm_train, f)\n",
    "with open('lstm_test.pkl', 'wb') as f: pickle.dump(df_lstm_test, f)\n",
    "with open('lstm_val.pkl', 'wb') as f: pickle.dump(df_lstm_val, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rZzkkZeYbaJ1"
   },
   "source": [
    "# LSTM Model on outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mbjYJG4c33gi",
    "outputId": "4138b6e7-4024-4afc-b981-bd955e603226"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 133,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list = [x for x in np.unique(df_lstm_train['label'])]\n",
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "HKIZrTaPbdIs",
    "outputId": "e3b44c32-559a-4708-be5b-d0fe46aeb22f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "text (InputLayer)            (None, None, 768)         0         \n",
      "_________________________________________________________________\n",
      "masking_3 (Masking)          (None, None, 768)         0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 100)               347600    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 30)                3030      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 62        \n",
      "=================================================================\n",
      "Total params: 350,692\n",
      "Trainable params: 350,692\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "text_input = Input(shape=(None,768,), dtype='float32', name='text')\n",
    "\n",
    "l_mask = layers.Masking(mask_value=-99.)(text_input)\n",
    "# Which we encoded in a single vector via a LSTM\n",
    "encoded_text = layers.LSTM(100,)(l_mask)\n",
    "out_dense = layers.Dense(30, activation='relu')(encoded_text)\n",
    "out = layers.Dense(len(label_list), activation='softmax')(out_dense)\n",
    "model = Model(text_input, out)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3ZNQyyf4ImXp"
   },
   "source": [
    "Thanks to Armand Olivares for his post which helped on teh generator function and mask\n",
    "https://medium.com/@armandj.olivares/using-bert-for-classifying-documents-with-long-texts-5c3e7b04573d\n",
    "\n",
    "Because chunk lengths can be different, we pad the shorter chunks with a special value, -99, which is masked and therfefore skipped for the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wU23D0zBEaDn"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#The generator functions (get the max length 3 batches at a time)\n",
    "num_sequences = len(df_train['features'].to_list())\n",
    "batch_size = 1\n",
    "batches_per_epoch =  647\n",
    "assert batch_size * batches_per_epoch == num_sequences\n",
    "num_features= 768\n",
    "def train_generator(df):\n",
    "    x_list= df['features'].to_list()\n",
    "    y_list =  df.label.to_list()\n",
    "    # Generate batches\n",
    "    while True:\n",
    "        for b in range(batches_per_epoch):\n",
    "            longest_index = (b + 1) * batch_size - 1\n",
    "            timesteps = len(max(df['features'].to_list()[:(b + 1) * batch_size][-batch_size:], key=len))\n",
    "            x_train = np.full((batch_size, timesteps, num_features), -99.)\n",
    "            y_train = np.zeros((batch_size,  1))\n",
    "            for i in range(batch_size):\n",
    "                li = b * batch_size + i\n",
    "                x_train[i, 0:len(x_list[li]), :] = x_list[li]\n",
    "                y_train[i] = y_list[li]\n",
    "            yield x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "skuzDmzAFRGy"
   },
   "outputs": [],
   "source": [
    "num_sequences_val = len(df_val['features'].to_list())\n",
    "batch_size_val = 1\n",
    "batches_per_epoch_val = 81\n",
    "assert batch_size_val * batches_per_epoch_val == num_sequences_val\n",
    "num_features= 768\n",
    "def val_generator(df):\n",
    "    x_list= df['features'].to_list()\n",
    "    y_list =  df.label.to_list()\n",
    "    # Generate batches\n",
    "    while True:\n",
    "        for b in range(batches_per_epoch_val):\n",
    "            longest_index = (b + 1) * batch_size_val - 1\n",
    "            timesteps = len(max(df['features'].to_list()[:(b + 1) * batch_size_val][-31:], key=len))\n",
    "            # print(len(df_train['emb'].to_list()[:b+batch_size][-7:]))\n",
    "            x_train = np.full((batch_size_val, timesteps, num_features), -99.)\n",
    "            y_train = np.zeros((batch_size_val,  1))\n",
    "            for i in range(batch_size_val):\n",
    "                li = b * batch_size_val + i\n",
    "                # print(\"li\", li)\n",
    "                # print(x_train[i, 0:len(x_list[li]), :].shape, len(x_list[li]))\n",
    "                x_train[i, 0:len(x_list[li]), :] = x_list[li]\n",
    "                y_train[i] = y_list[li]\n",
    "            yield x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DPxXek1cEmiL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v9-g-fsl5ibF"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "call_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.95, patience=3, verbose=2,\n",
    "                                mode='auto', min_delta=0.01, cooldown=0, min_lr=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "colab_type": "code",
    "id": "R9O2REszbea9",
    "outputId": "1c3b4ba5-bba6-4d13-be86-6091794352a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "647/647 [==============================] - 19s 30ms/step - loss: 0.6585 - acc: 0.6090 - val_loss: 0.9741 - val_acc: 0.4074\n",
      "Epoch 2/10\n",
      "647/647 [==============================] - 19s 30ms/step - loss: 0.6558 - acc: 0.6229 - val_loss: 0.9312 - val_acc: 0.4568\n",
      "Epoch 3/10\n",
      "647/647 [==============================] - 19s 30ms/step - loss: 0.6455 - acc: 0.6306 - val_loss: 0.8867 - val_acc: 0.4938\n",
      "Epoch 4/10\n",
      "647/647 [==============================] - 19s 29ms/step - loss: 0.6386 - acc: 0.6461 - val_loss: 0.8868 - val_acc: 0.4815\n",
      "Epoch 5/10\n",
      "647/647 [==============================] - 19s 30ms/step - loss: 0.6350 - acc: 0.6507 - val_loss: 0.8999 - val_acc: 0.4568\n",
      "Epoch 6/10\n",
      "647/647 [==============================] - 19s 30ms/step - loss: 0.6314 - acc: 0.6476 - val_loss: 0.8617 - val_acc: 0.4444\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "Epoch 7/10\n",
      "647/647 [==============================] - 19s 30ms/step - loss: 0.6258 - acc: 0.6553 - val_loss: 0.8167 - val_acc: 0.4568\n",
      "Epoch 8/10\n",
      "647/647 [==============================] - 19s 30ms/step - loss: 0.6189 - acc: 0.6692 - val_loss: 0.7615 - val_acc: 0.4815\n",
      "Epoch 9/10\n",
      "647/647 [==============================] - 19s 29ms/step - loss: 0.6137 - acc: 0.6801 - val_loss: 0.7257 - val_acc: 0.4815\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "Epoch 10/10\n",
      "647/647 [==============================] - 19s 29ms/step - loss: 0.6080 - acc: 0.6832 - val_loss: 0.7020 - val_acc: 0.4815\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f236874b048>"
      ]
     },
     "execution_count": 223,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator(df_lstm_train), \n",
    "                    steps_per_epoch=len(df_lstm_train), \n",
    "                    epochs=10,\n",
    "                    validation_data=val_generator(df_lstm_val), \n",
    "                    validation_steps=len(df_lstm_val), \n",
    "                    callbacks =[call_reduce] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "53yUe_3MGfob"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MJtDrBx1Gj8C"
   },
   "source": [
    "# LSTM Model: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8uhzOmoIGgAt",
    "outputId": "518a2869-eace-46cd-9de3-f0bf450b66cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7586062550544739, 0.604938268661499]"
      ]
     },
     "execution_count": 224,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_sequences_val = len(df_test['features'].to_list())\n",
    "batch_size_val = 1\n",
    "batches_per_epoch_val = 81\n",
    "assert batch_size_val * batches_per_epoch_val == num_sequences_val\n",
    "num_features= 768\n",
    "model.evaluate_generator(val_generator(df_test), steps= batches_per_epoch_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z_svyGVwGuEV"
   },
   "outputs": [],
   "source": [
    "y_log = model.predict_generator(val_generator(df_test), steps= batches_per_epoch_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oOi-Od1IGx4b"
   },
   "outputs": [],
   "source": [
    "y_pred = np.argmax(y_log, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "R0lRNC3rG0ta",
    "outputId": "375e45e9-2a0f-4bd4-ab5f-ff23fa6c5897"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM split chunks\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.95      0.69        37\n",
      "           1       0.88      0.32      0.47        44\n",
      "\n",
      "    accuracy                           0.60        81\n",
      "   macro avg       0.71      0.63      0.58        81\n",
      "weighted avg       0.72      0.60      0.57        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show classification report\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "print(\"LSTM split chunks\")\n",
    "print(classification_report(df_test['label'], y_pred))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Bert_multi_chunk_TF2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "w266",
   "language": "python",
   "name": "w266"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
