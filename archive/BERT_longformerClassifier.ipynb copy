{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import time\n",
    "import datetime\n",
    "import re\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Graphing\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns \n",
    "\n",
    "# PyTorch Imports\n",
    "import torch # a tensor library\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "#Huggingface Transformers\n",
    "import transformers\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "from transformers import LongformerModel, LongformerTokenizer\n",
    "from transformers import LongformerForSequenceClassification, AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Set Up\n",
    "Set up the model and the configuration we need\n",
    "\n",
    "- max_len - how many tokens will be used from the document.\n",
    "- batch_size - reduce if memory issues. paper reccomends 16-32\n",
    "- num epochs\n",
    "\n",
    "- tokenizer - this should be a pretrined tokenizer, e.g. distilBert. \n",
    "- model - make sure it uses the same tokenizer for generating the weights\n",
    "\n",
    "#### input files\n",
    "- train.csv: heading removed, dates and URL replcaed, un-cased, sentence breaks and punctuation included  \n",
    "- train_lcase.csv: heading removed, dates and URL replcaed, lower cased, sentence breaks and punctuation removed\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "train_file = \"data/train.csv\"\n",
    "test_file = \"data/test.csv\"\n",
    "\n",
    "max_len = 512\n",
    "batch_size = 8\n",
    "num_epochs = 5\n",
    "\n",
    "tokenizer = LongformerTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
    "model = LongformerForSequenceClassification.from_pretrained('allenai/longformer-base-4096',\n",
    "                                                       num_labels = 2,\n",
    "                                                       output_attentions = False,\n",
    "                                                       output_hidden_states = False,\n",
    "                                                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get data\n",
    "def get_data(fname):\n",
    "    df = pd.read_csv(fname)\n",
    "    df = df[['cleaned_contents', 'Discrimination_Label']]\n",
    "    df = df.rename(columns = {'cleaned_contents':'text', 'Discrimination_Label':'label'})\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to format elapsed time \n",
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to tokenize data and return tensors for input ids, attention mask and labels\n",
    "def tokenize_plus(df):\n",
    "\n",
    "    # Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "    sentences = df['text'].values\n",
    "    labels = df['label'].values\n",
    "\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    # For every sentence...\n",
    "    for sent in sentences:\n",
    "        # `encode_plus` will:\n",
    "        #   (1) Tokenize the sentence.\n",
    "        #   (2) Prepend the `[CLS]` token to the start.\n",
    "        #   (3) Append the `[SEP]` token to the end.\n",
    "        #   (4) Map tokens to their IDs.\n",
    "        #   (5) Pad or truncate the sentence to `max_length`\n",
    "        #   (6) Create attention masks for [PAD] tokens.\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "                            sent,                      # Sentence to encode.\n",
    "                            add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                            max_length = max_len,           # Pad & truncate all sentences.\n",
    "                            truncation = True,\n",
    "                            pad_to_max_length = True,\n",
    "                            return_attention_mask = True,   # Construct attn. masks.\n",
    "                            return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                       )\n",
    "\n",
    "        # Add the encoded sentence to the list.    \n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "\n",
    "        # And its attention mask (simply differentiates padding from non-padding).\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "    # Convert the lists into tensors.\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    return input_ids, attention_masks, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_manual(df, att=True):\n",
    "    tokenized = df['text'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, \n",
    "                                                             max_length=max_len, \n",
    "                                                             truncation=True)))\n",
    "    padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
    "    attention_mask = np.where(padded != 0, 1, 0)\n",
    "    if att:\n",
    "        for i in range(len(padded)):\n",
    "            idx = [i for i, x in enumerate(padded[i]) if x == 104]\n",
    "            attention_mask[i][idx] = 2\n",
    "    \n",
    "    input_ids = torch.tensor(padded) \n",
    "    attention_mask = torch.tensor(attention_mask)\n",
    "\n",
    "    labels = df['label']\n",
    "    labels = torch.tensor(labels)\n",
    "    \n",
    "    return input_ids, attention_mask, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SENTENCE\\n\\n\\t1.\\tYou are charged as follows:\\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SENTENCE\\n\\n\\t1.\\tJOSEFA KOTOBALAVU, you were ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SENTENCE\\n\\n1. The Director of Public Prosecut...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SENTENCE\\n\\n\\t1.\\tMOHOMMED NABI UD- DEAN, you ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JUDGMENT OF THE COURT\\n\\nBackground\\n\\n[1] The...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  SENTENCE\\n\\n\\t1.\\tYou are charged as follows:\\...      0\n",
       "1  SENTENCE\\n\\n\\t1.\\tJOSEFA KOTOBALAVU, you were ...      1\n",
       "2  SENTENCE\\n\\n1. The Director of Public Prosecut...      1\n",
       "3  SENTENCE\\n\\n\\t1.\\tMOHOMMED NABI UD- DEAN, you ...      1\n",
       "4  JUDGMENT OF THE COURT\\n\\nBackground\\n\\n[1] The...      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_data(train_file)\n",
    "#df = df.sample(n = 10) # limit size for testing \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids, attention_masks, labels = tokenize_plus(df)\n",
    "#input_ids, attention_masks, labels = tokenize_manual(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "647\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "# check size of embeddings\n",
    "print(len(input_ids))\n",
    "print(len(input_ids[0]))\n",
    "\n",
    "# Use torchsummary to print out layers nicely, needs the imput shape\n",
    "#p!ip install torchsummary\n",
    "#summary(your_model, input_size=(channels, H, W))\n",
    "#from torchsummary import summary\n",
    "#summary(model, input_size=(8, 647, 512))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the training inputs into a TensorDataset.\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  582 training samples\n",
      "   65 validation samples\n"
     ]
    }
   ],
   "source": [
    "# Create a 90-10 train-validation split.\n",
    "# Calculate the number of samples to include in each set.\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "# Divide the dataset by randomly selecting samples.\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataLoaders for our training and validation sets.\n",
    "# Take training samples in random order. \n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LongformerForSequenceClassification(\n",
       "  (longformer): LongformerModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(4098, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): LongformerEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (classifier): LongformerClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tell pytorch to run this model on the GPU.\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "# I believe the 'W' stands for 'Weight Decay fix\"\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
    "# training data.\n",
    "epochs = num_epochs\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 5 ========\n",
      "Training...\n",
      "  Batch    40  of     73.    Elapsed: 0:00:37.\n",
      "\n",
      "  Average training loss: 0.66\n",
      "  Training epcoh took: 0:01:07\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.67\n",
      "  Validation Loss: 0.63\n",
      "  Validation took: 0:00:02\n",
      "\n",
      "======== Epoch 2 / 5 ========\n",
      "Training...\n",
      "  Batch    40  of     73.    Elapsed: 0:00:36.\n",
      "\n",
      "  Average training loss: 0.64\n",
      "  Training epcoh took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.58\n",
      "  Validation Loss: 0.77\n",
      "  Validation took: 0:00:02\n",
      "\n",
      "======== Epoch 3 / 5 ========\n",
      "Training...\n",
      "  Batch    40  of     73.    Elapsed: 0:00:36.\n",
      "\n",
      "  Average training loss: 0.61\n",
      "  Training epcoh took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.72\n",
      "  Validation Loss: 0.65\n",
      "  Validation took: 0:00:02\n",
      "\n",
      "======== Epoch 4 / 5 ========\n",
      "Training...\n",
      "  Batch    40  of     73.    Elapsed: 0:00:36.\n",
      "\n",
      "  Average training loss: 0.54\n",
      "  Training epcoh took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.65\n",
      "  Validation Loss: 0.71\n",
      "  Validation took: 0:00:02\n",
      "\n",
      "======== Epoch 5 / 5 ========\n",
      "Training...\n",
      "  Batch    40  of     73.    Elapsed: 0:00:37.\n",
      "\n",
      "  Average training loss: 0.48\n",
      "  Training epcoh took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.65\n",
      "  Validation Loss: 0.79\n",
      "  Validation took: 0:00:02\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:05:42 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# We'll store a number of quantities such as training and validation loss, \n",
    "# validation accuracy, and timings.\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to \n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # The documentation for this `model` function is here: \n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        # It returns different numbers of parameters depending on what arguments\n",
    "        # arge given and what flags are set. For our useage here, it returns\n",
    "        # the loss (because we provided labels) and the \"logits\"--the model\n",
    "        # outputs prior to activation.\n",
    "        loss, logits = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "        # the `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "            # values prior to applying an activation function like the softmax.\n",
    "            (loss, logits) = model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels)\n",
    "            \n",
    "        # Accumulate the validation loss.\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "        \n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    \n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Valid. Loss</th>\n",
       "      <th>Valid. Accur.</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Validation Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0:01:07</td>\n",
       "      <td>0:00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0:01:06</td>\n",
       "      <td>0:00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0:01:06</td>\n",
       "      <td>0:00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0:01:06</td>\n",
       "      <td>0:00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0:01:06</td>\n",
       "      <td>0:00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
       "epoch                                                                         \n",
       "1               0.66         0.63           0.67       0:01:07         0:00:02\n",
       "2               0.64         0.77           0.58       0:01:06         0:00:02\n",
       "3               0.61         0.65           0.72       0:01:06         0:00:02\n",
       "4               0.54         0.71           0.65       0:01:06         0:00:02\n",
       "5               0.48         0.79           0.65       0:01:06         0:00:02"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display floats with two decimal places.\n",
    "pd.set_option('precision', 2)\n",
    "\n",
    "# Create a DataFrame from our training statistics.\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "# Use the 'epoch' as the row index.\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "# A hack to force the column headers to wrap.\n",
    "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
    "\n",
    "# Display the table.\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
    "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.xticks([1, 2, 3, 4])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SENTENCE\\n\\n[Name of the victim is suppressed....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JUDGMENT\\n\\nThis is an appeal against convicti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JUDGMENT\\n\\n1. On 13 May 2008, the Appellant, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JUDGMENT\\n[1] On the 17th July 2012 in the Nas...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SENTENCE\\n\\nBackground \\n\\n1. The accused was ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  SENTENCE\\n\\n[Name of the victim is suppressed....      1\n",
       "1  JUDGMENT\\n\\nThis is an appeal against convicti...      1\n",
       "2  JUDGMENT\\n\\n1. On 13 May 2008, the Appellant, ...      1\n",
       "3  JUDGMENT\\n[1] On the 17th July 2012 in the Nas...      0\n",
       "4  SENTENCE\\n\\nBackground \\n\\n1. The accused was ...      1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Holdoit\n",
    "df = get_data(test_file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize test data using tokenizer.encode_plus, put into a pytorch dataloader\n",
    "input_ids, attention_masks, labels = tokenize_plus(df)\n",
    "#input_ids, attention_masks, labels = tokenize_manual(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloader from input tensors, to help with memory usage\n",
    "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 162 test sentences...\n",
      "    DONE.\n"
     ]
    }
   ],
   "source": [
    "# Prediction on test set\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict \n",
    "for batch in prediction_dataloader:\n",
    "  # Add batch to GPU\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "  \n",
    "  # Unpack the inputs from our dataloader\n",
    "  b_input_ids, b_input_mask, b_labels = batch\n",
    "  \n",
    "  # Telling the model not to compute or store gradients, saving memory and \n",
    "  # speeding up prediction\n",
    "  with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      outputs = model(b_input_ids, token_type_ids=None, \n",
    "                      attention_mask=b_input_mask)\n",
    "\n",
    "  logits = outputs[0]\n",
    "\n",
    "  # Move logits and labels to CPU\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "  \n",
    "  # Store predictions and true labels\n",
    "  predictions.append(logits)\n",
    "  true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive samples: 97 of 162 (59.88%)\n"
     ]
    }
   ],
   "source": [
    "print('Positive samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision, Recall, F1, Support: (0.7155963302752294, 0.8041237113402062, 0.7572815533980584, None)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Combine the results across all batches. \n",
    "flat_predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# For each sample, pick the label (0 or 1) with the higher score.\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "\n",
    "# Combine the correct labels for each batch into a single list.\n",
    "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "scores = precision_recall_fscore_support(flat_true_labels, flat_predictions, average='binary')\n",
    "\n",
    "# Calculate the P,R,F1\n",
    "print('Precision, Recall, F1, Support:', scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of good predictions: 112\n",
      "number of bad predictions: 50\n",
      "accuracy 0.691358024691358\n"
     ]
    }
   ],
   "source": [
    "# get the bad predictions index\n",
    "bad_preds = [idx for idx, elem in enumerate(flat_predictions) if elem != flat_true_labels[idx]] \n",
    "good_preds = [idx for idx, elem in enumerate(flat_predictions) if elem == flat_true_labels[idx]] \n",
    "print(\"number of good predictions:\", len(good_preds))\n",
    "print(\"number of bad predictions:\", len(bad_preds))\n",
    "print(\"accuracy\", len(good_preds)/len(flat_predictions) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 0 0 1 0 1 1 0 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 0 0 1 0\n",
      " 1 0 0 0 1 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 0 1 0 1 1 0 1 0 0 1 0 0 1 1\n",
      " 0 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 0\n",
      " 0 0 1 0 1 0 1 0 1 0 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(flat_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
