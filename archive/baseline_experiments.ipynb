{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# General libraries.\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/train.csv\")\n",
    "df_test = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "647\n",
      "162\n"
     ]
    }
   ],
   "source": [
    "print(len(df_train))\n",
    "print(len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>cleaned_contents</th>\n",
       "      <th>Discrimination_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73277</td>\n",
       "      <td>sentence\\n\\n\\t1.\\tyou are charged as follows:\\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79776</td>\n",
       "      <td>sentence\\n\\n\\t1.\\tjosefa kotobalavu, you were ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75870</td>\n",
       "      <td>sentence\\n\\n1. the director of public prosecut...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79299</td>\n",
       "      <td>sentence\\n\\n\\t1.\\tmohommed nabi ud- dean, you ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80603</td>\n",
       "      <td>judgment of the court\\n\\nbackground\\n\\n[1] the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>78884</td>\n",
       "      <td>sentence\\n\\nintroduction\\n\\nyou are charged wi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>80837</td>\n",
       "      <td>judgment of the court\\n\\n[1] on 23 march 2004 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>256799</td>\n",
       "      <td>judgment\\n \\n  \\n• the appellant was charged a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>270467</td>\n",
       "      <td>ruling\\n \\n \\n[1] following a trial in the hig...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>83006</td>\n",
       "      <td>sentence\\n\\npio cakau you were found guilty an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>647 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      docid                                   cleaned_contents  \\\n",
       "0     73277  sentence\\n\\n\\t1.\\tyou are charged as follows:\\...   \n",
       "1     79776  sentence\\n\\n\\t1.\\tjosefa kotobalavu, you were ...   \n",
       "2     75870  sentence\\n\\n1. the director of public prosecut...   \n",
       "3     79299  sentence\\n\\n\\t1.\\tmohommed nabi ud- dean, you ...   \n",
       "4     80603  judgment of the court\\n\\nbackground\\n\\n[1] the...   \n",
       "..      ...                                                ...   \n",
       "642   78884  sentence\\n\\nintroduction\\n\\nyou are charged wi...   \n",
       "643   80837  judgment of the court\\n\\n[1] on 23 march 2004 ...   \n",
       "644  256799  judgment\\n \\n  \\n• the appellant was charged a...   \n",
       "645  270467  ruling\\n \\n \\n[1] following a trial in the hig...   \n",
       "646   83006  sentence\\n\\npio cakau you were found guilty an...   \n",
       "\n",
       "     Discrimination_Label  \n",
       "0                       0  \n",
       "1                       1  \n",
       "2                       1  \n",
       "3                       1  \n",
       "4                       0  \n",
       "..                    ...  \n",
       "642                     1  \n",
       "643                     0  \n",
       "644                     0  \n",
       "645                     0  \n",
       "646                     0  \n",
       "\n",
       "[647 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = list(df_train.X)\n",
    "y_train = list(df_train.y)\n",
    "X_test = list(df_test.X)\n",
    "y_test = list(df_test.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag Of Words Count Vectorizer and Training\n",
    "\n",
    "1) Train Naive Bayes, Linear SVM and Logisitic Regression using BOW\n",
    "\n",
    "2) (TBD) Use word2vec\n",
    "\n",
    "3) (TBD) CNN with word2vec\n",
    "\n",
    "4) (TBD) RNN + LTSM with word2vec\n",
    "\n",
    "5) (TBD) BERT with word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(strip_accents='unicode', \n",
    "                     lowercase=True, \n",
    "                     token_pattern=u'(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b',\n",
    "                     stop_words='english')\n",
    "X_train_cv = cv.fit_transform(X_train)\n",
    "X_test_cv = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>years</th>\n",
       "      <td>8636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence</th>\n",
       "      <td>7285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>court</th>\n",
       "      <td>7070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imprisonment</th>\n",
       "      <td>5096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offence</th>\n",
       "      <td>4862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "years         8636\n",
       "sentence      7285\n",
       "court         7070\n",
       "imprisonment  5096\n",
       "offence       4862"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check training data\n",
    "word_freq_df = pd.DataFrame(X_train_cv.toarray(), columns=cv.get_feature_names())\n",
    "top_words_df = pd.DataFrame(word_freq_df.sum()).sort_values(0, ascending=False)\n",
    "top_words_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_some_training(model):\n",
    "    clf = model\n",
    "    clf.fit(X_train_cv, y_train)\n",
    "    preds = clf.predict(X_test_cv)\n",
    "    print(model)\n",
    "    print('Accuracy: ', round(accuracy_score(y_test, preds),3))\n",
    "    print('Precision: ', round(precision_score(y_test, preds),3))\n",
    "    print('Recall: ', round(recall_score(y_test, preds),3))\n",
    "    print(\"\\n------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "Accuracy:  0.543\n",
      "Precision:  0.6\n",
      "Recall:  0.587\n",
      "\n",
      "------------------------\n",
      "\n",
      "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "Accuracy:  0.414\n",
      "Precision:  0.483\n",
      "Recall:  0.457\n",
      "\n",
      "------------------------\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='ovr', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Accuracy:  0.469\n",
      "Precision:  0.533\n",
      "Recall:  0.522\n",
      "\n",
      "------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "do_some_training(BernoulliNB())\n",
    "do_some_training(svm.SVC(kernel='linear', C = 1.0))\n",
    "do_some_training(LogisticRegression(solver='liblinear',multi_class='ovr'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "w266",
   "language": "python",
   "name": "w266"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
