{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ktrain\n",
    "from ktrain import text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build test and training sets & define preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_WORDS = 50000\n",
    "MAXLEN = 1000\n",
    "NGRAM_RANGE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detected encoding: utf-8 (if wrong, set manually)\n",
      "language: en\n",
      "Word Counts: 17751\n",
      "Nrows: 647\n",
      "647 train sequences\n",
      "train sequence lengths:\n",
      "\tmean : 1526\n",
      "\t95percentile : 4005\n",
      "\t99percentile : 7619\n",
      "x_train shape: (647,1000)\n",
      "y_train shape: (647, 2)\n",
      "Is Multi-Label? False\n",
      "162 test sequences\n",
      "test sequence lengths:\n",
      "\tmean : 1414\n",
      "\t95percentile : 3320\n",
      "\t99percentile : 7203\n",
      "x_test shape: (162,1000)\n",
      "y_test shape: (162, 2)\n"
     ]
    }
   ],
   "source": [
    "train, test, preproc = text.texts_from_csv('../data/train.csv',\n",
    "                                          'cleaned_contents',\n",
    "                                          label_columns=['Discrimination_Label'],\n",
    "                                          val_filepath='../data/test.csv',\n",
    "                                          max_features=NUM_WORDS,\n",
    "                                          maxlen=MAXLEN,\n",
    "                                          ngram_range=NGRAM_RANGE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "compiling word ID features...\n",
      "maxlen is 1000\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "model = text.text_classifier('fasttext', train, preproc=preproc)\n",
    "learner = ktrain.get_learner(model, train_data=train, val_data=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 1000, 64)          3200000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,204,546\n",
      "Trainable params: 3,204,418\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "learner.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find a good initial learning rate\n",
    "\n",
    "This is a method that was developed at the Naval Research Laboratory.  It's been promoted by Jeremy Howard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulating training for different learning rates... this may take a few moments...\n",
      "Train on 647 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ktrain/core.py:476: UserWarning: max_epochs is being set to 5 since steps per epoch is small. If you wish to estimate LR using more epochs, set max_epochs manually.\n",
      "  'If you wish to estimate LR using more epochs, set max_epochs manually.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "647/647 [==============================] - 2s 3ms/sample - loss: 1.1054 - accuracy: 0.4791\n",
      "Epoch 2/5\n",
      "647/647 [==============================] - 1s 875us/sample - loss: 1.1372 - accuracy: 0.4807\n",
      "Epoch 3/5\n",
      "647/647 [==============================] - 1s 853us/sample - loss: 1.1474 - accuracy: 0.4637\n",
      "Epoch 4/5\n",
      "647/647 [==============================] - 1s 843us/sample - loss: 0.9344 - accuracy: 0.5379\n",
      "Epoch 5/5\n",
      "384/647 [================>.............] - ETA: 0s - loss: 23.6795 - accuracy: 0.5000\n",
      "\n",
      "done.\n",
      "Visually inspect loss plot and select learning rate associated with falling loss\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.lr_find(show_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reduce_on_plateau automatically enabled at patience=2\n",
      "\n",
      "\n",
      "begin training using triangular learning rate policy with max lr of 0.02...\n",
      "Train on 647 samples, validate on 162 samples\n",
      "Epoch 1/1024\n",
      "647/647 [==============================] - 1s 2ms/sample - loss: 0.9667 - accuracy: 0.5549 - val_loss: 0.6819 - val_accuracy: 0.5988\n",
      "Epoch 2/1024\n",
      "647/647 [==============================] - 1s 978us/sample - loss: 0.7748 - accuracy: 0.5518 - val_loss: 0.6721 - val_accuracy: 0.5988\n",
      "Epoch 3/1024\n",
      "647/647 [==============================] - 1s 919us/sample - loss: 0.6804 - accuracy: 0.5904 - val_loss: 0.6805 - val_accuracy: 0.5988\n",
      "Epoch 4/1024\n",
      "647/647 [==============================] - 1s 908us/sample - loss: 0.6676 - accuracy: 0.6229 - val_loss: 0.6713 - val_accuracy: 0.5988\n",
      "Epoch 5/1024\n",
      "647/647 [==============================] - 1s 939us/sample - loss: 0.6521 - accuracy: 0.6445 - val_loss: 0.6567 - val_accuracy: 0.5988\n",
      "Epoch 6/1024\n",
      "647/647 [==============================] - 1s 1ms/sample - loss: 0.6050 - accuracy: 0.6739 - val_loss: 0.6519 - val_accuracy: 0.5988\n",
      "Epoch 7/1024\n",
      "647/647 [==============================] - 1s 993us/sample - loss: 0.5632 - accuracy: 0.7264 - val_loss: 0.6332 - val_accuracy: 0.6296\n",
      "Epoch 8/1024\n",
      "647/647 [==============================] - 1s 970us/sample - loss: 0.5183 - accuracy: 0.7465 - val_loss: 0.6026 - val_accuracy: 0.6111\n",
      "Epoch 9/1024\n",
      "647/647 [==============================] - 1s 967us/sample - loss: 0.5400 - accuracy: 0.7465 - val_loss: 0.5953 - val_accuracy: 0.6543\n",
      "Epoch 10/1024\n",
      "647/647 [==============================] - 1s 923us/sample - loss: 0.5168 - accuracy: 0.7141 - val_loss: 0.5925 - val_accuracy: 0.6296\n",
      "Epoch 11/1024\n",
      "647/647 [==============================] - 1s 1ms/sample - loss: 0.4718 - accuracy: 0.7728 - val_loss: 0.5338 - val_accuracy: 0.7160\n",
      "Epoch 12/1024\n",
      "647/647 [==============================] - 1s 967us/sample - loss: 0.4365 - accuracy: 0.8022 - val_loss: 0.5340 - val_accuracy: 0.6914\n",
      "Epoch 13/1024\n",
      "608/647 [===========================>..] - ETA: 0s - loss: 0.4976 - accuracy: 0.7796\n",
      "Epoch 00013: Reducing Max LR on Plateau: new max lr will be 0.01 (if not early_stopping).\n",
      "647/647 [==============================] - 1s 946us/sample - loss: 0.4965 - accuracy: 0.7790 - val_loss: 0.5411 - val_accuracy: 0.7160\n",
      "Epoch 14/1024\n",
      "647/647 [==============================] - 1s 937us/sample - loss: 0.3970 - accuracy: 0.8207 - val_loss: 0.5385 - val_accuracy: 0.7222\n",
      "Epoch 15/1024\n",
      "647/647 [==============================] - 1s 927us/sample - loss: 0.3582 - accuracy: 0.8423 - val_loss: 0.5312 - val_accuracy: 0.7284\n",
      "Epoch 16/1024\n",
      "647/647 [==============================] - 1s 933us/sample - loss: 0.3643 - accuracy: 0.8547 - val_loss: 0.5153 - val_accuracy: 0.7346\n",
      "Epoch 17/1024\n",
      "647/647 [==============================] - 1s 954us/sample - loss: 0.3374 - accuracy: 0.8501 - val_loss: 0.5020 - val_accuracy: 0.7654\n",
      "Epoch 18/1024\n",
      "647/647 [==============================] - 1s 926us/sample - loss: 0.3299 - accuracy: 0.8686 - val_loss: 0.5008 - val_accuracy: 0.7469\n",
      "Epoch 19/1024\n",
      "647/647 [==============================] - 1s 886us/sample - loss: 0.2916 - accuracy: 0.8717 - val_loss: 0.5261 - val_accuracy: 0.7346\n",
      "Epoch 20/1024\n",
      "640/647 [============================>.] - ETA: 0s - loss: 0.3004 - accuracy: 0.8734\n",
      "Epoch 00020: Reducing Max LR on Plateau: new max lr will be 0.005 (if not early_stopping).\n",
      "647/647 [==============================] - 1s 932us/sample - loss: 0.3054 - accuracy: 0.8702 - val_loss: 0.5426 - val_accuracy: 0.7346\n",
      "Epoch 21/1024\n",
      "647/647 [==============================] - 1s 989us/sample - loss: 0.2396 - accuracy: 0.9150 - val_loss: 0.5537 - val_accuracy: 0.7346\n",
      "Epoch 22/1024\n",
      "608/647 [===========================>..] - ETA: 0s - loss: 0.3118 - accuracy: 0.8750\n",
      "Epoch 00022: Reducing Max LR on Plateau: new max lr will be 0.0025 (if not early_stopping).\n",
      "647/647 [==============================] - 1s 886us/sample - loss: 0.3159 - accuracy: 0.8702 - val_loss: 0.5516 - val_accuracy: 0.7407\n",
      "Epoch 23/1024\n",
      "640/647 [============================>.] - ETA: 0s - loss: 0.2572 - accuracy: 0.8984Restoring model weights from the end of the best epoch.\n",
      "647/647 [==============================] - 1s 935us/sample - loss: 0.2605 - accuracy: 0.8964 - val_loss: 0.5567 - val_accuracy: 0.7469\n",
      "Epoch 00023: early stopping\n",
      "Weights from best epoch have been loaded into model.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2f55776358>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.autofit(2e-2, early_stopping=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.65      0.67        65\n",
      "           1       0.77      0.81      0.79        97\n",
      "\n",
      "    accuracy                           0.75       162\n",
      "   macro avg       0.74      0.73      0.73       162\n",
      "weighted avg       0.74      0.75      0.75       162\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[42, 23],\n",
       "       [18, 79]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.validate(class_names=preproc.get_classes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "X_test = pd.read_csv('../data/test.csv')['cleaned_contents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = ktrain.get_predictor(learner.model, preproc=preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "\n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=1\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.654</b>, score <b>0.635</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.791\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 85.28%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.156\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(120, 100.00%, 96.04%); opacity: 0.81\" title=\"0.087\">as</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.67%); opacity: 0.81\" title=\"0.171\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.71%); opacity: 0.83\" title=\"0.342\">accused</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.89%); opacity: 0.83\" title=\"0.382\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.04%); opacity: 0.81\" title=\"0.157\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 62.03%); opacity: 0.99\" title=\"2.210\">sole</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"2.380\">breadwinner</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.30%); opacity: 0.82\" title=\"0.226\">for</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.58%); opacity: 0.81\" title=\"0.102\">his</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 71.80%); opacity: 0.92\" title=\"1.445\">family</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 90.36%); opacity: 0.83\" title=\"0.312\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.13%); opacity: 0.81\" title=\"0.153\">reduce</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.59%); opacity: 0.82\" title=\"0.256\">his</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.63%); opacity: 0.82\" title=\"0.213\">sentence</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.87%); opacity: 0.82\" title=\"0.245\">by</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.55%); opacity: 0.81\" title=\"0.138\">two</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.78%); opacity: 0.80\" title=\"0.016\">years</span><span style=\"opacity: 0.80\">.</span>\n",
       "    </p>\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.explain('As the accused is the sole breadwinner for his family, I reduce his sentence by two years.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.save('models/fasttext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pred = ktrain.load_predictor('models/fasttext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "\n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=1\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.654</b>, score <b>0.635</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.791\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 85.28%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.156\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(120, 100.00%, 96.04%); opacity: 0.81\" title=\"0.087\">as</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.67%); opacity: 0.81\" title=\"0.171\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.71%); opacity: 0.83\" title=\"0.342\">accused</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.89%); opacity: 0.83\" title=\"0.382\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.04%); opacity: 0.81\" title=\"0.157\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 62.03%); opacity: 0.99\" title=\"2.210\">sole</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"2.380\">breadwinner</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.30%); opacity: 0.82\" title=\"0.226\">for</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.58%); opacity: 0.81\" title=\"0.102\">his</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 71.80%); opacity: 0.92\" title=\"1.445\">family</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 90.36%); opacity: 0.83\" title=\"0.312\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.13%); opacity: 0.81\" title=\"0.153\">reduce</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.59%); opacity: 0.82\" title=\"0.256\">his</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.63%); opacity: 0.82\" title=\"0.213\">sentence</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.87%); opacity: 0.82\" title=\"0.245\">by</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.55%); opacity: 0.81\" title=\"0.138\">two</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.78%); opacity: 0.80\" title=\"0.016\">years</span><span style=\"opacity: 0.80\">.</span>\n",
       "    </p>\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_pred.explain('As the accused is the sole breadwinner for his family, I reduce his sentence by two years.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
