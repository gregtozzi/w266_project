{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# General libraries.\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "809\n"
     ]
    }
   ],
   "source": [
    "# load the matching document contents\n",
    "df_text = pd.read_csv(\"data/trackGBV_xls_match.csv\")\n",
    "print(len(df_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "809\n"
     ]
    }
   ],
   "source": [
    "df_labels = pd.read_csv(\"data/trackGBV_labels.csv\")\n",
    "print(len(df_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There are 5 types of document\n",
    "\n",
    "* Judgment\n",
    "* Sentence\n",
    "* Ruling\n",
    "* Decision\n",
    "* Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the index of the document type\n",
    "df_text[\"j_idx\"]= df_text[\"contents\"].str.find(\"JUDGMENT\") \n",
    "df_text[\"s_idx\"]= df_text[\"contents\"].str.find(\"SENTENCE\") \n",
    "df_text[\"r_idx\"]= df_text[\"contents\"].str.find(\"RULING\")\n",
    "df_text[\"d_idx\"]= df_text[\"contents\"].str.find(\"DECISION\")\n",
    "df_text[\"o_idx\"] = df_text[\"contents\"].str.find('APPLICATION FOR BAIL PENDING APPEAL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of docs that are:\n",
      "\n",
      "JUDGMENT: 196\n",
      "SENTENCE: 555\n",
      "RULING: 46\n",
      "DECISION: 4\n",
      "OTHER: 1\n",
      "JUDGMENT & SENTENCE: 9\n",
      "JUDGMENT & RULING: 1\n",
      "JUDGMENT & DECISION: 0\n",
      "SENTENCE & RULING: 2\n",
      "SENTENCE & DECISION: 0\n",
      "RULING & DECISION: 0\n"
     ]
    }
   ],
   "source": [
    "# check if there are any duplicate document_types\n",
    "# first j_idx and s_idx, then do the others\n",
    "\n",
    "print(\"Number of docs that are:\")\n",
    "print()\n",
    "print(\"JUDGMENT:\", len(df_text.loc[(df_text.j_idx != -1)])) # 203\n",
    "print(\"SENTENCE:\", len(df_text.loc[(df_text.s_idx != -1)])) # 565\n",
    "print(\"RULING:\", len(df_text.loc[(df_text.r_idx != -1)]))   # 47\n",
    "print(\"DECISION:\", len(df_text.loc[(df_text.d_idx != -1)])) # 4\n",
    "print(\"OTHER:\", len(df_text.loc[(df_text.o_idx != -1)])) # 4\n",
    "\n",
    "print(\"JUDGMENT & SENTENCE:\", len(df_text.loc[((df_text.j_idx != -1) & (df_text.s_idx != -1))])) # 9\n",
    "print(\"JUDGMENT & RULING:\", len(df_text.loc[((df_text.j_idx != -1) & (df_text.r_idx != -1))]))   # 1\n",
    "print(\"JUDGMENT & DECISION:\", len(df_text.loc[((df_text.j_idx != -1) & (df_text.d_idx != -1))])) # 0\n",
    "\n",
    "print(\"SENTENCE & RULING:\", len(df_text.loc[((df_text.s_idx != -1) & (df_text.r_idx != -1))]))   # 2\n",
    "print(\"SENTENCE & DECISION:\", len(df_text.loc[((df_text.s_idx != -1) & (df_text.d_idx != -1))])) # 0\n",
    "\n",
    "print(\"RULING & DECISION:\", len(df_text.loc[((df_text.r_idx != -1) & (df_text.d_idx != -1))])) # 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find and replace missing judgment statements\n",
    "df_text.loc[((df_text.j_idx == -1) & (df_text.s_idx == -1) & (df_text.r_idx == -1) & (df_text.d_idx == -1) & \n",
    "              df_text.contents.str.contains('J U D G M E N T')\n",
    "            ), 'j_idx' ] = df_text.loc[((df_text.j_idx == -1) & (df_text.s_idx == -1) & (df_text.r_idx == -1) & (df_text.d_idx == -1) & \n",
    "              df_text.contents.str.contains('J U D G M E N T')\n",
    "            )]['contents'].str.find('J U D G M E N T')\n",
    "\n",
    "df_text.loc[((df_text.j_idx == -1) & (df_text.s_idx == -1) & (df_text.r_idx == -1) & (df_text.d_idx == -1) & \n",
    "              df_text.contents.str.contains('JUDGEMENT')\n",
    "            ), 'j_idx' ] = df_text.loc[((df_text.j_idx == -1) & (df_text.s_idx == -1) & (df_text.r_idx == -1) & (df_text.d_idx == -1) & \n",
    "              df_text.contents.str.contains('JUDGEMENT')\n",
    "            )]['contents'].str.find('JUDGEMENT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find and replace missing ruling statements\n",
    "\n",
    "df_text.loc[((df_text.j_idx == -1) & (df_text.s_idx == -1) & (df_text.r_idx == -1) & (df_text.d_idx == -1) & \n",
    "              df_text.contents.str.contains('R U L I N G')\n",
    "            ), 'r_idx' ] = df_text.loc[((df_text.j_idx == -1) & (df_text.s_idx == -1) & (df_text.r_idx == -1) & (df_text.d_idx == -1) & \n",
    "              df_text.contents.str.contains('R U L I N G')\n",
    "            )]['contents'].str.find('R U L I N G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find and replace missing sentence statements\n",
    "\n",
    "df_text.loc[((df_text.j_idx == -1) & (df_text.s_idx == -1) & (df_text.r_idx == -1) & (df_text.d_idx == -1) & \n",
    "              df_text.contents.str.contains('S E N T E N C E')\n",
    "            ), 's_idx' ] = df_text.loc[((df_text.j_idx == -1) & (df_text.s_idx == -1) & (df_text.r_idx == -1) & (df_text.d_idx == -1) & \n",
    "              df_text.contents.str.contains('S E N T E N C E')\n",
    "            )]['contents'].str.find('S E N T E N C E')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find and replace missing 'other' statements\n",
    "df_text.loc[((df_text.j_idx == -1) & (df_text.s_idx == -1) & (df_text.r_idx == -1) & (df_text.d_idx == -1) & \n",
    "              df_text.contents.str.contains('CHARGE')\n",
    "            ), 'o_idx' ] = df_text.loc[((df_text.j_idx == -1) & (df_text.s_idx == -1) & (df_text.r_idx == -1) & (df_text.d_idx == -1) & \n",
    "              df_text.contents.str.contains('CHARGE')\n",
    "            )]['contents'].str.find('CHARGE')\n",
    "\n",
    "df_text.loc[((df_text.j_idx == -1) & (df_text.s_idx == -1) & (df_text.r_idx == -1) & (df_text.d_idx == -1) & \n",
    "              df_text.contents.str.contains('PUNISHMENT')\n",
    "            ), 'o_idx' ] = df_text.loc[((df_text.j_idx == -1) & (df_text.s_idx == -1) & (df_text.r_idx == -1) & (df_text.d_idx == -1) & \n",
    "              df_text.contents.str.contains('PUNISHMENT')\n",
    "            )]['contents'].str.find('PUNISHMENT')\n",
    "\n",
    "df_text.loc[((df_text.j_idx == -1) & (df_text.s_idx == -1) & (df_text.r_idx == -1) & (df_text.d_idx == -1) & \n",
    "              df_text.contents.str.contains('ORDER OF SUMMARY DISMISSAL')\n",
    "            ), 'o_idx' ] = df_text.loc[((df_text.j_idx == -1) & (df_text.s_idx == -1) & (df_text.r_idx == -1) & (df_text.d_idx == -1) & \n",
    "              df_text.contents.str.contains('ORDER OF SUMMARY DISMISSAL')\n",
    "            )]['contents'].str.find('ORDER OF SUMMARY DISMISSAL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the lower case 'sentence' and 'judgment' cases (there are only 6)\n",
    "df_text.loc[((df_text.j_idx == -1) & (df_text.s_idx == -1) & (df_text.r_idx == -1) & (df_text.d_idx == -1) & \n",
    "              df_text.contents.str.contains('Sentence')\n",
    "            ), 's_idx' ] = df_text.loc[((df_text.j_idx == -1) & (df_text.s_idx == -1) & (df_text.r_idx == -1) & (df_text.d_idx == -1) & \n",
    "              df_text.contents.str.contains('Sentence')\n",
    "            )]['contents'].str.find('Sentence')\n",
    "\n",
    "df_text.loc[((df_text.j_idx == -1) & (df_text.s_idx == -1) & (df_text.r_idx == -1) & (df_text.d_idx == -1) & \n",
    "              df_text.contents.str.contains('Judgment')\n",
    "            ), 'j_idx' ] = df_text.loc[((df_text.j_idx == -1) & (df_text.s_idx == -1) & (df_text.r_idx == -1) & (df_text.d_idx == -1) & \n",
    "              df_text.contents.str.contains('Judgment')\n",
    "            )]['contents'].str.find('Judgment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>contents</th>\n",
       "      <th>j_idx</th>\n",
       "      <th>s_idx</th>\n",
       "      <th>r_idx</th>\n",
       "      <th>d_idx</th>\n",
       "      <th>o_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [docid, contents, j_idx, s_idx, r_idx, d_idx, o_idx]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check we have captured every doc type = there should be none\n",
    "df_text.loc[((df_text.j_idx == -1) & (df_text.s_idx == -1) & (df_text.r_idx == -1) & (df_text.d_idx == -1) & (df_text.o_idx == -1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all -1s to a None so that we can get the \"minimum Non -1 value to key off of in or replace text\"\n",
    "df_text.loc[df_text['s_idx'] == -1, 's_idx'] = None\n",
    "df_text.loc[df_text['j_idx'] == -1, 'j_idx'] = None\n",
    "df_text.loc[df_text['r_idx'] == -1, 'r_idx'] = None\n",
    "df_text.loc[df_text['d_idx'] == -1, 'd_idx'] = None\n",
    "df_text.loc[df_text['o_idx'] == -1, 'o_idx'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text['type_idx'] = df_text[['s_idx', 'j_idx', 'r_idx', 'd_idx', 'o_idx']].min(axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all the parts of the document up to the document type\n",
    "for row in df_text.itertuples():\n",
    "    idx = row.type_idx\n",
    "    new_text = row.contents[idx:]\n",
    "    df_text.at[row.Index, 'cleaned_contents'] = new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Remove URL\n",
    "df_text['cleaned_contents'] = df_text['cleaned_contents'].replace(r'http://www.paclii.org.*', '<URL>', regex=True)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENTENCE\n",
      "[Child Rape]\n",
      "\n",
      "[1] On the 11th October 2011 the accused entered a plea of guilty to one charge of rape contrary to Section 207(1) & (2) (b) of the Crimes Decree 2009, the particulars being that on the 14th March 2010 at Uciwai settlement, Korolevu he raped a child with his finger. He agreed to facts put to him, whereupon he was found guilty and convicted.\n",
      "\n",
      "[2] The facts admitted by the accused were that in March 2010 he was staying with the victims' family, he being related to the victims' father. On the 14th March 2010, the mother had left home to visit the father in hospital. She left the victim, who at the time was 9 years old and her elder brother in the care of the accused.\n",
      "\n",
      "[3] After dinner the two children went to sleep on a mattress. The boy asked the accused to sleep on the mattress with them as his mother has not yet returned. The accused blew out the candle and joined them on the mattress. The boy told the victim to lie in the middle between him and the accused. While lying down the accused pulled down the girls' panties and used his fingers to indecently invade her. The victim felt pain and tried to push his hand away, however the accused persisted. The next morning the young girl told her mother what had happened. The accused was chased from the house and the Police informed.\n",
      "\n",
      "[4] The maximum penalty for rape is life imprisonment and the Courts have recently been handing down very heavy sentences on offenders against children. Sexual offending against children in this country has become far too prevalent and it is the hope that harsh sentences will send out a clear message to would be perpetrators that our children are to be protected from such unrestrained immorality.\n",
      "\n",
      "[5] In Tamanitoakula HAC 28 of 2010 (Lbs), Thurairaja J passed a sentence of 16 years against an accused convicted of rape of a thirteen year old, as a deterrent punishment.\n",
      "\n",
      "[6] A very similar case to this was in Labasa where a 50 years old raped a nine year old and attracted a sentence of twelve years by Goundar J in Joji Mara HAC 38 of 2010(Lbs).\n",
      "\n",
      "[7] The Court of Appeal has set the starting point for rape of a child to be ten years imprisonment in Drotini AAU0001.2005S.\n",
      "\n",
      "[8] In mitigation, Counsel for the accused tells me that the accused is 57 years old, and while previously a saw miller, he now works as a security guard. He regrets what has happened and when he came to his senses he got up and left the room. He was previously a member of the Catholic Church but now belongs to the Harvest Evangelical Church whose Senior Pastor gave a sworn testimonial in his favour.\n",
      "\n",
      "[9] He produces a letter from the Parish Priest of the Lautoka Catholic Church attesting to his good character.\n",
      "\n",
      "[10] He is asthmatic and intensely remorseful. He would have sought forgiveness from the victim but was unable to because of the strict bail conditions imposed on him.\n",
      "\n",
      "[11] Two of the biggest mitigatory features in his favour are his \"eve of trial\" plea of guilty, and in doing so relieving the victim of having to relive her ordeal.\n",
      "\n",
      "[12] It is an aggravating feature of the case that the accused was in a position of trust, that trust given him by the mother to care for the children in her absence. That trust he abused.\n",
      "\n",
      "[13] I take as a starting point a term of fourteen years imprisonment and for the aggravation of breach of trust I increase that to a term of sixteen years. For the demonstrable remorse and religious mitigation I deduct 2 years. This also includes credit for his clear record. The plea of guilty was entered on the day of trial and will not receive the full credit it could; but I am nevertheless aware of the saving of the young girl giving evidence. He will receive credit for that of three years, meaning that the accused will serve a total term of imprisonment of 11 years.\n",
      "\n",
      "[14] He will serve a minimum term of nine years before being eligible for parole.\n",
      "\n",
      "Paul K. Madigan\n",
      "JUDGE\n",
      "At Lautoka\n",
      "12th October 2011.\n",
      "\n",
      "\n",
      "PacLII: Copyright Policy | Disclaimers | Privacy Policy | Feedback\n",
      "URL: <URL>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_text['cleaned_contents'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower case - DO NOT DO\n",
    "# df_text['cleaned_contents'] = df_text['cleaned_contents'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "df_labels = pd.read_csv(\"data/trackGBV_labels.csv\")\n",
    "df = pd.merge(left=df_text, right=df_labels, left_on='docid', right_on='DocID')\n",
    "df_split = df[['docid', 'cleaned_contents', 'Discrimination_Label']].copy()\n",
    "train, test = train_test_split(df_split, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>contents</th>\n",
       "      <th>j_idx</th>\n",
       "      <th>s_idx</th>\n",
       "      <th>r_idx</th>\n",
       "      <th>d_idx</th>\n",
       "      <th>o_idx</th>\n",
       "      <th>type_idx</th>\n",
       "      <th>cleaned_contents</th>\n",
       "      <th>DocID</th>\n",
       "      <th>Customary_Practices</th>\n",
       "      <th>Gender_Stereotypes</th>\n",
       "      <th>Other_Factors</th>\n",
       "      <th>Num_Factors</th>\n",
       "      <th>Discrimination_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80380</td>\n",
       "      <td>Home | Databases | WorldLII | Search | Feedbac...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>592.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>592</td>\n",
       "      <td>SENTENCE\\n[Child Rape]\\n\\n[1] On the 11th Octo...</td>\n",
       "      <td>80380</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78839</td>\n",
       "      <td>Home | Databases | WorldLII | Search | Feedbac...</td>\n",
       "      <td>601.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>601</td>\n",
       "      <td>JUDGMENT\\n\\nOn the 12th of August 2004, the Ap...</td>\n",
       "      <td>78839</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>248796</td>\n",
       "      <td>State v Lagivere - Sentence [2017] FJHC 386...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>874.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>874</td>\n",
       "      <td>SENTENCE\\n \\n  \\n• Inoke Lagivere, you stand c...</td>\n",
       "      <td>248796</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>257586</td>\n",
       "      <td>State v Goundar - Sentence [2018] FJHC 438;...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>875.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>875</td>\n",
       "      <td>SENTENCE\\n \\n \\n (The name of the complainant ...</td>\n",
       "      <td>257586</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80121</td>\n",
       "      <td>Home | Databases | WorldLII | Search | Feedbac...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>645.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>645</td>\n",
       "      <td>SENTENCE\\nBackground\\n[1] On the 17th July 201...</td>\n",
       "      <td>80121</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    docid                                           contents  j_idx  s_idx  \\\n",
       "0   80380  Home | Databases | WorldLII | Search | Feedbac...    NaN  592.0   \n",
       "1   78839  Home | Databases | WorldLII | Search | Feedbac...  601.0    NaN   \n",
       "2  248796     State v Lagivere - Sentence [2017] FJHC 386...    NaN  874.0   \n",
       "3  257586     State v Goundar - Sentence [2018] FJHC 438;...    NaN  875.0   \n",
       "4   80121  Home | Databases | WorldLII | Search | Feedbac...    NaN  645.0   \n",
       "\n",
       "   r_idx  d_idx  o_idx  type_idx  \\\n",
       "0    NaN    NaN    NaN       592   \n",
       "1    NaN    NaN    NaN       601   \n",
       "2    NaN    NaN    NaN       874   \n",
       "3    NaN    NaN    NaN       875   \n",
       "4    NaN    NaN    NaN       645   \n",
       "\n",
       "                                    cleaned_contents   DocID  \\\n",
       "0  SENTENCE\\n[Child Rape]\\n\\n[1] On the 11th Octo...   80380   \n",
       "1  JUDGMENT\\n\\nOn the 12th of August 2004, the Ap...   78839   \n",
       "2  SENTENCE\\n \\n  \\n• Inoke Lagivere, you stand c...  248796   \n",
       "3  SENTENCE\\n \\n \\n (The name of the complainant ...  257586   \n",
       "4  SENTENCE\\nBackground\\n[1] On the 17th July 201...   80121   \n",
       "\n",
       "   Customary_Practices  Gender_Stereotypes  Other_Factors  Num_Factors  \\\n",
       "0                    0                   0              1            1   \n",
       "1                    0                   0              1            1   \n",
       "2                    0                   0              0            0   \n",
       "3                    1                   1              0            2   \n",
       "4                    0                   1              0            1   \n",
       "\n",
       "   Discrimination_Label  \n",
       "0                     1  \n",
       "1                     1  \n",
       "2                     0  \n",
       "3                     1  \n",
       "4                     1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(r'data/train.csv', index = False)\n",
    "test.to_csv(r'data/test.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOWER CASE AND REMOVE NEWLINE\n",
    "import pandas as pd\n",
    "import re\n",
    "def lcase_text(df):\n",
    "\n",
    "    df['len_txt'] =df.cleaned_contents.apply(lambda x: len(x.split()))\n",
    "    df = df[df.len_txt >249]\n",
    "    df = df[df.len_txt <20000]\n",
    "    df = df.rename(columns = {'cleaned_contents':'text', 'Discrimination_Label':'label'})\n",
    "    df['text'] = df['text'].str.lower()\n",
    "    df['text'] = pd.Series(re.sub(r'(jan(uary)?|feb(ruary)?|mar(ch)?|apr(il)?|may|jun(e)?|jul(y)?|aug(ust)?|sep(t)?(tember)?|oct(ober)?|nov(ember)?|dec(ember)?)([\\s]{1,3})?([0-9]{1,2})(.{1,3})?((,)|(.))?([\\s]{1,3})?([0-9]{4})|([0-9]{1,2})(.{1,3})?([\\s]{1,3})?(day)?([\\s]{1,3})?(of)?([\\s]{1,3})?(jan(uary)?|feb(ruary)?|mar(ch)?|apr(il)?|may|jun(e)?|jul(y)?|aug(ust)?|sep(t)?(tember)?|oct(ober)?|nov(ember)?|dec(ember)?)((,)|(.))?(\\s{1,3})?([0-9]{4})|(first|second|third|fourth|fifth|sixth|seventh|eighth|ninth|tenth|eleventh|twelfth|thirteenth|fourteenth|fifteenth|sixteenth|seventeenth|eighteenth|nineteenth|twentieth|twenty-first|twenty-second|twenty-third|twenty-fourth|twenty-fifth|twenty-sixth|twenty-seventh|twenty-eighth|twenty-ninth|thirtieth|thirty-first)([\\s]{1,3})?(day)?([\\s]{1,3})?(of)?([\\s]{1,3})?(jan(uary)?|feb(ruary)?|mar(ch)?|apr(il)?|may|jun(e)?|jul(y)?|aug(ust)?|sep(t)?(tember)?|oct(ober)?|nov(ember)?|dec(ember)?)((,)|(.))?(\\s{1,3})?([0-9]{4})|(\\b[0-9]{1,2}(\\-|\\/)[0-9]{1,2}(\\-|\\/)[0-9]{2,4}\\b)|(\\b[0-9]{2,4}(\\-|\\/)[0-9]{1,2}(\\-|\\/)[0-9]{1,2}\\b)', '[DATE]', i) for i in df['text'])\n",
    "    df = df.replace({'text': {\"'\": \"\"}}, regex=True)\n",
    "    df = df.replace({'text': {\"(\\\\W)+\": \" \"}}, regex=True)\n",
    "    df.dropna(subset = [\"text\"], inplace=True)\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    return(df)\n",
    "\n",
    "df_train = lcase_text(pd.read_csv(\"../w266_project/data/train.csv\"))\n",
    "df_test = lcase_text(pd.read_csv(\"../w266_project/data/test.csv\"))\n",
    "df_all = pd.concat([df_train, df_test])\n",
    "\n",
    "# Save to disk\n",
    "df_train.to_csv(r'data/train_lcase.csv', index = False)\n",
    "df_test.to_csv(r'data/test_lcase.csv', index = False)\n",
    "df_all.to_csv(r'data/all_lcase.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "w266",
   "language": "python",
   "name": "w266"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
